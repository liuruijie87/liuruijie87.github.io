<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>liuruijie</title>
  
  <subtitle>快乐搬砖，码出未来</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liuruijie87.github.io/"/>
  <updated>2020-08-17T08:24:24.708Z</updated>
  <id>https://liuruijie87.github.io/</id>
  
  <author>
    <name>liuruijie</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>线程的五种状态（生命周期）</title>
    <link href="https://liuruijie87.github.io/2020/08/17/%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BA%94%E7%A7%8D%E7%8A%B6%E6%80%81%EF%BC%88%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%EF%BC%89/"/>
    <id>https://liuruijie87.github.io/2020/08/17/线程的五种状态（生命周期）/</id>
    <published>2020-08-17T08:16:08.510Z</published>
    <updated>2020-08-17T08:24:24.708Z</updated>
    
    <content type="html"><![CDATA[<p>　　线程在创建到销毁的过程中，总共经历五种状态的转换，分别是：新建、就绪、运行、阻塞、死亡。具体如下：<br>新建：创建线程对象<br>就绪：线程对象已经启动了,但是还没有获取到cpu的执行权<br>运行：获取到了cpu的执行权<br>阻塞：没有cpu的执行权,回到就绪<br>死亡：代码运行完毕,线程消亡　</p><img src="/2020/08/17/线程的五种状态（生命周期）/1_线程状态图.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;　　线程在创建到销毁的过程中，总共经历五种状态的转换，分别是：新建、就绪、运行、阻塞、死亡。具体如下：&lt;br&gt;新建：创建线程对象&lt;br&gt;就绪：线程对象已经启动了,但是还没有获取到cpu的执行权&lt;br&gt;运行：获取到了cpu的执行权&lt;br&gt;阻塞：没有cpu的执行权,回到就绪&lt;b
      
    
    </summary>
    
      <category term="Linux" scheme="https://liuruijie87.github.io/categories/Linux/"/>
    
    
      <category term="线程" scheme="https://liuruijie87.github.io/tags/%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>malloc底层实现原理</title>
    <link href="https://liuruijie87.github.io/2020/07/18/malloc%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>https://liuruijie87.github.io/2020/07/18/malloc底层实现原理/</id>
    <published>2020-07-18T07:52:22.041Z</published>
    <updated>2020-07-18T08:58:44.152Z</updated>
    
    <content type="html"><![CDATA[<p>　　对于malloc，以前只知道如何用，却不知道它的内部实现原理。这次特意学习了一下，做个记录。下面分析均是基于linux环境下的malloc实现。先总结结论，再逐步展开。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>　　<br>　　1）当开辟的空间小于128K时，调用brk（）函数，malloc的底层实现是系统调用函数brk（），其主要移动指针_edata(这里的_edata指的是Linux地址空间中堆段的末尾地址，不是数据段的末尾地址)<br>　　2）当开辟的空间大于128K时，mmap（）系统调用函数会在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟。</p><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><p>　　当一个进程发生缺页中断的时候，进程会陷入核心态，执行以下操作：<br>　　1）检查要访问的虚拟地址是否合法<br>　　2）查找/分配一个物理页<br>　　3）填充物理页内容（读取磁盘，或者直接置0，或者什么都不做）<br>　　4）建立映射关系（虚拟地址到物理地址的映射关系）<br>　　5）重复执行发生缺页中断的那条指令</p><h1 id="内存分配的原理"><a href="#内存分配的原理" class="headerlink" title="内存分配的原理"></a>内存分配的原理</h1><p>　　从操作系统角度看，进程分配内存有两种方式，分别由两个系统调用完成：brk 和 mmap (不考虑共享内存)<br>　　1）brk是将数据段（.data）的最高地址指针_edata往高地址推<br>　　2）mmap是在进程的虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空闲的虚拟内存。<br>　　这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p><h1 id="具体分配过程"><a href="#具体分配过程" class="headerlink" title="具体分配过程"></a>具体分配过程</h1><h2 id="情况一：malloc小于128K的内存，使用brk分配"><a href="#情况一：malloc小于128K的内存，使用brk分配" class="headerlink" title="情况一：malloc小于128K的内存，使用brk分配"></a>情况一：malloc小于128K的内存，使用brk分配</h2><p>　　将_edata往高地址推(只分配虚拟空间，不对应物理内存(因此没有初始化)，第一次读/写数据时，引起内核缺页中断，内核才分配对应的物理内存，然后虚拟地址空间建立映射关系)，如下图：</p><img src="/2020/07/18/malloc底层实现原理/1_内存分配.png"><p>　　1、进程启动的时候，其（虚拟）内存空间的初始布局如图1所示。<br>　　2、进程调用A=malloc(30K)以后，内存空间如图2。<br>　　malloc函数会调用brk系统调用，将_edata指针往高地址推30K，就完成虚拟内存分配，要注意：_edata+30K只是完成虚拟地址的分配，A这块内存现在还是没有物理页与之对应的，等到进程第一次读写A这块内存的时候，发生缺页中断，这个时候，内核才分配A这块内存对应的物理页。也就是说，如果用malloc分配了A这块内容，然后从来不访问它，那么，A对应的物理页是不会被分配的。<br>　　3、进程调用B=malloc(40K)以后，内存空间如图3。</p><h2 id="情况二：malloc大于128K的内存，使用mmap分配（munmap释放）"><a href="#情况二：malloc大于128K的内存，使用mmap分配（munmap释放）" class="headerlink" title="情况二：malloc大于128K的内存，使用mmap分配（munmap释放）"></a>情况二：malloc大于128K的内存，使用mmap分配（munmap释放）</h2><img src="/2020/07/18/malloc底层实现原理/2_内存分配.png">　<p>　　4、进程调用C=malloc(200K)以后，内存空间如图4。<br>　　默认情况下，malloc函数分配内存，如果请求内存大于128K（可由M_MMAP_THRESHOLD选项调节），那就不是去推_edata指针了，而是利用mmap系统调用，从堆和栈的中间分配一块虚拟内存，这样做主要是因为:brk分配的内存需要等到高地址内存释放以后才能释放（例如，在B释放之前，A是不可能释放的，因为只有一个_edata 指针，这就是内存碎片产生的原因），而mmap分配的内存可以单独释放。<br>　　5、进程调用D=malloc(100K)以后，内存空间如图5。<br>　　6、进程调用free(C)以后，C对应的虚拟内存和物理内存一起释放。</p><img src="/2020/07/18/malloc底层实现原理/3_内存分配.png"><p>　　7、进程调用free(B)以后，如图7所示。<br>　　B对应的虚拟内存和物理内存都没有释放，因为只有一个_edata指针，如果往回推，那么D这块内存怎么办呢？当然，B这块内存，是可以重用的，如果这个时候再来一个40K的请求，那么malloc很可能就把B这块内存返回回去了。<br>　　8、进程调用free(D)以后，如图8所示B和D连接起来，变成一块140K的空闲内存。　　<br>　　9，默认情况下，当最高地址空间的空闲内存超过128K（可由M_TRIM_THRESHOLD选项调节）时，执行内存紧缩操作（trim）。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩，变成图9所示。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;　　对于malloc，以前只知道如何用，却不知道它的内部实现原理。这次特意学习了一下，做个记录。下面分析均是基于linux环境下的malloc实现。先总结结论，再逐步展开。&lt;/p&gt;
&lt;h1 id=&quot;结论&quot;&gt;&lt;a href=&quot;#结论&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
      <category term="Linux" scheme="https://liuruijie87.github.io/categories/Linux/"/>
    
    
      <category term="malloc" scheme="https://liuruijie87.github.io/tags/malloc/"/>
    
  </entry>
  
  <entry>
    <title>优先队列的理解-与堆排序的比较</title>
    <link href="https://liuruijie87.github.io/2020/07/12/%E5%A4%A7%E9%A1%B6%E5%A0%86%E5%B0%8F%E9%A1%B6%E5%A0%86%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>https://liuruijie87.github.io/2020/07/12/大顶堆小顶堆的理解/</id>
    <published>2020-07-12T03:17:40.936Z</published>
    <updated>2020-07-12T05:05:39.842Z</updated>
    
    <content type="html"><![CDATA[<p>　　优先队列 priority_queue，头文件#include <dequeue>。<br>　　priority_queue&lt;int, vector<int>, greater<int>&gt; 表示队列内部是小顶堆，队列输出为升序序列（输出过程是小的先输出）。<br>　　priority_queue&lt;int, vector<int>, less<int>&gt; 表示队列内部是大顶堆，队列输出为降序序列。（优先队列默认即为大顶堆）<br>　　这里要与堆排序中的升序降序情况区别开来，在堆排序中，一般是对数组中的元素进行排序，如果要进行升序排序（即排序后的结果是升序的，并没有规定按什么顺序输出，排完之后数组中的元素变为升序），则利用大顶堆，每次调整后将堆顶元素（当前堆中最大元素）和最后一个元素交换，即从后往前变成有序的。同理，在降序排序中，要利用小顶堆，也是每次调整后将堆顶元素（当前堆中最小元素）和最后一个元素交换，从后往前变成有序的。</int></int></int></int></dequeue></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;　　优先队列 priority_queue，头文件#include &lt;dequeue&gt;。&lt;br&gt;　　priority_queue&amp;lt;int, vector&lt;int&gt;, greater&lt;int&gt;&amp;gt; 表示队列内部是小顶堆，队列输出为升序序列（输出过程是小的先输出）。&lt;
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="堆" scheme="https://liuruijie87.github.io/tags/%E5%A0%86/"/>
    
  </entry>
  
  <entry>
    <title>mmap详解</title>
    <link href="https://liuruijie87.github.io/2020/07/02/mmap%E8%AF%A6%E8%A7%A3/"/>
    <id>https://liuruijie87.github.io/2020/07/02/mmap详解/</id>
    <published>2020-07-02T01:53:05.505Z</published>
    <updated>2020-07-12T05:11:45.935Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mmap基础概念"><a href="#mmap基础概念" class="headerlink" title="mmap基础概念"></a>mmap基础概念</h1><p>　　mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示：</p><img src="/2020/07/02/mmap详解/1_空间映射.png"><p>　　由上图可以看出，进程的虚拟地址空间，由多个虚拟内存区域构成。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即具有同样特性的连续地址范围。上图中所示的text数据段（代码段）、初始数据段、BSS数据段、堆、栈和内存映射，都是一个独立的虚拟内存区域。而为内存映射服务的地址空间处在堆栈之间的空余部分。<br>linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示：</p><img src="/2020/07/02/mmap详解/2_虚拟内存区域.png"><p>　　vm_area_struct结构中包含区域起始和终止地址以及其他相关信息，同时也包含一个vm_ops指针，其内部可引出所有针对这个区域可以使用的系统调用函数。这样，进程对某一虚拟内存区域的任何操作需要用要的信息，都可以从vm_area_struct中获得。mmap函数就是要创建一个新的vm_area_struct结构，并将其与文件的物理磁盘地址相连。</p><h1 id="mmap内存映射原理"><a href="#mmap内存映射原理" class="headerlink" title="mmap内存映射原理"></a>mmap内存映射原理</h1><p>　　mmap内存映射的实现过程，总的来说可以分为三个阶段：</p><h2 id="（一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域"><a href="#（一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域" class="headerlink" title="（一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域"></a>（一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域</h2><p>　　1、进程在用户空间调用库函数mmap，原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);<br>　　2、在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址<br>　　3、为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化<br>　　4、将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中</p><h2 id="（二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系"><a href="#（二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系" class="headerlink" title="（二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系"></a>（二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系</h2><p>　　5、为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护着和这个已打开文件相关各项信息。<br>　　6、通过该文件的文件结构体，链接到file_operations模块，调用内核函数mmap，其原型为：int mmap(struct file *filp, struct vm_area_struct *vma)，不同于用户空间库函数。<br>　　7、内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址。<br>　　8、通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，这片虚拟地址并没有任何数据关联到主存中。</p><h2 id="（三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝"><a href="#（三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝" class="headerlink" title="（三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝"></a>（三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝</h2><p>　　注：前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。<br>　　9、进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常。<br>　　10、缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。<br>　　11、调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中。<br>　　12、之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。<br>　　注：修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步,这样所写的内容就能立即保存到文件里了。</p><h1 id="mmap和常规文件操作的区别"><a href="#mmap和常规文件操作的区别" class="headerlink" title="mmap和常规文件操作的区别"></a>mmap和常规文件操作的区别</h1><p>　　首先简单看一下常规文件系统操作（调用read/fread等类函数）中，函数的调用过程：<br>　　1、进程发起读文件请求。<br>　　2、内核通过查找进程文件符表，定位到内核已打开文件集上的文件信息，从而找到此文件的inode。<br>　　3、inode在address_space上查找要请求的文件页是否已经缓存在页缓存中。如果存在，则直接返回这片文件页的内容。<br>　　4、如果不存在，则通过inode定位到文件磁盘地址，将数据从磁盘复制到页缓存。之后再次发起读页面过程，进而将页缓存中的数据发给用户进程。<br>　　总结来说，常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。写操作也是一样，待写入的buffer在内核空间不能直接访问，必须要先拷贝至内核空间对应的主存，再写回磁盘中（延迟写回），也是需要两次数据拷贝。<br>　　而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。<br>　　总而言之，<strong>常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。</strong>说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高。</p><h1 id="mmap优点总结"><a href="#mmap优点总结" class="headerlink" title="mmap优点总结"></a>mmap优点总结</h1><p>　　由上文讨论可知，mmap优点共有一下几点：<br>　　1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。<br>　　2、实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。<br>　　3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。<br>　　4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。</p><h1 id="mmap相关函数"><a href="#mmap相关函数" class="headerlink" title="mmap相关函数"></a>mmap相关函数</h1><p>　　函数原型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);</span><br><span class="line"></span><br><span class="line">　返回说明:成功执行时，mmap()返回被映射区的指针。失败时，mmap()返回MAP_FAILED[其值为(void *)-1]， error被设为以下的某个值：</span><br><span class="line"> EACCES：访问出错</span><br><span class="line"> EAGAIN：文件已被锁定，或者太多的内存已被锁定</span><br><span class="line"> EBADF：fd不是有效的文件描述词</span><br><span class="line"> EINVAL：一个或者多个参数无效</span><br><span class="line"> ENFILE：已达到系统对打开文件的限制</span><br><span class="line"> ENODEV：指定文件所在的文件系统不支持内存映射</span><br><span class="line"> ENOMEM：内存不足，或者进程已超出最大内存映射数量</span><br><span class="line"> EPERM：权能不足，操作不允许</span><br><span class="line"> ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志</span><br><span class="line"> SIGSEGV：试着向只读区写入</span><br><span class="line"> SIGBUS：试着访问不属于进程的内存区</span><br><span class="line"> </span><br><span class="line"> 参数:</span><br><span class="line"> start：映射区的开始地址</span><br><span class="line"> length：映射区的长度</span><br><span class="line"> prot：期望的内存保护标志，不能与文件的打开模式冲突。是以下的某个值，可以通过or运算合理地组合在一起</span><br><span class="line">   PROT_EXEC ：页内容可以被执行</span><br><span class="line">   PROT_READ ：页内容可以被读取</span><br><span class="line">   PROT_WRITE ：页可以被写入</span><br><span class="line">   PROT_NONE ：页不可访问</span><br><span class="line"> flags：指定映射对象的类型，映射选项和映射页是否可以共享。它的值可以是一个或者多个以下位的组合体</span><br><span class="line">   MAP_FIXED //使用指定的映射起始地址，如果由start和len参数指定的内存区重叠于现存的映射空间，重叠部分将会被丢弃。如果指定的起始地址不可用，操作将会失败。并且起始地址必须落在页的边界上。</span><br><span class="line">   MAP_SHARED //与其它所有映射这个对象的进程共享映射空间。对共享区的写入，相当于输出到文件。直到msync()或者munmap()被调用，文件实际上不会被更新。</span><br><span class="line">   MAP_PRIVATE //建立一个写入时拷贝的私有映射。内存区域的写入不会影响到原文件。这个标志和以上标志是互斥的，只能使用其中一个。</span><br><span class="line">   MAP_DENYWRITE //这个标志被忽略。</span><br><span class="line">   MAP_EXECUTABLE //同上</span><br><span class="line">   MAP_NORESERVE //不要为这个映射保留交换空间。当交换空间被保留，对映射区修改的可能会得到保证。当交换空间不被保留，同时内存不足，对映射区的修改会引起段违例信号。</span><br><span class="line">   MAP_LOCKED //锁定映射区的页面，从而防止页面被交换出内存。</span><br><span class="line">   MAP_GROWSDOWN //用于堆栈，告诉内核VM系统，映射区可以向下扩展。</span><br><span class="line">   MAP_ANONYMOUS //匿名映射，映射区不与任何文件关联。</span><br><span class="line">   MAP_ANON //MAP_ANONYMOUS的别称，不再被使用。</span><br><span class="line">   MAP_FILE //兼容标志，被忽略。</span><br><span class="line">   MAP_32BIT //将映射区放在进程地址空间的低2GB，MAP_FIXED指定时会被忽略。当前这个标志只在x86-64平台上得到支持。</span><br><span class="line">   MAP_POPULATE //为文件映射通过预读的方式准备好页表。随后对映射区的访问不会被页违例阻塞。</span><br><span class="line">   MAP_NONBLOCK //仅和MAP_POPULATE一起使用时才有意义。不执行预读，只为已存在于内存中的页面建立页表入口。</span><br><span class="line"> fd：有效的文件描述词。如果MAP_ANONYMOUS被设定，为了兼容问题，其值应为-1</span><br><span class="line"> offset：被映射对象内容的起点</span><br></pre></td></tr></table></figure><p>　　相关函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int munmap( void * addr, size_t len ) </span><br><span class="line">//成功执行时，munmap()返回0。失败时，munmap返回-1，error返回标志和mmap一致；</span><br><span class="line">//该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小；</span><br><span class="line">//当映射关系解除后，对原来映射地址的访问将导致段错误发生。 </span><br><span class="line"></span><br><span class="line">int msync( void *addr, size_t len, int flags )</span><br><span class="line">//一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。</span><br><span class="line">//可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。</span><br></pre></td></tr></table></figure><h1 id="mmap使用细节"><a href="#mmap使用细节" class="headerlink" title="mmap使用细节"></a>mmap使用细节</h1><p>　　1、使用mmap需要注意的一个关键点是，mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。<br>　　2、内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。具体情形参见“情形三”。<br>　　3、映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。<br>　　在上面的知识前提下，我们下面看看如果大小不是页的整倍数的具体情况：</p><h2 id="情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。"><a href="#情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。" class="headerlink" title="情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。"></a>情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。</h2><p>　　分析：因为单位物理页面的大小是4096字节，虽然被映射的文件只有5000字节，但是对应到进程虚拟地址区域的大小需要满足整页大小，因此mmap函数执行后，实际映射到虚拟内存区域8192个 字节，5000~8191的字节部分用零填充。映射后的对应关系如下图所示：</p><img src="/2020/07/02/mmap详解/3_文件映射.png"><p>　　此时：<br>　　（1）读/写前5000个字节（0-4999），会返回操作文件内容。<br>　　（2）读字节5000-8191时，结果全为0。写5000-8191时，进程不会报错，但是所写的内容不会写入原文件中 。<br>　　（3）读/写8192以外的磁盘部分，会返回一个SIGSECV错误。</p><p>##情形二：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射15000字节到虚拟内存中，即映射大小超过了原始文件的大小。</p><p>　　分析：由于文件的大小是5000字节，和情形一一样，其对应的两个物理页。那么这两个物理页都是合法可以读写的，只是超出5000的部分不会体现在原文件中。由于程序要求映射15000字节，而文件只占两个物理页，因此8192字节~15000字节都不能读写，操作时会返回异常。如下图所示：</p><img src="/2020/07/02/mmap详解/4_文件映射.png"><p>　　此时：<br>　　（1）进程可以正常读/写被映射的前5000字节(0-4999)，写操作的改动会在一定时间后反映在原文件中。<br>　　（2）对于5000-8191字节，进程可以进行读写过程，不会报错。但是内容在写入前均为0，另外，写入后不会反映在文件中。<br>　　（3）对于8192-14999字节，进程不能对其进行读写，会报SIGBUS错误。<br>　　（4）对于15000以外的字节，进程不能对其读写，会引发SIGSEGV错误。</p><h2 id="情形三：一个文件初始大小为0，使用mmap操作映射了1000-4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。"><a href="#情形三：一个文件初始大小为0，使用mmap操作映射了1000-4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。" class="headerlink" title="情形三：一个文件初始大小为0，使用mmap操作映射了1000*4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。"></a>情形三：一个文件初始大小为0，使用mmap操作映射了1000*4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。</h2><p>　　分析：如果在映射建立之初，就对文件进行读写操作，由于文件大小为0，并没有合法的物理页对应，如同情形二一样，会返回SIGBUS错误。<br>　　但是如果每次操作ptr读写前，先增加文件的大小，那么ptr在文件大小内部的操作就是合法的。例如，文件扩充4096字节，ptr就能操作ptr ~ [ (char)ptr + 4095]的空间。只要文件扩充的范围在1000个物理页（映射范围）内，ptr都可以对应操作相同的大小。这样，方便随时扩充文件空间，随时写入文件，不造成空间浪费。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;mmap基础概念&quot;&gt;&lt;a href=&quot;#mmap基础概念&quot; class=&quot;headerlink&quot; title=&quot;mmap基础概念&quot;&gt;&lt;/a&gt;mmap基础概念&lt;/h1&gt;&lt;p&gt;　　mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件
      
    
    </summary>
    
      <category term="Linux" scheme="https://liuruijie87.github.io/categories/Linux/"/>
    
    
      <category term="mmap" scheme="https://liuruijie87.github.io/tags/mmap/"/>
    
  </entry>
  
  <entry>
    <title>网络编程学习笔记（五）--select、poll、epoll比较</title>
    <link href="https://liuruijie87.github.io/2020/06/26/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%94%EF%BC%89--select-poll-epoll/"/>
    <id>https://liuruijie87.github.io/2020/06/26/网络编程学习（五）--select-poll-epoll/</id>
    <published>2020-06-26T13:17:02.670Z</published>
    <updated>2020-06-27T08:08:37.341Z</updated>
    
    <content type="html"><![CDATA[<h1 id="select介绍"><a href="#select介绍" class="headerlink" title="select介绍"></a>select介绍</h1><p>　　select创建了3个文件描述符集（fd_set）并拷贝到内核中，分别监听读、写、异常动作。select可以监听的文件描述符受到单个进程所能打开的fd的限制，默认为1024。采用轮询方式，遍历所有的fd，最后返回一个文件描述符是否就绪的mask掩码，并根据mask掩码给fd_set赋值。将之前的fd_set拷贝传出到用户态并返回就绪的文件描述符的总个数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。应用程序索引就绪文件描述符的时间复杂度是O(n)。再次调用select时，需要将新的fd_set监听文件描述符拷贝传入进内核。select只能工作在相对较低下的LT模式。</p><h2 id="select的缺点"><a href="#select的缺点" class="headerlink" title="select的缺点"></a>select的缺点</h2><p>　　（1）select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。<br>　　（2）对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。<br>　　（3）需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。</p><h1 id="poll介绍"><a href="#poll介绍" class="headerlink" title="poll介绍"></a>poll介绍</h1><p>　　将struct_pollfd结构体数组拷贝到内核中进行监听。poll采用链表poll_list来进行文件描述符的存储，因此poll可以监听的文件描述符数为系统可以打开的最大文件描述符数（65535）。采用轮询方式，查询每个fd的状态，如果就绪，内核就修改fd对应的revents的值，而events成员保持不变，因此下次调用poll时，应用程序无需重置pollfd类型的事件集参数。将之前传入的struct_pollfd结构体数组拷贝传出到用户态，并返回就绪文件描述符的总个数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判读。应用程序索引就绪文件描述符的时间复杂度是O(n)。poll只能工作在相对较低下的LT模式。</p><h2 id="poll的缺点"><a href="#poll的缺点" class="headerlink" title="poll的缺点"></a>poll的缺点</h2><p>　　（1）大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。<br>　　（2）poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。</p><h1 id="epoll介绍"><a href="#epoll介绍" class="headerlink" title="epoll介绍"></a>epoll介绍</h1><p>　　执行epoll_create()函数会在内核创建一颗红黑树rb_node以及就绪链表rdllist(存放已经就绪的文件描述符)，监听的文件描述符数为系统可以打开的最大文件描述符数（65535）。接着用户执行的epoll_ctl()函数将epoll_event结构体拷贝传入内核，内核会在红黑树上添加相应的结点，并注册回调函数ep_poll_callback()，内核在检测到某文件描述符可读/可写时就调用回调函数callback,该回调函数将文件描述符放入就绪链表rdllist中。epoll_wait()函数只需要观察rdllist中有无就绪的文件描述符即可，内核将就绪的文件描述符事件复制到传入的epoll_event结构体数组中返回给用户空间，所以用户只用遍历依次处理即可，即应用程序索引就绪文件描述符的时间复杂度是O（1）。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存传递的，减少了不必要的拷贝。再次调用epoll系统调用，不用重建红黑树，直接沿用已经存在的即可。epoll支持ET模式，当内核将该事件通知给用户后，用户必须立即处理，这样就减少了可读、可写和异常事件被触发的次数。</p><h2 id="epoll的优点"><a href="#epoll的优点" class="headerlink" title="epoll的优点"></a>epoll的优点</h2><p>　　（1）没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。<br>　　（2）效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。<br>　　（3）内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。</p><h2 id="epoll对文件描述符操作的两种模式"><a href="#epoll对文件描述符操作的两种模式" class="headerlink" title="epoll对文件描述符操作的两种模式"></a>epoll对文件描述符操作的两种模式</h2><p>　　（1）LT（level_trigger）模式：是缺省的工作方式，并且同时支持block和no-block_socket，当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。<br>　　（2）ET（edge_trigger）模式：)是高速工作方式，只支持no-block_socket，当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。<br>　　ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</p><h1 id="select、poll、epoll区别"><a href="#select、poll、epoll区别" class="headerlink" title="select、poll、epoll区别"></a>select、poll、epoll区别</h1><p>　　在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)<br>　　如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。</p><h1 id="为什么epoll比select和poll更高效？"><a href="#为什么epoll比select和poll更高效？" class="headerlink" title="为什么epoll比select和poll更高效？"></a>为什么epoll比select和poll更高效？</h1><p>（1）减少了用户态和内核态之间文件描述符的拷贝<br>　　select创建了3个文件描述符集（fd_set）并拷贝到内核中，分别监听读、写、异常事件。内核分配相关数据结构（fd_set_bits），内核在检测到有就绪事件后，就修改用户传进来的fd_set的值以告知用户有就绪的文件描述符。将文件描述符fd_set拷贝传出到用户态并返回就绪的文件描述符的总个数。内核删除和文件描述符相关的数据结构，由于内核修改了用户传进来的fd_set文件描述符集，下次调用select前必须要重置fd_set，然后重新传给内核，内核再重新拷贝一份，重新分配数据结构。<br>　　poll系统调用将struct_pollfd结构体数组拷贝到内核中进行监听，内核分配相关数据结构poll_list,用来存储监听的文件描述符，然后调用所有fd对应的poll(将current挂到各个fd对应的设备等待队列上)，内核在检测到有就绪事件后，就修改fd对应的revents的值用来告知用户有就绪的文件描述符，而events成员保持不变，因此下次调用poll时，应用程序无需重置pollfd类型的事件集参数。将之前传入的struct_pollfd结构体数组拷贝传出到用户态，并返回就绪文件描述符的总个数。内核删除和文件描述符相关的数据结构，下次调用poll需要将struct pollfd重新传给内核，内核在重新拷贝一份，重新分配数据结构。<br>　　epoll执行epoll_create()函数会在内核创建一颗红黑树rb_node以及就绪链表rdllist(存放已经就绪的文件描述符)，接着用户执行的epoll_ctl()函数将epoll_event结构体拷贝传入内核，内核会在红黑树上添加相应的结点，内核将就绪的文件描述符事件复制到传入的epoll_event结构体数组中返回给用户空间，系统调用在返回时采用mmap共享存储区，需要拷贝的次数大大减少。由于epoll创建的有关文件描述符的数据结构本身就存在于内核态中。下一次调用epoll系统调用时，不需要再次拷贝用户空间所要监听的文件描述符，也不需要重新构建红黑树和就绪链表等相关数据结构，直接沿用已经存在的数据结构。</p><p>（2）减少了对就绪文件描述符的遍历<br>　　select和poll采用轮询的方式来检查文件描述符是否处于就绪状态。并且内核修改用户传进来的fd_set和pollfd结构体的成员的revents值以告知用户有文件描述符就绪，但是用户并不知道有哪些文件描述符处于就绪态，需要遍历查找就绪文件描述符，因此，应用程序索引就绪文件描述符的时间复杂度为O（n）。而epoll采用回调机制。在调用epoll_ctl时，已经将用户感兴趣的事件传给了内核，内核会维持一个内核事件表，记录用户感兴趣的事件，就绪事件发生时，驱动设备调用回调函数ep_poll_callback()将就绪的fd挂到rdllist上。用户调用epoll_wait时，将rdllist上就绪的文件描述符发送给用户。此时发送给用户的都是就绪的fd。因此，应用程序索引就绪文件描述符的时间复杂度为O（1）。</p><p>（3）select和poll只支持LT模式，而epoll支持高效的ET模式，并且epoll还支持EPOLLONESHOT事件。<br>　　LT模式（电平触发）：LT模式是默认的工作模式，当检测到文件描述符上有事件发生并将此事件通知给应用程序，应用程序可以不立即处理该事件，下次调用会再次响应应用程序并通知此事件。<br>　　ET模式（边沿触发）：当检测到文件描述符上有事件发生并将此事件通知给应用程序，应用程序必须立即处理该事件，如果没处理或者没处理完，下次调用不会再响应应用程序并通知此事件。<br>　　ET模式很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高，epoll工作在ET模式的时候，必须使用非阻塞的套接字，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。<br>　　<strong>注意</strong>即使使用ET模式，一个socket上的某个事件还是可能被触发多次，这在并发程序中就会引发一个问题。比如一个线程在读取完某个socket上的数据开始处理这些数据的时候，而在数据的处理过程中这个socket上又有新数据可读，这时另一个线程被唤醒来处理新数据，于是就出现了两个线程同时操作一个socket的局面。因此需要使用epoll的EPOLLONESHOT事件实现。对于注册了EPOLLONESHOT事件的文件描述符，操作系统最多触发其上的一个读、写或异常事件，且只触发一次。当一个线程在处理socket时，其它线程是不可能有机会操作该socket的。注册了EPOLLONESHOT事件的socket一旦被某个线程处理完，该线程就应该立即重置这个socket上的EPOLLONESHOT事件，以确保这个socket下次可读时，其EPOLLIN事件可被触发，进而让其它线程有机会处理这个socket。使用EPOLLONESHOT事件能进一步减少可读、可写和异常事件的被触发的次数。</p><h1 id="无论哪种情况下，eopll都比select和poll高效吗？"><a href="#无论哪种情况下，eopll都比select和poll高效吗？" class="headerlink" title="无论哪种情况下，eopll都比select和poll高效吗？"></a>无论哪种情况下，eopll都比select和poll高效吗？</h1><h2 id="epoll适用于连接较多，活动数量较少的情况。"><a href="#epoll适用于连接较多，活动数量较少的情况。" class="headerlink" title="epoll适用于连接较多，活动数量较少的情况。"></a>epoll适用于连接较多，活动数量较少的情况。</h2><p>　　(1)epoll为了实现返回就绪的文件描述符，维护了一个红黑树和好多个等待队列，内核开销很大。如果此时监听了很少的文件描述符，底层的开销会得不偿失；<br>　　(2)epoll中注册了回调函数，当有事件发生时，服务器设备驱动调用回调函数将就绪的fd挂在rdllist上，如果有很多的活动，同一时间需要调用的回调函数数量太多，服务器压力太大。</p><h2 id="select和poll适用于连接较少的情况。"><a href="#select和poll适用于连接较少的情况。" class="headerlink" title="select和poll适用于连接较少的情况。"></a>select和poll适用于连接较少的情况。</h2><p>　　当select和poll上监听的fd数量较少，内核通知用户现在有就绪事件发生，应用程序判断当前是哪个fd就绪所消耗的时间复杂度就会大大减小。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;select介绍&quot;&gt;&lt;a href=&quot;#select介绍&quot; class=&quot;headerlink&quot; title=&quot;select介绍&quot;&gt;&lt;/a&gt;select介绍&lt;/h1&gt;&lt;p&gt;　　select创建了3个文件描述符集（fd_set）并拷贝到内核中，分别监听读、写、异常动
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="网络编程" scheme="https://liuruijie87.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>网络编程学习笔记（四）--几种高性能方案</title>
    <link href="https://liuruijie87.github.io/2020/06/14/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89--%E9%AB%98%E6%80%A7%E8%83%BD%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://liuruijie87.github.io/2020/06/14/网络编程学习笔记（四）--高性能解决方案/</id>
    <published>2020-06-14T13:19:56.634Z</published>
    <updated>2020-06-14T13:23:01.805Z</updated>
    
    <content type="html"><![CDATA[<h1 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h1><p>　　我们假设设计了这样一个应用程序，该程序从标准输入接收数据输入，然后通过套接字发送出去，同时，该程序也通过套接字接收对方发送的数据流。我们可以使用fgets方法等待标准输入，但是一旦这样做，就没有办法在套接字有数据的时候读出数据；我们也可以使用read方法等待套接字有数据返回，但是这样做，也没有办法在标准输入有数据的情况下，读入数据并发送给对方。<br>　　I/O多路复用的设计初衷就是解决这样的场景。我们可以把标准输入、套接字等都看做I/O的一路，多路复用的意思，就是在任何一路I/O有“事件”发生的情况下，通知应用程序去处理相应的I/O事件，这样我们的程序就变成了“多面手”，在同一时刻仿佛可以处理多个I/O事件。像刚才的例子，使用I/O复用以后，如果标准输入有数据，立即从标准输入读入数据，通过套接字发送出去；如果套接字有数据可以读，立即可以读出数据。</p><h2 id="select函数"><a href="#select函数" class="headerlink" title="select函数"></a>select函数</h2><p>　　select函数就是这样一种常见的I/O多路复用技术，使用select函数，通知内核挂起进程，当一个或多个I/O事件发生后，控制权返还给应用程序，由应用程序进行I/O事件的处理。<br>select函数的使用方法<br>　　select函数的使用方法有点复杂，我们先看一下它的声明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int select(int maxfd, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct *timeval);</span><br><span class="line">返回：若有就绪描述符则为其数目，若超时则为 0，若出错则为 -1</span><br></pre></td></tr></table></figure><p>　　在这个函数中，maxfd表示的是待测试的描述符基数，它的值是待测试的最大描述符加1。比如现在的select待测试的描述符集合是{0,1,4}，那么maxfd就是5，紧接着的是三个描述符集合，分别是读描述符集合readset、写描述符集合writeset和异常描述符集合exceptset，这三个分别通知内核，在哪些描述符上检测数据可以读，可以写和有异常发生。<br>　　那么如何设置这些描述符集合呢？以下的宏可以帮助到我们。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void FD_ZERO(fd_set *fdset); </span><br><span class="line">void FD_SET(int fd, fd_set *fdset); </span><br><span class="line">void FD_CLR(int fd, fd_set *fdset); </span><br><span class="line">int FD_ISSET(int fd, fd_set *fdset);</span><br></pre></td></tr></table></figure><p>　　如果刚入门，理解这些宏可能有些困难。我们可以这样想象，下面一个向量代表了一个描述符集合，其中，这个向量的每个元素都是二机制数中的0或者1。<br>　　a[maxfd-1], …, a[1], a[0]<br>　　我们按照这样的思路来理解这些宏：其中0代表不需要处理，1代表需要处理。实际上，很多系统是用一个整型数组来表示一个描述字集合的，一个32位的整型数可以表示32个描述字，例如第一个整型数表示0-31描述字，第二个整型数可以表示32-63描述字，以此类推。这个时候再来理解为什么描述字集合{0,1,4}，对应的maxfd是5，而不是4，就比较方便了。因为这个向量对应的是这样的：a[4],a[3],a[2],a[1],a[0]。待测试的描述符个数显然是5，而不是4。<br>　　三个描述符集合中的每一个都可以设置成空，这样就表示不需要内核进行相关的检测。最后一个参数是timeval结构体时间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct timeval </span><br><span class="line">&#123; </span><br><span class="line">long tv_sec; /* seconds */ </span><br><span class="line">long tv_usec; /* microseconds */ </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>　　这个参数设置成不同的值，会有不同的可能：第一个可能是设置成空(NULL)，表示如果没有I/O事件发生，则select一直等待下去。第二个可能是设置一个非零的值，这个表示等待固定的一段时间后从select阻塞调用中返回。第三个可能是将tv_sec和tv_usec都设置成0，表示根本不等待，检测完毕立即返回。这种情况使用得比较少。<br>　　select函数检测套接字可读有以下几种情况：第一种情况是套接字接收缓冲区有数据可以读，如果我们使用read函数去执行读操作，肯定不会被阻塞，而是会直接读到这部分数据。第二种情况是对方发送了FIN，使用read函数执行读操作，不会被阻塞，直接返回0。第三种情况是针对一个监听套接字而言的，有已经完成的连接建立，此时使用accept函数去执行不会阻塞，直接返回已经完成的连接。第四种情况是套接字有错误待处理，使用read函数去执行读操作，不阻塞，且返回-1。总结成一句话就是，内核通知我们套接字有数据可以读了，使用read函数不会阻塞。<br>　　select检测套接字可写，完全是基于套接字本身的特性来说的，具体来说有以下几种情况。第一种是套接字发送缓冲区足够大，如果我们使用非阻塞套接字进行write操作，将不会被阻塞，直接返回。第二种是连接的写半边已经关闭，如果继续进行写操作将会产生SIGPIPE信号。第三种是套接字上有错误待处理，使用write函数去执行写操作，不阻塞，且返回 -1。总结成一句话就是，内核通知我们套接字可以往里写了，使用write函数就不会阻塞。</p><h2 id="poll：另一种I-O多路复用"><a href="#poll：另一种I-O多路复用" class="headerlink" title="poll：另一种I/O多路复用"></a>poll：另一种I/O多路复用</h2><p>　　select方法是多个UNIX平台支持的非常常见的I/O多路复用技术，它通过描述符集合来表示检测的I/O对象，通过三个不同的描述符集合来描述I/O事件：可读、可写和异常。但是select有一个缺点，那就是所支持的文件描述符的个数是有限的。在Linux系统中，select的默认最大值为1024。<br>　　poll是除了select之外，另一种普遍使用的I/O多路复用技术，和select相比，它和内核交互的数据结构有所变化，另外，也突破了文件描述符的个数限制。下面是poll函数的原型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int poll(struct pollfd *fds, unsigned long nfds, int timeout);</span><br><span class="line">返回值：若有就绪描述符则为其数目，若超时则为 0，若出错则为 -1</span><br></pre></td></tr></table></figure><p>　　这个函数里面输入了三个参数，第一个参数是一个pollfd的数组。其中pollfd的结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct pollfd </span><br><span class="line">&#123; </span><br><span class="line">int fd; /* file descriptor */ </span><br><span class="line">short events; /* events to look for */ </span><br><span class="line">short revents; /* events returned */ </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>　　这个结构体由三个部分组成，首先是描述符fd，然后是描述符上待检测的事件类型events，注意这里的events可以表示多个不同的事件，具体的实现可以通过使用二进制掩码位操作来完成，例如，POLLIN和POLLOUT可以表示读和写事件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define POLLIN 0x0001 /* any readable data available */ </span><br><span class="line">#define POLLPRI 0x0002 /* OOB/Urgent readable data */ </span><br><span class="line">#define POLLOUT 0x0004 /* file descriptor is writeable */</span><br></pre></td></tr></table></figure><p>　　和select非常不同的地方在于，poll每次检测之后的结果不会修改原来的传入值，而是将结果保留在revents字段中，这样就不需要每次检测完都得重置待检测的描述字和感兴趣的事件。我们可以把revents理解成“returned events”。<br>　　events类型的事件可以分为两大类。第一类是可读事件，有以下几种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define POLLIN 0x0001 /* any readable data available */ </span><br><span class="line">#define POLLPRI 0x0002 /* OOB/Urgent readable data */ </span><br><span class="line">#define POLLRDNORM 0x0040 /* non-OOB/URG data available */ </span><br><span class="line">#define POLLRDBAND 0x0080 /* OOB/Urgent readable data */</span><br></pre></td></tr></table></figure><p>　　一般我们在程序里面有POLLIN即可。套接字可读事件和select的readset基本一致，是系统内核通知应用程序有数据可以读，通过read函数执行操作不会被阻塞。<br>　　第二类是可写事件，有以下几种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define POLLOUT 0x0004 /* file descriptor is writeable */ </span><br><span class="line">#define POLLWRNORM POLLOUT /* no write type differentiation */ </span><br><span class="line">#define POLLWRBAND 0x0100 /* OOB/Urgent data can be written */</span><br></pre></td></tr></table></figure><p>　　一般我们在程序里面统一使用POLLOUT。套接字可写事件和select的writeset基本一致，是系统内核通知套接字缓冲区已准备好，通过write函数执行写操作不会被阻塞。以上两大类的事件都可以在“returned events”得到复用。还有另一大类事件，没有办法通过poll向系统内核递交检测请求，只能通过“returned events”来加以检测，这类事件是各种错误事件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define POLLERR 0x0008 /* 一些错误发送 */ </span><br><span class="line">#define POLLHUP 0x0010 /* 描述符挂起 */ </span><br><span class="line">#define POLLNVAL 0x0020 /* 请求的事件无效 */</span><br></pre></td></tr></table></figure><p>　　我们再回过头看一下poll函数的原型。参数nfds描述的是数组fds的大小，简单说，就是向poll申请的事件检测的个数。最后一个参数timeout，描述了poll的行为。如果是一个小于0的数，表示在有事件发生之前永远等待；如果是0，表示不阻塞进程，立即返回；如果是一个大于0的数，表示poll调用方等待指定的毫秒数后返回。关于返回值，当有错误发生时，poll函数的返回值为-1；如果在指定的时间到达之前没有任何事件发生，则返回0，否则就返回检测到的事件个数，也就是“returned events”中非0的描述符个数。<br>　　poll函数有一点非常好，如果我们不想对某个pollfd结构进行事件检测，可以把它对应的pollfd结构的fd成员设置成一个负值。这样，poll函数将忽略这样的events事件，检测完成以后，所对应的“returned events”的成员值也将设置为0。和select函数对比一下，我们发现poll函数和select不一样的地方就是，在select里面，文件描述符的个数已经随着fd_set的实现而固定，没有办法对此进行配置；而在poll函数里，我们可以控制pollfd结构的数组大小，这意味着我们可以突破原来select函数最大描述符的限制，在这种情况下，应用程序调用者需要分配pollfd数组并通知poll函数该数组的大小。<br>　　poll是另一种在各种UNIX系统上被广泛支持的I/O多路复用技术，虽然名声没有select那么响，能力一点不比select差，而且因为可以突破select文件描述符的个数限制，在高并发的场景下尤其占优势。</p><h1 id="非阻塞I-O"><a href="#非阻塞I-O" class="headerlink" title="非阻塞I/O"></a>非阻塞I/O</h1><p>　　当应用程序调用阻塞I/O完成某个操作时，应用程序会被挂起，等待内核完成操作，感觉应用程序像是被“阻塞”了一样。实际上，内核所做的事情是将CPU时间切换给其他有需要的进程，网络应用程序在这种情况下就会得不到CPU时间做该做的事情。非阻塞I/O则不然，当应用程序调用非阻塞I/O完成某个操作时，内核立即返回，不会把CPU时间切换给其他进程，应用程序在返回后，可以得到足够的CPU时间继续完成其他事情。</p><h2 id="非阻塞I-O读操作"><a href="#非阻塞I-O读操作" class="headerlink" title="非阻塞I/O读操作"></a>非阻塞I/O读操作</h2><p>　　如果套接字对应的接收缓冲区没有数据可读，在非阻塞情况下read调用会立即返回，一般返回EWOULDBLOCK或EAGAIN出错信息。在这种情况下，出错信息是需要小心处理，比如后面再次调用read操作，而不是直接作为错误直接返回。这就好像去书店买书没买到离开一样，需要不断进行又一次轮询处理。</p><h2 id="非阻塞I-O写操作"><a href="#非阻塞I-O写操作" class="headerlink" title="非阻塞I/O写操作"></a>非阻塞I/O写操作</h2><p>　　在阻塞I/O情况下，write函数返回的字节数，和输入的参数总是一样的。而在非阻塞I/O的情况下，如果套接字的发送缓冲区已达到了极限，不能容纳更多的字节，那么操作系统内核会尽最大可能从应用程序拷贝数据到发送缓冲区中，并立即从write等函数调用中返回。可想而知，在拷贝动作发生的瞬间，有可能一个字符也没拷贝，有可能所有请求字符都被拷贝完成，那么这个时候就需要返回一个数值，告诉应用程序到底有多少数据被成功拷贝到了发送缓冲区中，应用程序需要再次调用write函数，以输出未完成拷贝的字节。<br>　　write等函数是可以同时作用到阻塞I/O和非阻塞I/O上的，为了复用一个函数，处理非阻塞和阻塞I/O多种情况，设计出了写入返回值，并用这个返回值表示实际写入的数据大小。也就是说，非阻塞I/O和阻塞I/O处理的方式是不一样的。非阻塞I/O需要这样：拷贝→返回→再拷贝→再返回。而阻塞I/O需要这样：拷贝→直到所有数据拷贝至发送缓冲区完成→返回。不过在实战中，可以不用区别阻塞和非阻塞I/O，使用循环的方式来写入数据就好了。只不过在阻塞I/O的情况下，循环只执行一次就结束了。<br>　　下面通过一张表来总结一下read和write在阻塞模式和非阻塞模式下的不同行为特性：</p><p>　　关于read和write还有几个结论:<br>　　1.read总是在接收缓冲区有数据时就立即返回，不是等到应用程序给定的数据充满才返回。当接收缓冲区为空时，阻塞模式会等待，非阻塞模式立即返回-1，并有EWOULDBLOCK或EAGAIN错误。<br>　　2.和read不同，阻塞模式下，write只有在发送缓冲区足以容纳应用程序的输出字节时才返回；而非阻塞模式下，则是能写入多少就写入多少，并返回实际写入的字节数。<br>　　3.阻塞模式下的write有个特例，就是对方主动关闭了套接字，这个时候write调用会立即返回，并通过返回值告诉应用程序实际写入的字节数，如果再次对这样的套接字进行write操作，就会返回失败。失败是通过返回值-1来通知到应用程序的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;I-O多路复用&quot;&gt;&lt;a href=&quot;#I-O多路复用&quot; class=&quot;headerlink&quot; title=&quot;I/O多路复用&quot;&gt;&lt;/a&gt;I/O多路复用&lt;/h1&gt;&lt;p&gt;　　我们假设设计了这样一个应用程序，该程序从标准输入接收数据输入，然后通过套接字发送出去，同时，该程
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="网络编程" scheme="https://liuruijie87.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>网络编程学习笔记（三）--数据传输、报文读取</title>
    <link href="https://liuruijie87.github.io/2020/06/01/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89--%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E3%80%81%E6%8A%A5%E6%96%87%E8%AF%BB%E5%8F%96/"/>
    <id>https://liuruijie87.github.io/2020/06/01/网络编程学习笔记（三）--数据传输、报文读取/</id>
    <published>2020-06-01T05:00:59.376Z</published>
    <updated>2020-06-01T05:03:39.156Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TIME-WAIT相关理解"><a href="#TIME-WAIT相关理解" class="headerlink" title="TIME_WAIT相关理解"></a>TIME_WAIT相关理解</h1><h2 id="TIME-WAIT发生的场景"><a href="#TIME-WAIT发生的场景" class="headerlink" title="TIME_WAIT发生的场景"></a>TIME_WAIT发生的场景</h2><p>　　应用服务需要通过发起TCP连接对外提供服务。每个连接会占用一个本地端口，当在高并发的情况下，TIME_WAIT状态的连接过多，多到把本机可用的端口耗尽，应用服务对外表现的症状，就是不能正常工作了。当过了一段时间之后，处于TIME_WAIT的连接被系统回收并关闭后，释放出本地端口可供使用，应用服务对外表现为可以正常工作。这样周而复始，便会出现了一会儿不可以，过一两分钟又可以正常工作的现象。<br>　　至于为什么会产生这么多的TIME_WAIT连接，这要从TCP的四次挥手说起。先来回顾一下四次挥手的过程，如下图。</p><img src="/2020/06/01/网络编程学习笔记（三）--数据传输、报文读取/1_四次挥手.jpg"><p>　　TCP连接终止时，主机1先发送FIN报文，主机2进入CLOSE_WAIT状态，并发送一个ACK应答，同时，主机2通过read调用获得EOF，并将此结果通知应用程序进行主动关闭操作，发送FIN报文。主机1在接收到FIN报文后发送ACK应答，此时主机1进入TIME_WAIT状态。主机1在TIME_WAIT停留持续时间是固定的，是最长分节生命期MSL（maximum segment lifetime）的两倍，一般称之为2MSL。和大多数BSD派生的系统一样，Linux系统里有一个硬编码的字段，名称为TCP_TIMEWAIT_LEN，其值为60秒。也就是说，Linux系统停留在TIME_WAIT的时间为固定的60秒。一定要记住，只有发起连接终止的一方会进入TIME_WAIT状态。</p><h2 id="TIME-WAIT的作用"><a href="#TIME-WAIT的作用" class="headerlink" title="TIME_WAIT的作用"></a>TIME_WAIT的作用</h2><p>　　为什么不直接进入CLOSED状态，而要停留在TIME_WAIT这个状态？这要从两个方面来说。<br>　　首先，这样做是为了确保最后的ACK能让被动关闭方接收，从而帮助其正常关闭。TCP在设计的时候，做了充分的容错性设计，比如，TCP假设报文会出错，需要重传。在这里，如果图中主机1的ACK报文没有传输成功，那么主机2就会重新发送FIN报文。如果主机1没有维护TIME_WAIT状态，而直接进入CLOSED状态，它就失去了当前状态的上下文，只能回复一个RST操作，从而导致被动关闭方出现错误。现在主机1知道自己处于TIME_WAIT的状态，就可以在接收到FIN报文之后，重新发出一个ACK报文，使得主机2可以进入正常的CLOSED状态。<br>　　第二个理由和连接“化身”和报文迷走有关系，为了让旧连接的重复分节在网络中自然消失。我们知道，在网络中，经常会发生报文经过一段时间才能到达目的地的情况，产生的原因是多种多样的，如路由器重启，链路突然出现故障等。如果迷走报文到达时，发现TCP连接四元组（源IP，源端口，目的IP，目的端口）所代表的连接不复存在，那么很简单，这个报文自然丢弃。我们考虑这样一个场景，在原连接中断后，又重新创建了一个原连接的“化身”，说是化身，其实是因为这个连接和原先的连接四元组完全相同，如果迷失报文经过一段时间也到达，那么这个报文会被误认为是新连接的一个TCP分节，这样就会对TCP通信产生影响。所以，TCP就设计出了这么一个机制，在一个连接之内，经过2MSL这个时间，足以让两个方向上的所有分组都被丢弃，使得原来连接的分组在网络中都自然消失，再出现的分组一定都是新化身所产生的。<br>　　要注意，2MSL的时间是从主机1接收到FIN后发送ACK开始计时的，如果在TIME_WAIT时间内，因为主机1的ACK没有传输到主机2，主机1又接收到了主机2重发的FIN报文，那么2MSL时间将重新计时。道理很简单，因为2MSL的时间，目的是为了让旧连接的所有报文都能自然消亡，现在主机1重新发送了ACK报文，自然需要重新计时，以便防止这个ACK报文对新可能的连接化身造成干扰。</p><h2 id="TIME-WAIT的危害与优化"><a href="#TIME-WAIT的危害与优化" class="headerlink" title="TIME_WAIT的危害与优化"></a>TIME_WAIT的危害与优化</h2><p>　　过多的TIME_WAIT的主要危害有两种。第一是内存资源占用，这个目前看来不是太严重，基本可以忽略。第二是对端口资源的占用，一个TCP连接至少消耗一个本地端口。要知道，端口资源也是有限的，一般可以开启的端口为32768～61000，也可以通过net.ipv4.ip_local_po rt_range指定，如果TIME_WAIT状态过多，会导致无法创建新连接。<br>　　那么如何优化TIME_WAIT呢？可以通过net.ipv4.tcp_tw_reuse选项，主要有两点：（1）只适用于连接发起方（C/S模型中的客户端）；（2）对应的TIME_WAIT状态的连接创建时间超过1秒才可以被复用。使用这个选项，还有一个前提，需要打开对TCP时间戳的支持，即net.ipv4.tcp_time stamps=1（默认即为1）。<br>　　要知道，TCP协议也在与时俱进，RFC1323中实现了TCP拓展规范，以便保证TCP的高可用，并引入了新的TCP选项，两个4字节的时间戳字段，用于记录TCP发送方的当前时间戳和从对端接收到的最新时间戳。由于引入了时间戳，前面提到的2MSL问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。</p><h1 id="TCP的一些机制"><a href="#TCP的一些机制" class="headerlink" title="TCP的一些机制"></a>TCP的一些机制</h1><h2 id="TCP的保持活跃机制"><a href="#TCP的保持活跃机制" class="headerlink" title="TCP的保持活跃机制"></a>TCP的保持活跃机制</h2><p>　　TCP有一个保持活跃的机制叫做Keep-Alive。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的TCP连接已经死亡，系统内核将错误信息通知给上层应用程序。上述的可定义变量，分别被称为保活时间、保活时间间隔和保活探测次数。在Linux系统中，这些变量分别对应sysctl变量net.ipv4.tcp_keepalive_time、net.ipv4.tcp_keepalive_intvl、net.ipv4.tcp_keepalve_probes，默认设置是7200秒（2小时）、75秒和9次探测。<br>　　如果开启了TCP保活，需要考虑以下几种情况：第一种，对端程序是正常工作的。当TCP保活的探测报文发送给对端，对端会正常响应，这样TCP保活时间会被重置，等待下一个TCP保活时间的到来。第二种，对端程序崩溃并重启。当TCP保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个RST报文，这样很快就会发现TCP连接已经被重置。第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当TCP保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP会报告该TCP连接已经死亡。<br>　　TCP保活机制默认是关闭的，当我们选择打开时，可以分别在连接的两个方向上开启，也可以单独在一个方向上开启。如果开启服务器端到客户端的检测，就可以在客户端非正常断连的情况下清除在服务器端保留的“脏数据”；而开启客户端到服务器端的检测，就可以在服务器无响应的情况下，重新发起连接。<br>　　如果使用TCP自身的keep-Alive机制，在Linux系统中，最少需要经过2小时11分15秒才可以发现一个“死亡”连接。这个时间是怎么计算出来的呢？其实是通过2小时，加上75秒乘以9的总和。实际上，对很多对时延要求敏感的系统中，这个时间间隔是不可接受的。所以，必须在应用程序这一层来寻找更好的解决方案。我们可以通过在应用程序中模拟TCP的Keep-Alive机制，来完成在应用层的连接探活。我们可以设计一个PING-PONG的机制，需要保活的一方，比如客户端，在保活时间达到后，发起对连接的PING操作，如果服务器端对PING操作有回应，则重新设置保活时间，否则对探测次数进行计数，如果最终探测次数达到了保活探测次数预先设置的值之后，则认为连接已经无效。这里有两个比较关键的点：第一个是需要使用定时器，这可以通过使用I/O复用自身的机制来实现；第二个是需要设计一个PING-PONG的协议。</p><h2 id="理解TCP协议中的动态数据传输"><a href="#理解TCP协议中的动态数据传输" class="headerlink" title="理解TCP协议中的动态数据传输"></a>理解TCP协议中的动态数据传输</h2><h3 id="从TCP角度看待数据流的发送和接收"><a href="#从TCP角度看待数据流的发送和接收" class="headerlink" title="从TCP角度看待数据流的发送和接收"></a>从TCP角度看待数据流的发送和接收</h3><p>　　我们已经熟悉如何通过套接字发送数据，比如使用write或者send方法来进行数据流的发送。我们已经知道，调用这些接口并不意味着数据被真正发送到网络上，其实，这些数据只是从应用程序中被拷贝到了系统内核的套接字缓冲区中，或者说是发送缓冲区中，等待协议栈的处理。至于这些数据是什么时候被发送出去的，对应用程序来说，是无法预知的。对这件事情真正负责的，是运行于操作系统内核的TCP协议栈实现模块。　　</p><h3 id="流量控制和生产者-消费者模型"><a href="#流量控制和生产者-消费者模型" class="headerlink" title="流量控制和生产者-消费者模型"></a>流量控制和生产者-消费者模型</h3><p>　　我们可以把理想中的TCP协议可以想象成一队运输货物的货车，运送的货物就是TCP数据包，这些货车将数据包从发送端运送到接收端，就这样不断周而复始。我们仔细想一下，货物达到接收端之后，是需要卸货处理、登记入库的，接收端限于自己的处理能力和仓库规模，是不可能让这队货车以不可控的速度发货的。接收端肯定会和发送端不断地进行信息同步，比如接收端通知发送端：“后面那20车你给我等等，等我这里腾出地方你再继续发货。”其实这就是发送窗口和接收窗口的本质，我们把这个叫做“TCP的生产者-消费者”模型。发送窗口和接收窗口是TCP连接的双方，一个作为生产者，一个作为消费者，为了达到一致协同的生产-消费速率、而产生的算法模型实现。说白了，作为TCP发送端，也就是生产者，不能忽略TCP的接收端，也就是消费者的实际状况，不管不顾地把数据包都传送过来。如果都传送过来，消费者来不及消费，必然会丢弃；而丢弃反过使得生产者又重传，发送更多的数据包，最后导致网络崩溃。<br>　　TCP的生产者-消费者模型，只是在考虑单个连接的数据传递，但是，TCP数据包是需要经过网卡、交换机、核心路由器等一系列的网络设备的，网络设备本身的能力也是有限的，当多个连接的数据包同时在网络上传送时，势必会发生带宽争抢、数据丢失等，这样，TCP就必须考虑多个连接共享在有限的带宽上，兼顾效率和公平性的控制，这就是拥塞控制的本质。举个形象一点的例子，有一个货车行驶在半夜三点的大路上，这样的场景是断然不需要拥塞控制的。我们可以把网络设备形成的网络信息高速公路和生活中实际的高速公路做个对比。正是因为有多个TCP连接，形成了高速公路上的多队运送货车，高速公路上开始变得熙熙攘攘，这个时候，就需要拥塞控制的接入了。在TCP协议中，拥塞控制是通过拥塞窗口来完成的，拥塞窗口的大小会随着网络状况实时调整。拥塞控制常用的算法有“慢启动”，它通过一定的规则，慢慢地将网络发送数据的速率增加到一个阈值。超过这个阈值之后，慢启动就结束了，另一个叫做“拥塞避免”的算法登场。在这个阶段，TCP会不断地探测网络状况，并随之不断调整拥塞窗口的大小。<br>　　现在我们可以发现，在任何一个时刻，TCP发送缓冲区的数据是否能真正发送出去，至少取决于两个因素，一个是当前的发送窗口大小，另一个是拥塞窗口大小，而TCP协议中总是取两者中最小值作为判断依据。比如当前发送的字节为100，发送窗口的大小是200，拥塞窗口的大小是80，那么取200和80中的最小值，就是80，当前发送的字节数显然是大于拥塞窗口的，结论就是不能发送出去。这里千万要分清楚发送窗口和拥塞窗口的区别。发送窗口反应了作为单TCP连接、点对点之间的流量控制模型，它是需要和接收端一起共同协调来调整大小的；而拥塞窗口则是反应了作为多个TCP连接共享带宽的拥塞控制模型，它是发送端独立地根据网络状况来动态调整的。</p><h3 id="服务器端程序重启时，地址被占用的原因和解决方法。"><a href="#服务器端程序重启时，地址被占用的原因和解决方法。" class="headerlink" title="服务器端程序重启时，地址被占用的原因和解决方法。"></a>服务器端程序重启时，地址被占用的原因和解决方法。</h3><p>　　我们已经知道，网络编程中，服务器程序需要绑定本地地址和一个端口，然后就监听在这个地址和端口上，等待客户端连接的到来。在实战中，可能会经常碰到一个问题，当服务器端程序重启之后，总是碰到“Address in use”的报错信息，服务器程序不能很快地重启。那么这个问题是如何产生的？我们又该如何避免呢？我们从一个TCP服务器端程序开始说起：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">static int count; </span><br><span class="line">static void sig_int(int signo) </span><br><span class="line">&#123; </span><br><span class="line">printf(&quot;\nreceived %d datagrams\n&quot;, count); </span><br><span class="line">exit(0); </span><br><span class="line">&#125; </span><br><span class="line">int main(int argc, char **argv) </span><br><span class="line">&#123; </span><br><span class="line">int listenfd; </span><br><span class="line">listenfd = socket(AF_INET, SOCK_STREAM, 0); </span><br><span class="line">struct sockaddr_in server_addr; </span><br><span class="line">bzero(&amp;server_addr, sizeof(server_addr)); </span><br><span class="line">server_addr.sin_family = AF_INET; </span><br><span class="line">server_addr.sin_addr.s_addr = htonl(INADDR_ANY); </span><br><span class="line">server_addr.sin_port = htons(SERV_PORT); </span><br><span class="line">int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr)); </span><br><span class="line">if(rt1 &lt; 0) </span><br><span class="line">&#123; </span><br><span class="line">error(1, errno, &quot;bind failed &quot;);</span><br><span class="line">&#125; </span><br><span class="line">int rt2 = listen(listenfd, LISTENQ); </span><br><span class="line">if (rt2 &lt; 0) </span><br><span class="line">&#123; </span><br><span class="line">error(1, errno, &quot;listen failed &quot;); </span><br><span class="line">&#125; </span><br><span class="line">signal(SIGPIPE, SIG_IGN);</span><br><span class="line">int connfd; struct sockaddr_in client_addr; </span><br><span class="line">socklen_t client_len = sizeof(client_addr); </span><br><span class="line">if((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) </span><br><span class="line">&#123;</span><br><span class="line">error(1, errno, &quot;bind failed &quot;); </span><br><span class="line">&#125; </span><br><span class="line">char message[MAXLINE]; </span><br><span class="line">count = 0; </span><br><span class="line">for(;;) </span><br><span class="line">&#123; </span><br><span class="line">int n = read(connfd, message, MAXLINE); </span><br><span class="line">if(n &lt; 0) </span><br><span class="line">&#123;</span><br><span class="line">error(1, errno, &quot;error read&quot;);</span><br><span class="line">&#125; </span><br><span class="line">else if(n == 0) </span><br><span class="line">&#123;</span><br><span class="line">error(1, 0, &quot;client closed \n&quot;); </span><br><span class="line">&#125; </span><br><span class="line">message[n] = 0; </span><br><span class="line">printf(&quot;received %d bytes: %s\n&quot;, n, message);</span><br><span class="line">count++; </span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　这个服务器端程序绑定到一个本地端口，使用的是通配地址ANY，当连接建立之后，从该连接中读取输入的字符流。启动服务器，之后我们使用Telnet登录这个服务器，并在屏幕上输入一些字符，例如：network，good。和我们期望的一样，服务器端打印出Telnet客户端的输入。在Telnet端关闭连接之后，服务器端接收到EOF，也顺利地关闭了连接。服务器端也可以很快重启，等待新的连接到来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$./addressused </span><br><span class="line">received 9 bytes: network </span><br><span class="line">received 6 bytes: good </span><br><span class="line">client closed </span><br><span class="line">$./addressused</span><br></pre></td></tr></table></figure><p>　　接下来，我们改变一下连接的关闭顺序。和前面的过程一样，先启动服务器，再使用Telnet作为客户端登录到服务器，在屏幕上输入一些字符。注意接下来的不同，不在Telnet端关闭连接，而是直接使用Ctrl+C的方式在服务器端关闭连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$telneet 127.0.0.1 9527 </span><br><span class="line">network </span><br><span class="line">bad </span><br><span class="line">Connection closed by foreign host.</span><br></pre></td></tr></table></figure><p>　　我们看到，连接已经被关闭，Telnet客户端也感知连接关闭并退出了。接下来，我们尝试重启服务器端程序。你会发现，这个时候服务端程序重启失败，报错信息为：bind failed: Address already in use。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$./addressused </span><br><span class="line">received 9 bytes: network</span><br><span class="line">received 6 bytes: good </span><br><span class="line">client closed </span><br><span class="line">$./addressused </span><br><span class="line">bind faied: Address already in use(98)</span><br></pre></td></tr></table></figure><p>　　此时我们想到了TIME_WAIT，当连接的一方主动关闭连接，在接收到对端的FIN报文之后，主动关闭连接的一方会在TIME_WAIT这个状态里停留一段时间，这个时间大约为2MSL。如果我们此时使用netstat去查看服务器程序所在主机的TIME_WAIT的状态连接，你会发现有一个服务器程序生成的TCP连接，当前正处于TIME_WAIT状态。通过服务器端发起的关闭连接操作，引起了一个已有的TCP连接处于TME_WAIT状态，正是这个TIME_WAIT的连接，使得服务器重启时，继续绑定在127.0.0.1地址和9527端口上的操作，返回了Address already in use的错误。</p><h3 id="重用套接字选项"><a href="#重用套接字选项" class="headerlink" title="重用套接字选项"></a>重用套接字选项</h3><p>　　我们知道，一个TCP连接是通过四元组（源地址、源端口、目的地址、目的端口）来唯一确定的，如果每次Telnet客户端使用的本地端口都不同，就不会和已有的四元组冲突，也就不会有TIME_WAIT的新旧连接化身冲突的问题。事实上，即使在很小的概率下，客户端Telnet使用了相同的端口，从而造成了新连接和旧连接的四元组相同，在现代Linux操作系统下，也不会有什么大的问题，原因是现代Linux操作系统对此进行了一些优化。第一种优化是新连接SYN告知的初始序列号，一定比TIME_WAIT老连接的末序列号大，这样通过序列号就可以区别出新老连接。第二种优化是开启了tcp_timestamps，使得新连接的时间戳比老连接的时间戳大，这样通过时间戳也可以区别出新老连接。在这样的优化之下，一个TIME_WAIT的TCP连接可以忽略掉旧连接，重新被新的连接所使用。这就是重用套接字选项，通过给套接字配置可重用属性，告诉操作系统内核，这样的TCP连接完全可以复用TIME_WAIT状态的连接。代码片段如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int on = 1; </span><br><span class="line">setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on));</span><br></pre></td></tr></table></figure><p>　　SO_REUSEADDR套接字选项，允许启动绑定在一个端口，即使之前存在一个和该端口一样的连接。前面的例子已经表明，在默认情况下，服务器端历经创建socket、bind和listen。重启时，如果试图绑定到一个现有连接上的端口，bind操作会失败，但是如果我们在创建socket和bind之间，使用上面的代码片段设置SO_REUSEADDR套接字选项，情况就会不同。<br>　　SO_REUSEADDR套接字选项还有一个作用，那就是本机服务器如果有多个地址，可以在不同地址上使用相同的端口提供服务。比如，一台服务器有192.168.1.101和10.10.2.102两个地址，我们可以在这台机器上启动三个不同的HTTP服务，第一个以本地通配地址ANY和端口80启动；第二个以192.168.101和端口80启动；第三个以10.10.2.102和端口80启动。这样目的地址为192.168.101，目的端口为80的连接请求会被发往第二个服务；目的地址为10.10.2.102，目的端口为80的连接请求会被发往第三个服务；目的端口为80的所有其他连接请求被发往第一个服务。我们必须给这三个服务设置SO_REUSEADDR套接字选项，否则第二个和第三个服务调用bind绑定到80端口时会出错。总之，可以总结成一句话：服务器端程序，都应该设置SO_REUSEADDR套接字选项，以便服务端程序可以在极短时间内复用同一个端口启动。<br>　　有人可能觉得这不是安全的。其实，单独重用一个套接字不会有任何问题。我们已经知道，TCP连接是通过四元组唯一区分的，只要客户端不使用相同的源端口，连接服务器是没有问题的，即使使用了相同的端口，根据序列号或者时间戳，也是可以区分出新旧连接的。而且，TCP的机制绝对不允许在相同的地址和端口上绑定不同的服务器，即使我们设置SO_REUSEADDR套接字选项，也不可能在ANY通配符地址下和端口9527上重复启动两个服务器实例。如果我们启动第二个服务器实例，不出所料会得到Address already in use的报错，即使当前还没有任何一条有效TCP连接产生。<br>　　那么tcp_tw_reuse的内核配置选项和SO_REUSEADDR套接字选项有什么区别呢？其实，这两个东西一点关系也没有。tcp_tw_reuse是内核选项，主要用在连接的发起方。TIME_WAIT状态的连接创建时间超过1秒后，新的连接才可以被复用，注意，这里是连接的发起方；SO_REUSEADDR是用户态的选项，SO_REUSEADDR选项用来告诉操作系统内核，如果端口已被占用，但是TCP连接状态位于TIME_WAIT，可以重用端口。如果端口忙，而TCP处于其他状态，重用端口时依旧得到“Address already in use”的错误信息。注意，这里一般都是连接的服务方。</p><h3 id="报文读取和解析"><a href="#报文读取和解析" class="headerlink" title="报文读取和解析"></a>报文读取和解析</h3><p>　　我们知道TCP的报文是以字节流的形式呈现给应用程序的，那么随之而来的一个问题就是，应用程序如何解读字节流呢？这就要说到报文格式和解析了。报文格式实际上定义了字节的组织形式，发送端和接收端都按照统一的报文格式进行数据传输和解析，这样就可以保证彼此能够完成交流。<br>　　报文格式最重要的是如何确定报文的边界。常见的报文格式有两种方法，一种是发送端把要发送的报文长度预先通过报文告知给接收端；另一种是通过一些特殊的字符来进行边界的划分。<br>　　显式编码报文长度，就是把要发送的报文长度预先通过报文告知接收端，如下图。</p><img src="/2020/06/01/网络编程学习笔记（三）--数据传输、报文读取/2_显式编码报文长度.jpg"><p>　　由图可以看出，这个报文的格式很简单，首先4个字节大小的消息长度，其目的是将真正发送的字节流的大小显式通过报文告知接收端，接下来是4个字节大小的消息类型，而真正需要发送的数据则紧随其后。<br>　　另外一种报文格式就是通过设置特殊字符作为报文边界。HTTP是一个非常好的例子。</p><img src="/2020/06/01/网络编程学习笔记（三）--数据传输、报文读取/3_HTTP格式.jpg"><p>　　HTTP通过设置回车符、换行符做为HTTP报文协议的边界。<br>　　由此看来，TCP数据流特性决定了字节流本身是没有边界的，一般我们通过显式编码报文长度的方式，以及选取特殊字符区分报文边界的方式来进行报文格式的设计。而对报文解析的工作就是要在知道报文格式的情况下，有效地对报文信息进行还原。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TIME-WAIT相关理解&quot;&gt;&lt;a href=&quot;#TIME-WAIT相关理解&quot; class=&quot;headerlink&quot; title=&quot;TIME_WAIT相关理解&quot;&gt;&lt;/a&gt;TIME_WAIT相关理解&lt;/h1&gt;&lt;h2 id=&quot;TIME-WAIT发生的场景&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="网络编程" scheme="https://liuruijie87.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>网络编程学习笔记（二）--连接与通信</title>
    <link href="https://liuruijie87.github.io/2020/05/25/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89--%E8%BF%9E%E6%8E%A5%E4%B8%8E%E9%80%9A%E4%BF%A1/"/>
    <id>https://liuruijie87.github.io/2020/05/25/网络编程学习笔记（二）--连接与通信/</id>
    <published>2020-05-25T01:24:43.091Z</published>
    <updated>2020-05-25T09:40:02.854Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用套接字格式建立连接"><a href="#使用套接字格式建立连接" class="headerlink" title="使用套接字格式建立连接"></a>使用套接字格式建立连接</h1><h2 id="服务端准备连接的过程"><a href="#服务端准备连接的过程" class="headerlink" title="服务端准备连接的过程"></a>服务端准备连接的过程</h2><p>　　一、创建套接字：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int socket(int domain, int type, int protocol);</span><br></pre></td></tr></table></figure><p>　　二、绑定地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bind(int fd, sockaddr * addr, socklen_t len);</span><br></pre></td></tr></table></figure><p>　　bind函数后面的第二个参数是通用地址格式sockaddr。这里有一个地方值得注意，那就是虽然接收的是通用地址格式，实际上传入的参数可能是IPv4、IPv6或者本地套接字格式。bind函数会根据len字段判断传入的参数addr该怎么解析，len字段表示的就是传入的地址长度，它是一个可变值。这里其实可以把bind函数理解成这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bind(int fd, void * addr, socklen_t len);</span><br></pre></td></tr></table></figure><p>　　不过BSD设计套接字的时候大约是1982年，那个时候的C语言还没有void指针的支持，为了解决这个问题，BSD的设计者们创造性地设计了通用地址格式来作为支持bind和accept等这些函数的参数。对于使用者来说，每次需要将IPv4、IPv6或者本地套接字格式转化为通用套接字格式，就像下面的IPv4套接字地址格式的例子一样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">struct sockaddr_in name; </span><br><span class="line">bind (sock, (struct sockaddr *) &amp;name, sizeof (name);</span><br></pre></td></tr></table></figure><p>　　设置bind的时候，对地址和端口可以有多种处理方式。我们可以把地址设置成本机的IP地址，这相当告诉操作系统内核，仅仅对目标IP是本机IP地址的IP包进行处理。但是这样写的程序在部署时有一个问题，我们编写应用程序时并不清楚自己的应用程序将会被部署到哪台机器上。这个时候，可以利用通配地址的能力帮助我们解决这个问题。<br>　　对于IPv4的地址来说，使用INADDR_ANY来完成通配地址的设置；对于IPv6的地址来说，使用IN6ADDR_ANY来完成通配地址的设置。如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">struct sockaddr_in name;</span><br><span class="line">name.sin_addr.s_addr = htonl (INADDR_ANY); /* IPV4 通配地址 */</span><br></pre></td></tr></table></figure><p>　　除了地址，还有端口。一般来说，服务器端的程序一定要绑定到一个众所周知的端口上。服务器端的IP地址和端口数据，相当于打电话拨号时需要知道的对方号码，如果没有电话号码，就没有办法和对方建立连接。<br>　　三、监听端口：<br>　　初始化创建的套接字，可以认为是一个”主动”套接字，其目的是之后主动发起请求（通过调用connect函数）。通过listen函数，可以将原来的”主动”套接字转换为”被动”套接字，告诉操作系统内核：“我这个套接字是用来等待用户请求的。”当然，操作系统内核会为此做好接收用户请求的一切准备，比如完成连接队列。listen函数的原型是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int listen (int socketfd, int backlog);</span><br></pre></td></tr></table></figure><p>　　第一个参数socketfd为套接字描述符，第二个参数backlog，官方的解释为未完成连接队列的大小，这个参数的大小决定了可以接收的并发数目。这个参数越大，并发数目理论上也会越大。但是参数过大也会占用过多的系统资源，一些系统，比如Linux并不允许对这个参数进行改变。<br>　　四、接收请求<br>　　当客户端的连接请求到达时，服务器端应答成功，连接建立，这个时候操作系统内核需要把这个事件通知到应用程序，并让应用程序感知到这个连接。accept这个函数的作用就是连接建立之后，操作系统内核和应用程序之间的桥梁。它的原型是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int accept(int listensockfd, struct sockaddr *cliaddr, socklen_t *addrlen);</span><br></pre></td></tr></table></figure><p>　　函数的第一个参数listensockfd是套接字，可以叫它为listen套接字，因为这就是前面通过bind，listen一系列操作而得到的套接字。函数的返回值有两个部分，第一个部分cliadd是通过指针方式获取的客户端的地址，addrlen告诉我们地址的大小。另一个部分是函数的返回值，这个返回值是一个全新的描述字，代表了与客户端的连接。这里一定要注意有两个套接字描述字，第一个是监听套接字描述字listensockfd，它是作为输入参数存在的；第二个是返回的已连接套接字描述字。为什么要把两个套接字分开呢？这是因为网络程序的一个重要特征就是并发处理，不可能一个应用程序运行之后只能服务一个客户，所以监听套接字一直都存在，它是要为成千上万的客户来服务的，直到这个监听套接字关闭；而一旦一个客户和服务器连接成功，完成了TCP三次握手，操作系统内核就为这个客户生成一个已连接套接字，让应用服务器使用这个已连接套接字和客户进行通信处理。如果应用服务器完成了对这个客户的服务，比如一次网购下单，一次付款成功，那么关闭的就是已连接套接字，这样就完成了TCP连接的释放。请注意，这个时候释放的只是这一个客户连接，其它被服务的客户连接可能还存在。最重要的是，监听套接字一直都处于“监听”状态，等待新的客户请求到达并服务。</p><h2 id="客户端发起连接的过程"><a href="#客户端发起连接的过程" class="headerlink" title="客户端发起连接的过程"></a>客户端发起连接的过程</h2><p>　　一、创建套接字：和服务端一样的做法。<br>　　二、connect:客户端和服务器端的连接建立，是通过connect函数完成的。这是connect的构建函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen);</span><br></pre></td></tr></table></figure><p>　　函数的第一个参数sockfd是连接套接字，通过前面讲述的socket函数创建。第二个、第三个参数servaddr和addrlen分别代表指向套接字地址结构的指针和该结构的大小。套接字地址结构必须含有服务器的IP地址和端口号。如果是TCP套接字，那么调用connect函数将激发TCP的三次握手过程，而且仅在连接建立成功或出错时才返回。其中出错返回可能有以下几种情况：<br>　　1.三次握手无法建立，客户端发出的SYN包没有任何响应，于是返回TIMEOUT错误。这种情况比较常见的原因是对应的服务端IP写错。<br>　　2.客户端收到了RST（复位）回答，这时候客户端会立即返回CONNECTION-REFUSED错误。这种情况比较常见于客户端发送连接请求时的请求端口写错，因为RST是TCP在发生错误时发送的一种TCP分节。产生RST的三个条件是：目的地为某端口的SYN到达，然而该端口上没有正在监听的服务器（如前所述）；TCP想取消一个已有连接；TCP接收到一个根本不存在的连接上的分节。<br>　　3.客户发出的SYN包在网络上引起了”destination-unreachable”，即目的不可达的错误。这种情况比较常见的原因是客户端和服务器端路由不通。</p><h2 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h2><img src="/2020/05/25/网络编程学习笔记（二）--连接与通信/1_TCP三次握手.jpg"><p>　　先看一下最初的过程，服务器端通过socket，bind和listen完成了被动套接字的准备工作，被动的意思就是等着别人来连接，然后调用accept，就会阻塞在这里，等待客户端的连接来临；客户端通过调用socket和connect函数之后，也会阻塞。接下来的事情是由操作系统内核完成的，更具体一点的说，是操作系统内核网络协议栈在工作。<br>　　下面是具体的过程：<br>　　1. 客户端的协议栈向服务器端发送了SYN包，并告诉服务器端当前发送序列号j，客户端进入SYNC_SENT状态；<br>　　2.服务器端的协议栈收到这个包之后，和客户端进行ACK应答，应答的值为j+1，表示对SYN包j的确认，同时服务器也发送一个SYN包，告诉客户端当前我的发送序列号为k，服务器端进入SYNC_RCVD状态；<br>　　3.客户端协议栈收到ACK之后，使得应用程序从connect调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为ESTABLISHED，同时客户端协议栈也会对服务器端的SYN包进行应答，应答数据为k+1；<br>　　4.应答包到达服务器端后，服务器端协议栈使得accept阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入ESTABLISHED状态。</p><h1 id="使用套接字进行读写"><a href="#使用套接字进行读写" class="headerlink" title="使用套接字进行读写"></a>使用套接字进行读写</h1><h2 id="发送数据"><a href="#发送数据" class="headerlink" title="发送数据"></a>发送数据</h2><p>　　发送数据时常用的有三个函数，分别是write、send和sendmsg。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssize_t write (int socketfd, const void *buffer, size_t size); </span><br><span class="line">ssize_t send (int socketfd, const void *buffer, size_t size, int flags); </span><br><span class="line">ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);</span><br></pre></td></tr></table></figure><p>　　每个函数都是单独使用的，使用的场景略有不同：第一个函数是常见的文件写函数，如果把socketfd换成文件描述符，就是普通的文件写入。如果想指定选项，发送带外数据，就需要使用第二个带flag的函数。所谓带外数据，是一种基于TCP协议的紧急数据，用于客户端-服务器在特定场景下的紧急处理。如果想指定多重缓冲区传输数据，就需要使用第三个函数，以结构体msghdr的方式发送数据。<br>　　当TCP三次握手成功，TCP连接成功建立后，操作系统内核会为每一个连接创建配套的基础设施，比如发送缓冲区。发送缓冲区的大小可以通过套接字选项来改变，当我们的应用程序调用write函数时，实际所做的事情是把数据从应用程序中拷贝到操作系统内核的发送缓冲区中，并不一定是把数据通过套接字写出去。这里有几种情况：第一种情况很简单，操作系统内核的发送缓冲区足够大，可以直接容纳这份数据，那么皆大欢喜，我们的程序从write调用中退出，返回写入的字节数就是应用程序的数据大小。第二种情况是，操作系统内核的发送缓冲区是够大了，不过还有数据没有发送完，或者数据发送完了，但是操作系统内核的发送缓冲区不足以容纳应用程序数据，在这种情况下，你预料的结果是什么呢？报错？还是直接返回？操作系统内核并不会返回，也不会报错，而是应用程序被阻塞，也就是说应用程序在write函数调用处停留，不直接返回。术语“挂起”也表达了相同的意思，不过“挂起”是从操作系统内核角度来说的。<br>　　那么什么时候才会返回呢？实际上，每个操作系统内核的处理是不同的。大部分UNIX系统的做法是一直等到可以把应用程序数据完全放到操作系统内核的发送缓冲区中，再从系统调用中返回。当TCP连接建立之后，它就开始运作起来。可以把发送缓冲区想象成一条包裹流水线，有个聪明且忙碌的工人不断地从流水线上取出包裹（数据），这个工人会按照TCP/IP的语义，将取出的包裹（数据）封装成TCP的MSS包，以及IP的MTU包，最后走数据链路层将数据发送出去。这样我们的发送缓冲区就又空了一部分，于是又可以继续从应用程序搬一部分数据到发送缓冲区里，这样一直进行下去，到某一个时刻，应用程序的数据可以完全放置到发送缓冲区里。在这个时候，write阻塞调用返回。注意返回的时刻，应用程序数据并没有全部被发送出去，发送缓冲区里还有部分数据，这部分数据会在稍后由操作系统内核通过网络发送出去。</p><img src="/2020/05/25/网络编程学习笔记（二）--连接与通信/2_发送数据.jpg"><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><p>　　read函数，这个函数的原型如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssize_t read (int socketfd, void *buffer, size_t size);</span><br></pre></td></tr></table></figure><p>　　read函数要求操作系统内核从套接字描述字socketfd读取最多多少个字节（size），并将结果存储到buffer中。返回值告诉我们实际读取的字节数目，也有一些特殊情况，如果返回值为0，表示EOF（end-of-file），这在网络中表示对端发送了FIN包，要处理断连的情况；如果返回值为-1，表示出错。当然，如果是非阻塞I/O，情况会略有不同。注意这里是最多读取size个字节。如果我们想让应用程序每次都读到size个字节，就需要编写下面的函数，不断地循环读取。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/* 从 socketfd 描述字中读取 &quot;size&quot; 个字节. */ </span><br><span class="line">ssize_t readn(int fd, void *vptr, size_t size) </span><br><span class="line">&#123; </span><br><span class="line">size_t nleft; ssize_t nread; </span><br><span class="line">char *ptr; </span><br><span class="line">ptr = vptr; </span><br><span class="line">nleft = size; </span><br><span class="line">while (nleft &gt; 0) </span><br><span class="line">&#123; </span><br><span class="line">if ( (nread = read(fd, ptr, nleft)) &lt; 0) </span><br><span class="line">&#123; </span><br><span class="line">if (errno == EINTR) </span><br><span class="line">nread = 0; /* 这里需要再次调用 read */ </span><br><span class="line">else </span><br><span class="line">return(-1); </span><br><span class="line">&#125; </span><br><span class="line">else if (nread == 0) </span><br><span class="line">break; /* EOF(End of File) 表示套接字关闭 */ </span><br><span class="line">nleft -= nread; </span><br><span class="line">ptr += nread; </span><br><span class="line">&#125; </span><br><span class="line">return(n - nleft); /* 返回的是实际读取的字节数 */ </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　需要注意：<br>　　1、阻塞式套接字最终发送返回的实际写入字节数和请求字节数是相等的。<br>　　2、发送成功仅仅表示的是数据被拷贝到了发送缓冲区中，并不意味着连接对端已经收到所有的数据。至于什么时候发送到对端的接收缓冲区，或者更进一步说，什么时候被对方应用程序缓冲所接收，对我们而言完全都是透明的。<br>　　3、对于send来说，返回成功仅仅表示数据写到发送缓冲区成功，并不表示对端已经成功收到。对于read来说，需要循环读取数据，并且需要考虑EOF等异常条件。</p><h1 id="UDP编程的情况"><a href="#UDP编程的情况" class="headerlink" title="UDP编程的情况"></a>UDP编程的情况</h1><p>　　<br>　　UDP和TCP编程非常不同，下面这张图是UDP程序设计时的主要过程。</p><img src="/2020/05/25/网络编程学习笔记（二）--连接与通信/3_UDP编程.jpg"><p>　　可以看到服务器端创建UDP套接字之后，绑定到本地端口，调用recvfrom函数等待客户端的报文发送；客户端创建套接字之后，调用sendto函数往目标地址和端口发送UDP报文，然后客户端和服务器端进入互相应答过程。recvfrom和sendto是UDP用来接收和发送报文的两个主要函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssize_t recvfrom(int sockfd, void *buff, size_t nbytes, int flags, struct sockaddr *from, socklen_t *addrlen); </span><br><span class="line">ssize_t sendto(int sockfd, const void *buff, size_t nbytes, int flags, const struct sockaddr *to, socklen_t *addrlen);</span><br></pre></td></tr></table></figure><p>　　先来看一下recvfrom函数，sockfd、buff和nbytes是前三个参数。sockfd是本地创建的套接字描述符，buff指向本 地的缓存，nbytes表示最大接收数据字节。第四个参数flags是和I/O相关的参数，这里我们还用不到，设置为0。后面两个参数from和addrlen，实际上是返回对端发送方的地址和端口等信息，这和TCP非常不一样，TCP是通过accept函数拿到的描述字信息来决定对端的信息。另外UDP报文每次接收都会获取对端的信息，也就是说报文和报文之间是没有上下文的。函数的返回值告诉我们实际接收的字节数。<br>　　接下来看一下sendto函数。sendto函数中的前三个参数为sockfd、buff和nbytes。sockfd是本地创建的套接字描述符，buff指向发送的缓存，nbytes表示发送字节数。第四个参数flags依旧设置为0。后面两个参数to和addrlen，表示发送的对端地址和端口等信息。函数的返回值告诉我们实际接收的字节数。<br>　　UDP是无连接的数据报程序，和TCP不同，不需要三次握手建立一条连接。UDP程序通过recvfrom和sendto函数直接收发数据报报文。</p><h1 id="本地套接字"><a href="#本地套接字" class="headerlink" title="本地套接字"></a>本地套接字</h1><p>　　实际上，本地套接字是IPC，也就是本地进程间通信的一种实现方式。除了本地套接字以外，其它技术，诸如管道、共享消息队列等也是进程间通信的常用方法，但因为本地套接字开发便捷，接受度高，所以普遍适用于在同一台主机上进程间通信的各种场景。<br>　　本地套接字是一种特殊类型的套接字，和TCP/UDP套接字不同。TCP/UDP即使在本地地址通信，也要走系统网络协议栈，而本地套接字，严格意义上说提供了一种单主机跨进程间调用的手段，减少了协议栈实现的复杂度，效率比TCP/UDP套接字都要高许多。类似的IPC机制还有UNIX管道、共享内存和RPC调用等。<br>　　本地字节流套接字和TCP服务器端、客户端编程最大的差异就是套接字类型的不同。本地字节流套接字识别服务器不再通过IP地址和端口，而是通过本地文件。本地套接字的编程接口和IPv4、IPv6套接字编程接口是一致的，可以支持字节流和数据报两种协议。本地套接字的实现效率大大高于IPv4和IPv6的字节流、数据报套接字实现。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用套接字格式建立连接&quot;&gt;&lt;a href=&quot;#使用套接字格式建立连接&quot; class=&quot;headerlink&quot; title=&quot;使用套接字格式建立连接&quot;&gt;&lt;/a&gt;使用套接字格式建立连接&lt;/h1&gt;&lt;h2 id=&quot;服务端准备连接的过程&quot;&gt;&lt;a href=&quot;#服务端准备连接
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="网络编程" scheme="https://liuruijie87.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>网络编程学习笔记（一）--几种概念</title>
    <link href="https://liuruijie87.github.io/2020/05/23/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89--%E5%87%A0%E7%A7%8D%E6%A6%82%E5%BF%B5/"/>
    <id>https://liuruijie87.github.io/2020/05/23/网络编程学习笔记（一）--几种概念/</id>
    <published>2020-05-23T07:45:42.993Z</published>
    <updated>2020-05-23T12:58:59.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="客户端-服务端模型"><a href="#客户端-服务端模型" class="headerlink" title="客户端-服务端模型"></a>客户端-服务端模型</h1><p>　　<br>　　一个连接可以通过客户端-服务器端的IP和端口唯一确定，这叫做套接字对，按照下面的四元组表示：（clientaddr:clientport, serveraddr: serverport)。下图表示了一个客户端-服务器之间的连接：</p><img src="/2020/05/23/网络编程学习笔记（一）--几种概念/1_客户端-服务端模型.jpg"><h1 id="保留网段"><a href="#保留网段" class="headerlink" title="保留网段"></a>保留网段</h1><p>　　国际标准组织在IPv4地址空间里面，专门划出了一些网段，这些网段不会用做公网上的IP，而是仅仅保留做内部使用，我们把这些地址称作保留网段。下表是三个保留网段，其可以容纳的计算机主机个数分别是 16777216 个、1048576 个和 65536 个。</p><img src="/2020/05/23/网络编程学习笔记（一）--几种概念/2_保留网段.jpg"><h1 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h1><p>　　在网络IP划分的时候，我们需要区分两个概念。第一是网络（network）的概念，直观点说，它表示的是这组IP共同的部分，比如在192.168.1.1-192.168.1.255这个区间里，它们共同的部分是192.168.1.0。第二是主机（host）的概念，它表示的是这组IP不同的部分，上面的例子中1-255就是不同的那些部分，表示有255个可用的不同IP。例如IPv4地址，192.0.2.12，我们可以说前面三个bytes是子网，最后一个byte是host，或者换个方式，我们能说host为8位，子网掩码为192.0.2.0/24（255.255.255.0）。<br>　　很久以前，有子网（subnet）的分类，在这里，一个IPv4地址的第一个，前两个或前三个字节是属于网络的一部分。如果你很幸运地可以拥有一个字节的网络，而另外三个字节是host地址，那在你的网络里，你有价值三个字节，也就是24个比特的主机地址，这是什么概念呢？2的24次方，大约是一千六百万个地址左右。这是一个“Class A”（A 类）网络。<br>　　再来重新看一下保留网段的这张表格，表格第一行就是这样的一个A类网络，10是对应的网络字节部分，主机的字节是3，我们将一个字节的子网记作255.0.0.0。相对的，“ClassB”（B类）的网络，网络有两个字节，而host只有两个字节，也就是说拥有的主机个数为65536。“ClassC”（C类）的网络，网络有三个字节，而host只有一个字节，也就是说拥有的主机个数为256。<br>　　网络地址位数由子网掩码（Netmask）决定，你可以将IP地址与子网掩码进行“位与”操作，就能得到网络的值。子网掩码一般看起来像是255.255.255.0（二进制为11111111.11111111.11111111.00000000），比如你的IP是192.0.2.12，使用这个子网掩码时，你的网络就会是192.0.2.12与255.255.255.0所得到的值：192.0.2.0，192.0.2.0就是这个网络的值。<br>　　子网掩码能接受任意个位，而不单纯是上面讨论的8，16或24个比特而已。所以你可以有一个子网掩码255.255.255.252（二进制位11111111.11111111.11111111.11111100），这个子网掩码能切出一个30个位的网络以及2个位的主机，这个网络最多有四台host。为什么是4台host呢？因为不变的部分只有最后两位，所有的可能为2的2次方，即4台host。<br>　　注意，子网掩码的格式永远都是二进制格式：前面是一连串的1，后面跟着一连串的0。不过一大串的数字会有点不好用，比如像255.192.0.0这样的子网掩码，人们无法直观地知道有多少个1，多少个0，后来人们发明了新的办法，你只需要将一个斜线放在IP地址后面，接着用一个十进制的数字用以表示网络的位数，类似这样：192.0.2.12/30,这样就很容易知道有30个1，2个0，所以主机个数为4。<br>　　例如，从172.16.0.0/12这个IP中得出信息，172.16.0.0为B类网，12为网络号，默认B类网的网络号（也就是子网掩码中1的个数）是16位，而此处为12位，那么便有2^(16-12)=16个连续子网。而对于192.168.0.0/16，192.168.0.0为C类网，16为网络号，默认C类网的网络号是24位，而此处为16位，那么便有2^(24-16)=256个连续的子网。注意，这里说的子网是说网络，并不是说可连接的主机数。从以上的分析可以看出，子网掩码决定了不同类型网络中子网的个数。</p><h1 id="全球域名系统"><a href="#全球域名系统" class="headerlink" title="全球域名系统"></a>全球域名系统</h1><p>　　全球域名按照从大到小的结构，形成了一棵树状结构。实际访问一个域名时，是从最底层开始写起，例如<a href="http://www.google.com，www.tinghua.edu.cn等。结构如下图：" target="_blank" rel="noopener">www.google.com，www.tinghua.edu.cn等。结构如下图：</a></p><img src="/2020/05/23/网络编程学习笔记（一）--几种概念/3_全球域名系统.jpg"><h1 id="套接字和地址"><a href="#套接字和地址" class="headerlink" title="套接字和地址"></a>套接字和地址</h1><p>　　在网络编程中，我们经常会提到socket这个词，它的中文翻译为套接字，有的时候也叫做套接口。在网络编程中，到底应该怎么理解socket呢？首先看一张图：</p><img src="/2020/05/23/网络编程学习笔记（一）--几种概念/4_套接字.jpg"><p>　　这张图表达的其实是网络编程中，客户端和服务器工作的核心逻辑。具体来说，客户端进程向操作系统内核发起write字节流写操作，内核协议栈将字节流通过网络设备传输到服务器端，服务器端从内核得到信息，将字节流从内核读入到进程中，并开始业务逻辑的处理，完成之后，服务器端再将得到的结果以同样的方式写给客户端。可以看到，一旦连接建立，数据的传输就不再是单向的，而是双向的，这也是TCP的一个显著特性。<br>　　以上所有的操作，都是通过socket来完成的。无论是客户端的connect，还是服务端的accept，或者read/write操作等，socket是我们用来建立连接，传输数据的唯一途径。<br>　　在使用套接字时，首先要解决通信双方寻址的问题。我们需要套接字的地址建立连接，就像打电话时首先需要查找电话簿，找到你想要联系的那个人，你才可以建立连接，开始交流。下面先看一下套接字的通用地址结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/* POSIX.1g 规范规定了地址族为 2 字节的值. */</span><br><span class="line">typedef unsigned short int sa_family_t;</span><br><span class="line">/* 描述通用套接字地址 */</span><br><span class="line">struct sockaddr&#123;</span><br><span class="line">sa_family_t sa_family; /* 地址族. 16-bit*/</span><br><span class="line">char sa_data[14]; /* 具体的地址值 112-bit */</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>　　在这个结构体里，第一个字段是地址族，它表示使用什么样的方式对地址进行解释和保存，好比电话簿里的手机格式，或者是固话格式，这两种格式的长度和含义都是不同的。地址族常用的有：AF_LOCAL（本地地址，对应的是Unix套接字，这种情况一般用于本地socket通信，很多情况下也可以写成AF_UNIX、AF_FILE）、AF_INET（因特网使用的IPv4地址）、AF_INET6（因特网使用的IPv6地址）。这里的AF_表示的含义是AddressFamily，但是很多情况下，我们也会看到以PF_表示的宏，比如PF_INET、PF_INET6等，实际上PF_的意思是ProtocolFamily，也就是协议族的意思。我们用AF_xxx这样的值来初始化socket地址，用PF_xxx这样的值来初始化socket。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;客户端-服务端模型&quot;&gt;&lt;a href=&quot;#客户端-服务端模型&quot; class=&quot;headerlink&quot; title=&quot;客户端-服务端模型&quot;&gt;&lt;/a&gt;客户端-服务端模型&lt;/h1&gt;&lt;p&gt;　　&lt;br&gt;　　一个连接可以通过客户端-服务器端的IP和端口唯一确定，这叫做套接字对
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="网络编程" scheme="https://liuruijie87.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>TCP/IP协议体系架构</title>
    <link href="https://liuruijie87.github.io/2020/05/17/TCP-IP%E5%8D%8F%E8%AE%AE%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    <id>https://liuruijie87.github.io/2020/05/17/TCP-IP协议体系架构/</id>
    <published>2020-05-17T07:06:12.332Z</published>
    <updated>2020-05-17T07:26:33.717Z</updated>
    
    <content type="html"><![CDATA[<p>　　在学习完TCP/IP协议后，个人感觉有几个重要的概念值得重视，所以记录在此。</p><h1 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h1><p>　　TCP-IP协议的体系结构如下图，其中，数据链路层、网络层、传输层在内核中实现，因为这些既高效又稳定，而应用层负责处理应用程序的逻辑，因此在用户态实现。</p><img src="/2020/05/17/TCP-IP协议体系架构/1_TCP-IP协议族体系结构.png"><h1 id="数据链路层之ARP协议"><a href="#数据链路层之ARP协议" class="headerlink" title="数据链路层之ARP协议"></a>数据链路层之ARP协议</h1><p>　　ARP协议属于数据链路层中的协议。网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转换为其物理地址，才能使用数据链路层提供的服务，这就是ARP协议的用途。</p><h1 id="网络层及网络层协议"><a href="#网络层及网络层协议" class="headerlink" title="网络层及网络层协议"></a>网络层及网络层协议</h1><p>　　网络层实现数据包的选路和转发。通信的两台主机一般不是直接相连的，而是通过多个中间节点（路由器）连接的，网络层的任务就是选择这些中间节点，以确定两台主机之间的通信路径。同时，网络层对上层协议隐藏了网络拓扑连接的细节，使得在传输层和网络应用程序看来，通信的双方是直接相连的。网络层的协议有ICMP协议和IP协议。</p><h1 id="传输层之TCP协议"><a href="#传输层之TCP协议" class="headerlink" title="传输层之TCP协议"></a>传输层之TCP协议</h1><p>　　TCP协议（传输控制协议）为应用层提供可靠的、面向连接的和基于流的服务。TCP协议使用超时重传、数据确认等方式来确保数据包正确地发送至目的端，因此TCP服务是可靠的。TCP服务是基于流的。基于流的数据没有边界限制，它源源不断地从通信的一端流入另一端。发送端可以逐个字节地向数据流写入数据，接收端也可以逐个字节地将它们读出。</p><h1 id="传输层之UDP协议"><a href="#传输层之UDP协议" class="headerlink" title="传输层之UDP协议"></a>传输层之UDP协议</h1><p>　　UDP协议为应用层提供不可靠、无连接和基于数据报的服务。使用UDP协议的应用程序通常要自己处理数据确认、超时重传等逻辑。UDP协议是无连接的，即通信双方不保持一个长久的联系，因此应用程序每次发送数据都要明确指定接收端的地址（IP地址等信息）。基于数据报的服务，是相对基于流的服务而言的。每个UDP数据报都有一个长度，接收端必须以该长度为最小单位将其所有内容一次性读出，否则数据将被截断。</p><h1 id="协议封装"><a href="#协议封装" class="headerlink" title="协议封装"></a>协议封装</h1><p>　　所谓封装，其实就是将上层的数据加上本层的头部或尾部。应用层数据经过层层封装，最终被封装成帧的形式，帧是最后在物理网络上传送的字节序列。</p><img src="/2020/05/17/TCP-IP协议体系架构/2_协议封装.png"><h1 id="协议分用"><a href="#协议分用" class="headerlink" title="协议分用"></a>协议分用</h1><p>　　当帧到达目的主机时，将沿着协议栈自底向上依次传递。各层协议通过处理本层负责的头部数据，以获得所需的信息，这就是分用。最终会将应用数据传递给应用层使用。</p><img src="/2020/05/17/TCP-IP协议体系架构/3_协议分用.png"><h1 id="协议类型"><a href="#协议类型" class="headerlink" title="协议类型"></a>协议类型</h1><p>　　由于IP协议、ARP协议、RARP协议都使用帧传输数据，所以帧的头部需要提供某个字段来区分它们。以以太网帧为例，它使用2字节的类型字段来标识上层协议。如果主机接收到的以太网帧类型字段的值为0x800，则为IP数据报，以太网驱动程序就将帧交付给IP模块。若值为0x806，则为ARP请求或应答报文。若值为0x835，则帧的数据部分为RARP请求或应答报文。</p><h1 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h1><p>　　Socket是一套应用程序编程接口，即API。能够实现系统调用，使得应用程序能够访问内核中协议提供的服务。<br>　　由socket定义的API提供两点功能：一是将应用程序的数据从用户缓冲区复制到TCP/UDP内核发送缓冲区，以交付内核来发送数据，或从内核TCP/UDP接受缓冲区复制数据到用户缓冲区，以读取数据。二是应用程序可以通过它们来修改内核中各层协议的某些头部信息或其他数据结构，从而精细地控制底层通信的行为。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;　　在学习完TCP/IP协议后，个人感觉有几个重要的概念值得重视，所以记录在此。&lt;/p&gt;
&lt;h1 id=&quot;体系结构&quot;&gt;&lt;a href=&quot;#体系结构&quot; class=&quot;headerlink&quot; title=&quot;体系结构&quot;&gt;&lt;/a&gt;体系结构&lt;/h1&gt;&lt;p&gt;　　TCP-IP协议的体系结
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="TCP/IP" scheme="https://liuruijie87.github.io/tags/TCP-IP/"/>
    
  </entry>
  
  <entry>
    <title>浅谈TCP协议</title>
    <link href="https://liuruijie87.github.io/2020/05/17/%E6%B5%85%E8%B0%88TCP%E5%8D%8F%E8%AE%AE/"/>
    <id>https://liuruijie87.github.io/2020/05/17/浅谈TCP协议/</id>
    <published>2020-05-17T07:02:04.032Z</published>
    <updated>2020-05-17T08:04:29.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TCP协议和UDP协议的特点"><a href="#TCP协议和UDP协议的特点" class="headerlink" title="TCP协议和UDP协议的特点"></a>TCP协议和UDP协议的特点</h1><p>　　TCP协议相对于UDP协议的特点是：面向连接、字节流和可靠传输。<br>　　这里需要明确一下什么叫字节流，什么叫数据报。<br>　　字节流：发送端执行的写操作次数和接收端执行的读操作次数之间没有任何数量关系，发送端和接收端分别与TCP缓冲区交互，应用程序对数据的发送和接收是没有边界限制的。<br>　　数据报：发送端应用程序每执行一次写操作，UDP模块就将其封装成一个UDP数据报并发送之。接收端必须及时针对每一个UDP数据报执行读操作，否则就会丢包。并且，如果用户没有指定足够的应用程序缓冲区来读取UDP数据，则UDP数据将被截断。<br>　　下面的图能够更加清晰的描述二者的区别。</p><img src="/2020/05/17/浅谈TCP协议/1_TCP和UDP的区别.png"><h1 id="TCP头部结构"><a href="#TCP头部结构" class="headerlink" title="TCP头部结构　　"></a>TCP头部结构　　</h1><img src="/2020/05/17/浅谈TCP协议/2_TCP头部结构.png"><p>　　注意：16位窗口大小是TCP流量控制的一个手段。这里的窗口指的是接收通告窗口，它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。</p><h1 id="TCP连接的建立和关闭"><a href="#TCP连接的建立和关闭" class="headerlink" title="TCP连接的建立和关闭"></a>TCP连接的建立和关闭</h1><img src="/2020/05/17/浅谈TCP协议/3_TCP连接的建立和关闭.png"><img src="/2020/05/17/浅谈TCP协议/4_TCP连接建立和断开过程中客户端和服务器的状态变化.png"><p>　　处于FIN_WAIT_2状态的客户端需要等待服务器发送结束报文段，才能转移至TIME_WAIT状态，否则它将一直停留在这个状态。连接停留在FIN_WAIT_2状态的情况可能发生在：客户端执行半关闭后，未等服务器关闭连接就强行退出了，此时客户端连接由内核来接管，称为孤儿连接。</p><h1 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h1><p>　　拥塞控制的目的是提高网络利用率，降低丢包率，并保证网络资源对每条数据流的公平性。拥塞控制的四个部分：慢启动、拥塞避免、快速重传、快速恢复。<br>　　拥塞控制其实是控制发送端向网络一次连续写入（收到其中第一个数据的确认之前）的数据量，称为SWND（发送窗口）。接收方可通过其接收通告窗口RWND来控制发送端的SWND，但是显然不够，所以发送端引入了一个称为拥塞窗口（CWND）的状态变量。实际的SWND值是RWND和CWND中的较小者。如下图：</p><img src="/2020/05/17/浅谈TCP协议/5_拥塞控制.png"><p>　　慢启动算法的理由是：TCP模块刚开始发送数据时并不知道网络的实际情况，需要用一种试探性的方式平滑地增加CWND的大小。但是刚开始这个CWND的值是以指数形式扩大，如果不进行干预，必然使得CWND很快膨胀，并最终导致网络拥塞。因此TCP拥塞控制中定义了另一个重要的状态变量：慢启动门限，当CWND的大小超过该值时，TCP拥塞控制将进入拥塞避免阶段。<br>　　拥塞避免算法使得CWND按照线性方式增加，从而减缓其扩大。</p><img src="/2020/05/17/浅谈TCP协议/6_慢启动和拥塞避免.png"><p>　　很多情况下，发送端都可能收到重复的确认报文段，比如TCP报文段丢失。拥塞控制算法需要判断当收到重复的确认报文段时，网络是否真的发生了拥塞。具体做法是：发送端如果连续收到3个重复的确认报文段，就认为是拥塞发生了。然后将启用快速重传和快速恢复算法来处理拥塞。过程如下：<br>　　1）当收到第3个重复确认报文段时，重新计算慢启动门限值，然后立即重传丢失的报文段，并设置CWND。（重新开始慢启动）<br>　　2）每次收到1个重复的确认时，设置CWND，此时发送端可以发送新的TCP报文段。<br>　　3）当收到新数据的确认时，设置CWND为新的慢启动门限值。<br>　　快速重传和快速恢复完成之后，拥塞控制恢复到拥塞避免阶段。</p><h1 id="TCP-IP通信实例逻辑"><a href="#TCP-IP通信实例逻辑" class="headerlink" title="TCP/IP通信实例逻辑"></a>TCP/IP通信实例逻辑</h1><img src="/2020/05/17/浅谈TCP协议/7_TCP-IP实例.png"><p>　　其中，Kongming20上运行wget客户端程序，ernest-laptop上运行squid代理服务器程序(HTTP代理服务器)。客户端通过代理服务器的中转，获取Internet上的主机<a href="http://www.baidu.com的首页。" target="_blank" rel="noopener">www.baidu.com的首页。</a></p><h1 id="HTTP代理服务器的工作原理"><a href="#HTTP代理服务器的工作原理" class="headerlink" title="HTTP代理服务器的工作原理"></a>HTTP代理服务器的工作原理</h1><p>　　正向代理要求客户端自己设置代理服务器的地址。客户的每次请求都将直接发送到该代理服务器，并由代理服务器来请求目标资源。<br>　　反向代理则被设置在服务端，因而客户端无需进行任何设置。反向代理是指用代理服务器来接收Internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从内部服务器上得到的结果返回给客户端。这种情况下，代理服务器对外就表现为一个真实的服务器。</p><img src="/2020/05/17/浅谈TCP协议/8_代理服务器.png"><h1 id="访问DNS服务器"><a href="#访问DNS服务器" class="headerlink" title="访问DNS服务器"></a>访问DNS服务器</h1><img src="/2020/05/17/浅谈TCP协议/9_访问DNS服务器.png"><p>　　IP头部的源端IP地址和目的端IP地址在转发过程中是始终不变的，但是帧头部的源端物理地址和目的端物理地址在转发过程中则是一直在变化的，因此在此过程中，在不停的找路由器的mac地址。</p><h1 id="HTTP通信过程"><a href="#HTTP通信过程" class="headerlink" title="HTTP通信过程"></a>HTTP通信过程</h1><img src="/2020/05/17/浅谈TCP协议/10_HTTP通信过程.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TCP协议和UDP协议的特点&quot;&gt;&lt;a href=&quot;#TCP协议和UDP协议的特点&quot; class=&quot;headerlink&quot; title=&quot;TCP协议和UDP协议的特点&quot;&gt;&lt;/a&gt;TCP协议和UDP协议的特点&lt;/h1&gt;&lt;p&gt;　　TCP协议相对于UDP协议的特点是：面向
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="TCP" scheme="https://liuruijie87.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>含有汇编代码的编译错误</title>
    <link href="https://liuruijie87.github.io/2020/05/04/%E5%90%AB%E6%9C%89%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81%E7%9A%84%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF/"/>
    <id>https://liuruijie87.github.io/2020/05/04/含有汇编代码的编译错误/</id>
    <published>2020-05-04T07:04:36.786Z</published>
    <updated>2020-05-04T07:26:49.898Z</updated>
    
    <content type="html"><![CDATA[<h1 id="含有汇编代码的vs2017工程编译错误"><a href="#含有汇编代码的vs2017工程编译错误" class="headerlink" title="含有汇编代码的vs2017工程编译错误"></a>含有汇编代码的vs2017工程编译错误</h1><p>　　当一个项目工程中含有汇编代码，在编译的时候可能会出现以下的错误。</p><h2 id="‘yasm’-不是内部或外部命令"><a href="#‘yasm’-不是内部或外部命令" class="headerlink" title="‘yasm’ 不是内部或外部命令"></a>‘yasm’ 不是内部或外部命令</h2><p>　　这是因为yasm.exe的路径不对，如果没有装yasm，则在 <a href="http://www.tortall.net/projects/yasm/wiki/Download" target="_blank" rel="noopener">http://www.tortall.net/projects/yasm/wiki/Download</a> 这里下载yasm，然后将vsyasm.exe 改名yasm.exe复制到VC安装目录，例如：D:\soft\vs2017\Common7\IDE。重新编译，即可成功。</p><h2 id="Microsoft-CppCommon-targets-172-5-error-MSB6006-“cmd-exe”已退出，代码为-9009。"><a href="#Microsoft-CppCommon-targets-172-5-error-MSB6006-“cmd-exe”已退出，代码为-9009。" class="headerlink" title="Microsoft.CppCommon.targets(172,5): error MSB6006: “cmd.exe”已退出，代码为 9009。"></a>Microsoft.CppCommon.targets(172,5): error MSB6006: “cmd.exe”已退出，代码为 9009。</h2><p>　　还是因为项目工程中有汇编代码，而汇编代码没有编译通过，所以导致这个错误，解决方法参考第一个错误。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;含有汇编代码的vs2017工程编译错误&quot;&gt;&lt;a href=&quot;#含有汇编代码的vs2017工程编译错误&quot; class=&quot;headerlink&quot; title=&quot;含有汇编代码的vs2017工程编译错误&quot;&gt;&lt;/a&gt;含有汇编代码的vs2017工程编译错误&lt;/h1&gt;&lt;p&gt;　　
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="编译错误" scheme="https://liuruijie87.github.io/tags/%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF/"/>
    
  </entry>
  
  <entry>
    <title>git常用命令</title>
    <link href="https://liuruijie87.github.io/2020/04/06/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://liuruijie87.github.io/2020/04/06/git常用命令/</id>
    <published>2020-04-06T08:23:23.964Z</published>
    <updated>2020-04-07T09:33:16.071Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Git常用命令"><a href="#Git常用命令" class="headerlink" title="Git常用命令"></a>Git常用命令</h1><h2 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h2><h3 id="在Linux上安装Git"><a href="#在Linux上安装Git" class="headerlink" title="在Linux上安装Git"></a>在Linux上安装Git</h3><p>　　在Ubuntu Linux中，使用 sudo apt-get install git 完成安装。<br>　　如果是其他Linux版本，可以直接通过源码安装。先从Git官网下载源码，然后解压，依次输入：./config，make，sudo make install这几个命令安装就好了。　　</p><h3 id="在Mac-OS-X上安装Git"><a href="#在Mac-OS-X上安装Git" class="headerlink" title="在Mac OS X上安装Git"></a>在Mac OS X上安装Git</h3><p>　　一是安装homebrew，然后通过homebrew安装Git，具体方法请参考homebrew的文档：<a href="http://brew.sh/。" target="_blank" rel="noopener">http://brew.sh/。</a><br>　　第二种方法更简单，也是推荐的方法，就是直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode，选择菜单“Xcode”-&gt;“Preferences”，在弹出窗口中找到“Downloads”，选择“Command Line Tools”，点“Install”就可以完成安装了。</p><h3 id="在Windows上安装Git"><a href="#在Windows上安装Git" class="headerlink" title="在Windows上安装Git"></a>在Windows上安装Git</h3><p>　　从Git官网直接下载 <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a> 然后按默认选项安装即可。<br>　　安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！<br>　　<strong>安装完成后，还需要最后一步设置，在命令行输入：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;Your Name&quot;</span><br><span class="line">git config --global user.email &quot;email@example.com&quot;</span><br></pre></td></tr></table></figure><p>　　注意config命令的–global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。</p><h2 id="创建版本库、提交文件"><a href="#创建版本库、提交文件" class="headerlink" title="创建版本库、提交文件"></a>创建版本库、提交文件</h2><p>　　选择一个合适的地方，创建一个空目录，然后创建文本文件，可以使用Notepad++编辑文本文件，默认编码设置为UTF-8 without BOM。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir learngit</span><br><span class="line">$ cd learngit</span><br><span class="line">$ pwd  //查看当前工作目录</span><br><span class="line">$ git init  //把这个目录变成Git可以管理的仓库，此时以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，最好不要修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。如果没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -ah命令就可以看见。</span><br><span class="line">$ git add readme.txt //把文件（readme.txt）添加到仓库</span><br><span class="line">$ git commit -m &quot;wrote a readme file&quot; //把文件提交到仓库，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样就能从历史记录里方便地找到改动记录。</span><br><span class="line">//为什么Git添加文件需要add，commit一共两步呢？因为commit可以一次提交很多文件，所以你可以多次add不同的文件。</span><br></pre></td></tr></table></figure><h2 id="查看仓库状态、文件修改、版本回退和前进"><a href="#查看仓库状态、文件修改、版本回退和前进" class="headerlink" title="查看仓库状态、文件修改、版本回退和前进"></a>查看仓库状态、文件修改、版本回退和前进</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ git status //可以让我们时刻掌握仓库当前的状态</span><br><span class="line">$ git diff readme.txt  //查看difference，知道了对readme.txt作了什么修改</span><br><span class="line">$ git log //显示从最近到最远的提交日志</span><br><span class="line">$ git log --pretty=oneline //简化版的查看提交日志</span><br><span class="line">$ git reset --hard HEAD^ //回退到上一个版本，在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。回退到前面版本，如果还想再回到最新版本，可以用 git reset --hard 版本号（不用写全）</span><br><span class="line">$ cat readme.txt //查看文件内容</span><br><span class="line">$ git reflog //记录每一次命令（可以查看版本号）</span><br><span class="line">$ git checkout -- readme.txt //撤销修改</span><br><span class="line">$ git reset HEAD readme.txt //把暂存区的修改回退到工作区</span><br><span class="line">$ rm test.txt //删除了工作区的文件</span><br><span class="line">$ git rm test.txt //从版本库中删除该文件，还需要git commit -m &quot;remove test.txt，才能彻底删除文件。</span><br><span class="line">$ git checkout -- test.txt //误删后因为版本库里还有，所以可以很轻松地把误删的文件恢复到最新版本。</span><br><span class="line">//git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。</span><br><span class="line">//注意：从来没有被添加到版本库就被删除的文件，是无法恢复的！</span><br></pre></td></tr></table></figure><p>　　场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。<br>　　场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD <file>，就回到了场景1，第二步按场景1操作。<br>　　场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。</file></p><h2 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Git常用命令&quot;&gt;&lt;a href=&quot;#Git常用命令&quot; class=&quot;headerlink&quot; title=&quot;Git常用命令&quot;&gt;&lt;/a&gt;Git常用命令&lt;/h1&gt;&lt;h2 id=&quot;安装Git&quot;&gt;&lt;a href=&quot;#安装Git&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="git" scheme="https://liuruijie87.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>malloc和free详解</title>
    <link href="https://liuruijie87.github.io/2020/03/15/malloc%E5%92%8Cfree%E8%AF%A6%E8%A7%A3/"/>
    <id>https://liuruijie87.github.io/2020/03/15/malloc和free详解/</id>
    <published>2020-03-15T06:42:48.989Z</published>
    <updated>2020-03-15T07:13:00.441Z</updated>
    
    <content type="html"><![CDATA[<h1 id="malloc和free详解"><a href="#malloc和free详解" class="headerlink" title="malloc和free详解"></a>malloc和free详解</h1><h2 id="malloc的实质"><a href="#malloc的实质" class="headerlink" title="malloc的实质"></a>malloc的实质</h2><p>　　malloc函数的实质体现在，它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。调用malloc函数时，它沿连接表寻找一个大到足以满足用户请求所需要的内存块。然后，将该内存块一分为二（一块的大小与用户请求的大小相等，另一块的大小就是剩下的字节）。接下来，将分配给用户的那块内存传给用户，并将剩下的那块（如果有的话）返回到连接表上。调用free函数时，它将用户释放的内存块连接到空闲链上。到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段，那么空闲链上可能没有可以满足用户要求的片段了。于是，malloc函数请求延时，并开始在空闲链上翻箱倒柜地检查各内存片段，对它们进行整理，将相邻的小空闲块合并成较大的内存块。如果无法获得符合要求的内存块，malloc函数会返回NULL指针，因此在调用malloc动态申请内存块时，一定要进行返回值的判断。</p><h2 id="malloc-到底从哪里得来了内存空间"><a href="#malloc-到底从哪里得来了内存空间" class="headerlink" title="malloc()到底从哪里得来了内存空间"></a>malloc()到底从哪里得来了内存空间</h2><p>　　１、malloc()到底从哪里得到了内存空间？答案是从堆里面获得空间。也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。就是这样！     　　说到这里，不得不另外插入一个小话题。什么是堆？说到堆，又忍不住说到了栈！什么是栈？下面就另外开个小部分专门而又简单地说一下这个题外话。<br>　　2、什么是堆：堆是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。  　　什么是栈：栈是线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立。每个函数都有自己的栈，栈被用来在函数之间传递参数。操作系统在切换线程的时候会自动的切换栈，就是切换SS/ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。<br>　　通过上面对概念的描述，可以知道：栈是由编译器自动分配释放，存放函数的参数值、局部变量的值等。操作方式类似于数据结构中的栈。堆一般由程序员分配释放，若不释放，程序结束时可能由OS回收。注意这里说是可能，并非一定。所以再强调一次，记得要释放！注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。<br>　　举个例子，如果你在函数上面定义了一个指针变量，然后在这个函数里申请了一块内存让指针指向它。实际上，这个指针的地址是在栈上，但是它所指向的内容却是在堆上面的！这一点要注意！所以，再想想，在一个函数里申请了空间后，比如说下面这个函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void Function(void) </span><br><span class="line">&#123; </span><br><span class="line">char *p = (char *)malloc(100 * sizeof(char)); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　就这个例子，千万不要认为函数返回，函数所在的栈被销毁指针也跟着销毁，申请的内存也就一样跟着销毁了！这绝对是错误的！因为申请的内存在堆上，而函数所在的栈被销毁跟堆完全没有啥关系。所以，还是那句话：记得释放！</p><h2 id="free-到底释放了什么"><a href="#free-到底释放了什么" class="headerlink" title="free()到底释放了什么"></a>free()到底释放了什么</h2><p>　　free()释放的是指针指向的内存！注意！释放的是内存，不是指针！这点非常非常重要！指针是一个变量，只有程序结束时才被销毁。释放了内存空间后，原来指向这块空间的指针还是存在！只不过现在指针指向的内容的垃圾，是未定义的，所以说是垃圾。因此，前面我已经说过了，释放内存后把指针指向NULL，防止指针在后面不小心又被解引用了。这一点非常重要！</p><h2 id="malloc-以及free-的机制"><a href="#malloc-以及free-的机制" class="headerlink" title="malloc()以及free()的机制"></a>malloc()以及free()的机制</h2><p>　　事实上，仔细看一下free()的函数原型，也许也会发现似乎很神奇，free()函数非常简单，只有一个参数，只要把指向申请空间的指针传递给free()中的参数就可以完成释放工作！这里要追踪到malloc()的申请问题了。申请的时候实际上占用的内存要比申请的大。因为超出的空间是用来记录对这块内存的管理信息。先看一下在《UNIX环境高级编程》中第七章的一段话：   　　大多数实现所分配的存储空间比所要求的要稍大一些，额外的空间用来记录管理信息——分配块的长度，指向下一个分配块的指针等等。这就意味着如果写过一个已分配区的尾端，则会改写后一块的管理信息。这种类型的错误是灾难性的，但是因为这种错误不会很快就暴露出来，所以也就很难发现。将指向分配块的指针向后移动也可能会改写本块的管理信息。   　　以上这段话已经给了我们一些信息了。malloc()申请的空间实际就是分了两个不同性质的空间。一个就是用来记录管理信息的空间，另外一个就是可用空间了。而用来记录管理信息的实际上是一个结构体。在C语言中，用结构体来记录同一个对象的不同信息是天经地义的事！下面看看这个结构体的原型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct mem_control_block </span><br><span class="line">&#123; </span><br><span class="line">    int is_available;    //这是一个标记？ </span><br><span class="line">    int size;            //这是实际空间的大小 </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>　　对于size,这个是实际空间大小。而is_available是否是一个标记？free()就是根据这个结构体的信息来释放malloc()申请的空间！而结构体的两个成员的大小我想应该是操作系统的事了。但是这里有一个问题，malloc()申请空间后返回一个指针应该是指向第二种空间，也就是可用空间！不然，如果指向管理信息空间的话，写入的内容和结构体的类型有可能不一致，或者会把管理信息屏蔽掉，那就没法释放内存空间了，所以会发生错误！接下来分析free()的源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void free(void *ptr)      </span><br><span class="line">&#123;</span><br><span class="line">struct mem_control_block *free;             </span><br><span class="line">free = ptr - sizeof(struct mem_control_block);             </span><br><span class="line">free-&gt;is_available = 1;             </span><br><span class="line">return;     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　看一下函数第二句，这句非常重要和关键。其实这句就是把指向可用空间的指针倒回去，让它指向管理信息的那块空间，因为这里是在值上减去了一个结构体的大小！后面那一句free-&gt;is_available = 1;这里is_available应该只是一个标记而已！因为从这个变量的名称上来看，is_available翻译过来就是“是可以用”。这个变量的值是1，表明是可以用的空间！如果把它改为0或者是其他值不知道会发生什么事？！但是有一点可以肯定，就是释放绝对不会那么顺利进行！因为这是一个标记！<br>　　当然，这里可能还是有人会有疑问，为什么这样就可以释放呢？就free()这个源代码来看，什么也没有释放。但是它确实是确定了管理信息的那块内存的内容。所以，free()只是记录了一些信息，然后告诉操作系统那块内存可以去释放，然后由操作系统来释放那段内存。之前一个错误的认识，就是认为指向那块内存的指针不管移到那块内存中的哪个位置都可以释放那块内存！但是，这是大错特错！释放是不可以释放一部分的！首先这点应该要明白。而且，从free()的源代码看，ptr只能指向可用空间的首地址，不然，减去结构体大小之后一定不是指向管理信息空间的首地址。所以，要确保指针指向可用空间的首地址！如若验证，可以写一个程序然后移动指向可用空间的指针，看程序会不会崩溃！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;malloc和free详解&quot;&gt;&lt;a href=&quot;#malloc和free详解&quot; class=&quot;headerlink&quot; title=&quot;malloc和free详解&quot;&gt;&lt;/a&gt;malloc和free详解&lt;/h1&gt;&lt;h2 id=&quot;malloc的实质&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="malloc和free" scheme="https://liuruijie87.github.io/tags/malloc%E5%92%8Cfree/"/>
    
  </entry>
  
  <entry>
    <title>一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。</title>
    <link href="https://liuruijie87.github.io/2020/03/06/%E7%BB%86%E8%83%9E%E5%88%86%E8%A3%82%E6%89%BE%E8%A7%84%E5%BE%8B%E9%A2%98/"/>
    <id>https://liuruijie87.github.io/2020/03/06/细胞分裂找规律题/</id>
    <published>2020-03-06T10:49:05.072Z</published>
    <updated>2020-03-06T11:09:48.802Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。"><a href="#一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。" class="headerlink" title="一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。"></a>一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。</h1><p>　　假设经过三个小时的细胞分裂后再死亡。根据题意，细胞的生命周期是三个小时，一个小时后，第一个细胞分裂，此时细胞总数变成2，但是这两个细胞的生存时间是不一样的，如果都当成新生细胞即存活时间为0，那么给定的3小时生命周期也就没意义了，所以这个时候其中一个细胞的生存时间变成了1，另外一个刚分裂出来的是0，下面简单表示一下分裂进程（-1表示死亡）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">时间 细胞状态 (生存时间) 细胞总数</span><br><span class="line">0 0 1</span><br><span class="line">1 1 0 2</span><br><span class="line">2 2 1 0 0 4</span><br><span class="line">3 -1 2 1 1 0 0 0 0 7</span><br><span class="line">4 -1 2 2 1 1 1 1 0 0 0 0 0 0 0 13</span><br><span class="line">5 -1 -1 2 2 2 2 1 1 1 1 1 1 1</span><br><span class="line">0 0 0 0 0 0 0 0 0 0 0 0 0 24</span><br><span class="line">… … …</span><br><span class="line">f0 = 1</span><br><span class="line">f1 = 2</span><br><span class="line">f2 = 4</span><br><span class="line">f3 = 7</span><br></pre></td></tr></table></figure><p>可以发现到第四个小时的时候，规律出来了，在第四个小时死亡的细胞是三小时前也就是第一个小时的时候同时出生的细胞，而在第一个小时同时出生的细胞数等于第一个小时前一个小时的细胞总数<br>所以有递推式：f(n) = 2f(n - 1) - f(n - 4)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。&quot;&gt;&lt;a href=&quot;#一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。&quot; class=&quot;headerlink&quot; title=&quot;一个细胞的生命周期是3小时，1小时分
      
    
    </summary>
    
      <category term="题集" scheme="https://liuruijie87.github.io/categories/%E9%A2%98%E9%9B%86/"/>
    
    
      <category term="细胞分裂" scheme="https://liuruijie87.github.io/tags/%E7%BB%86%E8%83%9E%E5%88%86%E8%A3%82/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议如何保证数据传输的可靠性</title>
    <link href="https://liuruijie87.github.io/2020/03/06/TCP%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/"/>
    <id>https://liuruijie87.github.io/2020/03/06/TCP协议如何保证数据传输的可靠性/</id>
    <published>2020-03-06T05:14:22.413Z</published>
    <updated>2020-03-06T05:48:16.715Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TCP协议如何保证数据传输的可靠性"><a href="#TCP协议如何保证数据传输的可靠性" class="headerlink" title="TCP协议如何保证数据传输的可靠性"></a>TCP协议如何保证数据传输的可靠性</h1><p>　　TCP协议传输的特点主要就是面向字节流、传输可靠、面向连接。<br>　　TCP协议保证数据传输可靠性的方式主要有：校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞控制。</p><h2 id="校验和"><a href="#校验和" class="headerlink" title="校验和"></a>校验和</h2><p>　　计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。<br>　　发送方：在发送数据之前计算检验和，并进行校验和的填充。<br>　　接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。<br>　　<strong>注意：</strong>如果接收方比对校验和与发送方不一致，那么数据一定传输有误。但是如果接收方比对校验和与发送方一致，数据不一定传输成功。</p><h2 id="确认应答与序列号"><a href="#确认应答与序列号" class="headerlink" title="确认应答与序列号"></a>确认应答与序列号</h2><p>　　序列号：TCP传输时将每个字节的数据都进行了编号，这就是序列号。序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一。<br>　　确认应答：TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文。这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。</p><h2 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h2><p>　　在进行TCP传输时，由于确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发送完数据后，迟迟没有等到接收方的ACK报文，这该怎么办呢？而没有收到ACK报文的原因可能是什么呢？<br>　　首先，发送方没有介绍到响应的ACK报文原因可能有两点：<br>　　1.数据在传输过程中由于网络原因等直接全体丢包，接收方根本没有接收到。<br>　　2.接收方接收到了响应的数据，但是发送的ACK报文响应却由于网络原因丢包了。<br>　　TCP在解决这个问题的时候引入了一个新的机制，叫做超时重传机制。简单理解就是发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送。如果是刚才第一个原因，接收方收到二次重发的数据后，便进行ACK应答。如果是第二个原因，接收方发现接收的数据已存在（判断存在的根据就是序列号，所以上面说序列号还有去除重复数据的作用），那么直接丢弃，仍旧发送ACK应答。<br>　　那么发送方发送完毕后等待的时间是多少呢？如果这个等待的时间过长，那么会影响TCP传输的整体效率，如果等待时间过短，又会导致频繁的发送重复的包。如何权衡？<br>　　由于TCP传输时保证能够在任何环境下都有一个高性能的通信，因此这个最大超时时间（也就是等待的时间）是动态计算的。<br>　　<em>在Linux中（BSD Unix和Windows下也是这样）超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。重发一次后，仍未响应，那么等待2x500ms的时间后，再次重传。等待4x500ms的时间继续重传。以一个指数的形式增长。累计到一定的重传次数，TCP就认为网络或者对端出现异常，强制关闭连接。</em></p><h2 id="连接管理"><a href="#连接管理" class="headerlink" title="连接管理"></a>连接管理</h2><p>　　连接管理就是三次握手与四次挥手的过程。保证可靠的连接，是保证可靠性的前提。</p><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>　　接收端在接收到数据后，对其进行处理。如果发送端的发送速度太快，导致接收端的结束缓冲区很快的填充满了。此时如果发送端仍旧发送数据，那么接下来发送的数据都会丢包，继而导致丢包的一系列连锁反应，超时重传呀什么的。而TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。<br>　　在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道，窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小。这个数字越大，证明接收端接收缓冲区的剩余空间越大，网络的吞吐量越大。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。<br>　　<strong>注：</strong>16位的窗口大小最大能表示65535个字节（64K），但是TCP的窗口大小最大并不是64K。在TCP首部中40个字节的选项中还包含了一个窗口扩大因子M，实际的窗口大小就是16为窗口字段的值左移M位。每移一位，扩大两倍。 </p><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>　　TCP传输的过程中，发送端开始发送数据的时候，如果刚开始就发送大量的数据，那么就可能造成一些问题。网络可能在开始的时候就很拥堵，如果给网络中在扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。<br>　　所以TCP引入了慢启动的机制，在开始发送数据时，先发送少量的数据探路。探清当前的网络状态如何，再决定多大的速度进行传输。这时候就引入一个叫做拥塞窗口的概念。发送刚开始定义拥塞窗口为1，每次收到ACK应答，拥塞窗口加1。在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小比对，取较小的值作为实际发送的窗口。<br>　　拥塞窗口的增长是指数级别的。慢启动的机制只是说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。为了控制拥塞窗口的增长，不能使拥塞窗口单纯的加倍，设置一个拥塞窗口的阈值，当拥塞窗口大小超过阈值时，不能再按照指数来增长，而是线性的增长。在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，发生超时重传时，慢启动的阈值会为原来的一半（这里的原来指的是发生网络拥塞时拥塞窗口的大小），同时拥塞窗口重置为1。<br>　　拥塞控制是TCP在传输时尽可能快的将数据传输，并且避免拥塞造成的一系列问题。是可靠性的保证，同时也是维护了传输的高效性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TCP协议如何保证数据传输的可靠性&quot;&gt;&lt;a href=&quot;#TCP协议如何保证数据传输的可靠性&quot; class=&quot;headerlink&quot; title=&quot;TCP协议如何保证数据传输的可靠性&quot;&gt;&lt;/a&gt;TCP协议如何保证数据传输的可靠性&lt;/h1&gt;&lt;p&gt;　　TCP协议传输的
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="TCP" scheme="https://liuruijie87.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>一次完整的http请求过程</title>
    <link href="https://liuruijie87.github.io/2020/03/05/%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84http%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B/"/>
    <id>https://liuruijie87.github.io/2020/03/05/一次完整的http请求过程/</id>
    <published>2020-03-05T14:30:21.648Z</published>
    <updated>2020-03-05T14:36:55.068Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）"><a href="#一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）" class="headerlink" title="一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）"></a>一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）</h1><p>1.首先进行域名解析，域名解析具体过程讲一下：<br>　　浏览器搜索自己的DNS缓存，缓存中维护一张域名与IP地址的对应表；<br>　　若没有，则搜索操作系统的DNS缓存；<br>　　若没有，则操作系统将域名发送至本地域名服务器（递归查询方式），本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则，通过以下方式迭代查找：<br>　　　　本地域名服务器向根域名服务器发起请求，根域名服务器返回com域的顶级域名服务器的地址；<br>　　　　本地域名服务器向com域的顶级域名服务器发起请求，返回权限域名服务器地址；<br>　　　　本地域名服务器向权限域名服务器发起请求，得到IP地址；<br>　　本地域名服务器将得到的IP地址返回给操作系统，同时自己将IP地址缓存起来；<br>　　操作系统将IP地址返回给浏览器，同时自己也将IP地址缓存起来；<br>　　至此，浏览器已经得到了域名对应的IP地址。<br>2.浏览器发起HTTP请求；<br>3.接下来到了传输层，选择传输协议，TCP或者UDP，TCP是可靠的传输控制协议，对HTTP请求进行封装，加入了端口号等信息；<br>4.然后到了网络层，通过IP协议将IP地址封装为IP数据报；然后此时会用到ARP协议，主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址，找到目的MAC地址；<br>5.接下来到了数据链路层，把网络层交下来的IP数据报添加首部和尾部，封装为MAC帧，现在根据目的mac开始建立TCP连接，三次握手，接收端在收到物理层上交的比特流后，根据首尾的标记，识别帧的开始和结束，将中间的数据部分上交给网络层，然后层层向上传递到应用层；<br>6.服务器响应请求并请求客户端要的资源，传回给客户端；<br>7.断开TCP连接，浏览器对页面进行渲染呈现给客户端。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）&quot;&gt;&lt;a href=&quot;#一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）&quot; class=&quot;headerlink&quot; title=&quot;一次完整的http请求过程（在浏览器输入URL后，执
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="https和http" scheme="https://liuruijie87.github.io/tags/https%E5%92%8Chttp/"/>
    
  </entry>
  
  <entry>
    <title>从https协议谈对称加密和非对称加密</title>
    <link href="https://liuruijie87.github.io/2020/03/05/%E4%BB%8Ehttps%E5%8D%8F%E8%AE%AE%E8%B0%88%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/"/>
    <id>https://liuruijie87.github.io/2020/03/05/从https协议谈对称加密和非对称加密/</id>
    <published>2020-03-05T14:05:23.424Z</published>
    <updated>2020-03-05T14:28:50.673Z</updated>
    
    <content type="html"><![CDATA[<p>　　首先，我们为什么要用https协议，在此我们举例说明：你在网上商城，发送一个购物的请求，要购买一件商品，但你的数据包被黑客截获了，黑客在网上商城服务器回复你之前回复你，让你提供银行卡账号和密码，如果你未能识别出这是黑客行文，那么后果就可以自己想象了。<br>　　为了解决这个问题，一般的思路就是加密。加密后的数据包黑客就算截获了了也无法解密，也就无法知道你要干嘛，就无从构造回复报文。加密分为两种方式：对称加密和非对称加密。<br>　　在对称加密算法中，加密和解密使用的密钥是相同的，因此在使用对称加密算法的时候一定要保证密钥不被泄露。<br>　　在非对称加密算法中，加密使用的密钥和解密使用的密钥是不同的，一把是作为公开的公钥，另一把是作为谁都不能给的密钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。<br>　　在效率方面，对称加密算法的效率比非对称加密算法的效率要高的多。<br>　　接下来我们详细说下对称加密。<br>　　假如使用对称加密，在购物时你和网上商城约定了一个密钥，你发送请求的时候用这个密钥加密，网上商城使用同样的密钥解密，这样看起来没有一起都很OK，但有个问题，你和商城怎样约定密钥而不被截获了，既在加密建立前如何安全的传送密钥？如果直接传送密钥的信息，那么这信息可能被黑客截获，之后所有的通信黑客都可以解密查看了，也就没有秘密了。我们总不能和商城的人约定一个时间地点然后线下传送密钥吧，就算是线下接头那是不是也要有个约定的暗号什么的，不然你们又不认识，但在传输暗号的时候还是可能被黑客截获，那么线下和你接头的人也说不好是谁呢…<br>　　So，只要是使用对称加密，如何安全的传送密钥就是一个绕不开的问题，如果只使用对称加密，就会陷入一个密钥传送的死循环，幸好此时我们的非对称加密挺身而出。<br>　　网站使用非对称加密的时候，他的密钥放在自己的口袋里谁也不给，但他会把公钥放在一个指定的地方谁都可以获取，只要你拿到了公钥，在你网站交流的时候，你用公钥加密你的信息，这时就算被人截获但因为缺少私钥，所以黑客也解不开你的信息。目前为止，一切开起来很顺利，但网站在给你回复信息的时候有个问题：网站的回复信息是拿他自己的私钥加密的，这个信息谁都可以用公钥来解密的。看来要解决这个问题，只使用网站的公私钥还不行，客户端也得有自己的公私钥，客户端把自己的公钥给网站，把私钥放在自己口袋，在和网站通信的时候客户端使用网站的公钥加密，网站使用客户端的私钥加密回复信息，至此解决了非对称加密的保密性问题。<br>　　但对于非对称加密也有和对称加密一样的问题，如何将公钥给到对方，前面其实我们也说过一个方法，就是把各自的公钥放在公网上，这样谁都可以去取；还有另一种方法，就是在建立连接的时候把公钥传给对方。但这两种方式都有一个问题，你怎么确保给到你的公钥就是你信任的人呢，有没有可能有人假冒对方呢，答案是完全有可能。<br>　　解决信任问题，最好的方法就是证明，证明什么呢，证明“你是你”！在现实生活中要证明你是你，你需要拿着公安局给你的身份证或者户口本来证明，别人不一定信任你，但身份证的颁发机构是公安局，是权威机构，别人看到身份证也就相信了你是你。其实在网络中也一样，你也需要一个权威机构给你一个证明，证明你是你，证明他是他，证明我是我…在网络世界里，权威部门颁发给你的身份证被称为“证书”。<br>　　在证书中包含：公钥、证书的所有者、证书的发布机构、和证书的有效期。这样来看证书其实和身份证很像~，证书是怎么来的呢，有没有可能有假的证书呢，就像假的身份证一样？<br>　　要生成证书需要发起一个证书请求，然后将这个请求发给权威机构去认证，这个权威机构不是公安局而是CA（Certificate Authority），把生成证书的请求发给权威机构后，权威机构会给这个证书卡个公章，我们称之为签名算法，接着，继续我们的怀疑精神，有没有可能会仿造签名呢，该怎么解决呢？签名算法解决了伪造签名的问题，签名算法用自己的私钥来进行签名，这样能用他的公钥解开的签名就能证明这个签名是真的。<br>　　签名算法一般先对信息做一个hash运算，得到一个hash值，我们都知道这个过程是不可逆的，也就是无法根据hash值推导出原来的信息。在把信息发送出去的时候呢，把这个hash值加密后作为签名一起发出去。<br>　　CA用自己的私钥给网站的公钥的签名，就相当于CA成了网站的担保人，担保这个公钥是这个网站的公钥而不是别人伪造的。<br>　　那么你在和网站通信的时候就不会得到一个公钥了，而是一个证书，一个由CA担保的证书，但我们都知道，信任会传递，不信任也会传递，我们凭什么相信一个我们并不了解的CA机构呢，他又不是国家的公安局，而且我们得到的证书要解密的话还需要CA的公钥，我们怎么获取CA的公钥呢，怎么去相信获得的是CA的公钥呢，这是不是又是一个信任的死循环呢？当然不是，首先CA的公钥也要有人给他做担保人，谁呢？更牛的CA，你不相信小的CA机构，但如果是大的CA机构呢，就这样CA一层层的做担保，直到大到那种全球认可的CA机构他们不再需要担保人，因为他们自身就是root CA。<br>　　在使用Https的时候还有一种常见的证书，就是自签名证书（self-signed certificate），有点像是我给自己带盐，你爱信不信的意思。<br>　　到现在为止我们知道了，在使用https的时候我们无法只使用对称加密算法，但可以只使用非对称加密，之前我们提到过，非对称加密算法在效率上要远低于对称加密算法，因此在传输大数据量的时候我们希望能使用对称加密来提高效率，因此https将两种加密算法搭配使用，具体的过程如下：<br>　　1.客户端发送Client Hello信息到服务器，信息以明文传输TLS版本信息、加密套件候选列表、压缩算法候选列表等。另外还会给对方一个随机数，这个随机数客户端和服务器都会留着。<br>　　2.服务器会回复Server Hello消息，告诉客户端用那个协议、加密套件、压缩算法等，并且服务器也会给客户端一个自己的随机数，现在每个人手里都有两个随机数了。<br>　　3.然后服务器会给客户端自己的证书<br>　　4.服务器会告诉客户端Server Hello done，我就给你这些信息。<br>　　5.客户端会去验证这个证书，在验证的过程中会不断的上溯CA、CA的CA，一直到一个你信任的CA出来做担保。<br>　　6.证书验证通过后，客户端会生成随机数Pre-master，发送Client Key Exchange，用证书中的公钥加密发给服务器。<br>　　7.服务器有了第三（客户端给了两个，自己生成一个）个随机数，客户端也有了三个随机数，然后双方都通过“自己的随机数”+“对端的随机数”+“Pre-master”一起算出对称密钥。<br>　　8.然后双方都发送给对方一个Encrypted Handshake Message，将已经协商好的参数等，采用密钥加密发给对方，作为握手验证，双方验证通过后就可以采用对称加密通信了。<br>　　总结<br>　　加密分为对称加密和非对称加密，对称加密效率高，但是解决不了秘钥的传输问题；非对称加密可以解决这个问题，但效率不高。<br>　　非对称加密需要通过证书来验证公钥的合法性。<br>　　https是综合了对称加密和非对称加密算法的http协议。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;　　首先，我们为什么要用https协议，在此我们举例说明：你在网上商城，发送一个购物的请求，要购买一件商品，但你的数据包被黑客截获了，黑客在网上商城服务器回复你之前回复你，让你提供银行卡账号和密码，如果你未能识别出这是黑客行文，那么后果就可以自己想象了。&lt;br&gt;　　为了解决
      
    
    </summary>
    
      <category term="技术积累" scheme="https://liuruijie87.github.io/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
      <category term="https和http" scheme="https://liuruijie87.github.io/tags/https%E5%92%8Chttp/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法学习笔记（2）-数组</title>
    <link href="https://liuruijie87.github.io/2020/01/14/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89-%E6%95%B0%E7%BB%84/"/>
    <id>https://liuruijie87.github.io/2020/01/14/数据结构与算法学习（2）-数组/</id>
    <published>2020-01-14T13:23:09.440Z</published>
    <updated>2020-01-14T13:42:26.079Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前记"><a href="#前记" class="headerlink" title="前记"></a>前记</h1><p>　　前篇总结复杂度分析，本篇学习数组。</p><h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h1><p>　　数组（Array）是一种线性表数据结构。它用一组连续的内存空间来存储一组具有相同类型的数据。<br>　　数组和链表的区别，很多人都说，“链表适合插入、删除，时间复杂度O(1)；数组适合查找，查找时间复杂度为O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。<br>　　数组为了保持内存数据的连续性，会导致插入、删除这两个操作比 较低效。</p><h2 id="插入操作"><a href="#插入操作" class="headerlink" title="插入操作"></a>插入操作</h2><p>　　如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是O(n)。因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为(1+2+…n)/n=O(n)。<br>　　如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须依次搬移k之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第k个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第k位的数据搬移到数组元素的最后，把新的元素直接放入第k个位置。</p><h2 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h2><p>　　跟插入数据类似，如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为O(1)；如果删除开头的数据，则最坏情况时间复杂度为O(n)；平均情况时间复杂度也为O(n)。</p><h2 id="警惕数组的访问越界问题"><a href="#警惕数组的访问越界问题" class="headerlink" title="警惕数组的访问越界问题"></a>警惕数组的访问越界问题</h2><p>　　数组越界在C语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。</p><h2 id="容器能否完全替代数组？"><a href="#容器能否完全替代数组？" class="headerlink" title="容器能否完全替代数组？"></a>容器能否完全替代数组？</h2><p>　　针对数组类型，很多语言都提供了容器类，比如Java中的ArrayList、C++STL中的vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？<br>　　数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为10的数组，当第11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。如果使用vector等容器，我们就完全不需要关心底层的扩容逻辑，vector已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为2倍大小。<br>　　不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建vector的时候事先指定数据大小。<br>　　作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验：<br>　　1.如果数据大小事先已知，并且对数据的操作非常简单，用不到vector提供的大部分方法，也可以直接使用数组<br>　　2.还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如int Object[][]array；而用容器的话则需要这样定义：vector&lt;vector<int>&gt; v;<br>　　总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。</int></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前记&quot;&gt;&lt;a href=&quot;#前记&quot; class=&quot;headerlink&quot; title=&quot;前记&quot;&gt;&lt;/a&gt;前记&lt;/h1&gt;&lt;p&gt;　　前篇总结复杂度分析，本篇学习数组。&lt;/p&gt;
&lt;h1 id=&quot;数组&quot;&gt;&lt;a href=&quot;#数组&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
      <category term="算法学习" scheme="https://liuruijie87.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="https://liuruijie87.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法学习笔记（1）-复杂度分析</title>
    <link href="https://liuruijie87.github.io/2020/01/13/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"/>
    <id>https://liuruijie87.github.io/2020/01/13/数据结构与算法学习（1）-复杂度分析/</id>
    <published>2020-01-13T13:16:58.814Z</published>
    <updated>2020-01-14T13:27:59.741Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前记"><a href="#前记" class="headerlink" title="前记"></a>前记</h1><p>　　众所周知，数据结构和算法是编程当中的内功，只有把内功修炼深厚，才能应对各种招式的变化。如果每天做一些机械性质的增删改查，那是注定在编程道路上走不远的，因此，从本篇开始，进行数据结构和算法的学习，并以笔记的形式进行知识点的总结。</p><h1 id="基本复杂度分析"><a href="#基本复杂度分析" class="headerlink" title="基本复杂度分析"></a>基本复杂度分析</h1><p>　　复杂度分析是算法学习的精髓，可以说掌握了复杂度分析，算法学习就成功了一半。而最常用的复杂度表示方法就是大O表示法，这是表示代码执行时间或所占空间随数据规模增长的变化趋势的一种方法。当n很大时，你可以把它想象成100000，而公式中的低阶、常量、系数三部分并不影响增长趋势，所以都可以忽略，我们只需保留一个最大量级就可以了。</p><h2 id="时间复杂度分析"><a href="#时间复杂度分析" class="headerlink" title="时间复杂度分析"></a>时间复杂度分析</h2><p>　　1 只关注循环执行次数最多的一段代码。<br>　　2 加法法则：总的时间复杂度等于量级最大的那段代码的时间复杂度。即抽象公式：T(n)=T1(n)+T2(n)=Max(O(f(n)),O(g(n)))。<br>　　3 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。<br>　　常见的复杂度有O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)、O(2^n)、O(n!)，其中O(2^n)和O(n!)为非多项式量级。<br>　　O(logn)比较难以分析，借用以下例子加以理解：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">i = 1;</span><br><span class="line">while(i &lt;= n)&#123;</span><br><span class="line">i = i * 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出i从1开始，每次循环就乘以2，当大于n时，循环结束，因此可以看出这是一个等比数列：2^0,2^1,2^2,2^3……2^k = n，其中k代表执行的次数，即k=logn（以2为底，用大O表示的话可以省略底数）。<br>　　另外，还有一种非寻常的情况，即代码的复杂度由两个数据的规模来决定，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">int cal(int m, int n) &#123;</span><br><span class="line">int sum_1 = 0;</span><br><span class="line">int i = 1;</span><br><span class="line">for (; i &lt; m; ++i) &#123;</span><br><span class="line">sum_1 = sum_1 + i;</span><br><span class="line">&#125;</span><br><span class="line">int sum_2 = 0;</span><br><span class="line">int j = 1;</span><br><span class="line">for (; j &lt; n; ++j) &#123;</span><br><span class="line">sum_2 = sum_2 + j;</span><br><span class="line">&#125;</span><br><span class="line">return sum_1 + sum_2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出，m和n表示两个数据规模，我们无法事先评估,m和n谁的量级大，所以复杂度就是O(m+n)。</p><h2 id="空间复杂度分析"><a href="#空间复杂度分析" class="headerlink" title="空间复杂度分析"></a>空间复杂度分析</h2><p>　　空间复杂度一般比较简单，能够通过肉眼看出来，例如下面代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void print(int n) &#123;</span><br><span class="line">int i = 0;</span><br><span class="line">int[] a = new int[n];</span><br><span class="line">for (i; i &lt;n; ++i) &#123;</span><br><span class="line">a[i] = i * i;</span><br><span class="line">&#125;</span><br><span class="line">for (i = n-1; i &gt;= 0; --i) &#123;</span><br><span class="line">print out a[i]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　可以看到，申请了一个大小为n的int类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是O(n)。</p><h1 id="最好、最坏时间复杂度"><a href="#最好、最坏时间复杂度" class="headerlink" title="最好、最坏时间复杂度"></a>最好、最坏时间复杂度</h1><p>　　顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。看代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">int find(int[] array, int n, int x) &#123;</span><br><span class="line">int i = 0;</span><br><span class="line">int pos = -1;</span><br><span class="line">for (; i &lt; n; ++i) &#123;</span><br><span class="line">if (array[i] == x) &#123;</span><br><span class="line">pos = i;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return pos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　上述代码中，在一个数组中查找x，如果x是第一个数，则最快，而如果x不存在数组中，则要遍历n次，因此，最好复杂度O(1)，最坏复杂度O(n)。</p><h1 id="平均情况时间复杂度"><a href="#平均情况时间复杂度" class="headerlink" title="平均情况时间复杂度"></a>平均情况时间复杂度</h1><p>　　还是上述代码，为了方便你理解，我们假设在数组中与不在数组中的概率都为1/2。另外，要查找的数据出现在0～n-1这n个位置的概率也是一样的，为1/n。所以，根据概率乘法法则，要查找的数据出现在0～n-1中任意位置的概率就是1/(2n)。因此平均时间复杂度的计算过程为：1/2n+2/2n+……+n/2n+n/2=(3n+1)/4。这个值就是加权平均值，用大O法表示即：O(n)。</p><h1 id="均摊时间复杂度"><a href="#均摊时间复杂度" class="headerlink" title="均摊时间复杂度"></a>均摊时间复杂度</h1><p>　　首先看代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">int[] array = new int[n];</span><br><span class="line">int count = 0;</span><br><span class="line">void insert(int val) &#123;</span><br><span class="line">if (count == array.length) &#123;</span><br><span class="line">int sum = 0;</span><br><span class="line">for (int i = 0; i &lt; array.length; ++i) &#123;</span><br><span class="line">sum = sum + array[i];</span><br><span class="line">&#125;</span><br><span class="line">array[0] = sum;</span><br><span class="line">count = 1;</span><br><span class="line">&#125;</span><br><span class="line">array[count] = val;</span><br><span class="line">++count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用for循环遍历数组求和，并清空数组，将求和之后的sum值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。<br>　　最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为count的位置就可以了，所以最好情况时间复杂度为O(1)。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为O(n)。<br>　　假设数组的长度是n，根据数据插入的位置的不同，我们可以分为n种情况，每种情况的时间复杂度是O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是O(n)。而且，这n+1种情况发生的概率一样，都是1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：1/(n+1)+1/(n+1)+……+n/(n+1)=O(1)。<br>　　每一次O(n)的插入操作，都会跟着n-1次O(1)的插入操作，所以把耗时多的那次操作均摊到接下来的n-1次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是O(1)。这就是均摊分析的大致思路。<br>　　对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系（即有规律），这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前记&quot;&gt;&lt;a href=&quot;#前记&quot; class=&quot;headerlink&quot; title=&quot;前记&quot;&gt;&lt;/a&gt;前记&lt;/h1&gt;&lt;p&gt;　　众所周知，数据结构和算法是编程当中的内功，只有把内功修炼深厚，才能应对各种招式的变化。如果每天做一些机械性质的增删改查，那是注定在编程道
      
    
    </summary>
    
      <category term="算法学习" scheme="https://liuruijie87.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="算法" scheme="https://liuruijie87.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
