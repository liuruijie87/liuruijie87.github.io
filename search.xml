<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[C++ static、const和static const 的初始化]]></title>
    <url>%2F2020%2F08%2F28%2FC%2B%2B%20static%E3%80%81const%E5%92%8Cstatic%20const%20%2F</url>
    <content type="text"><![CDATA[const定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。 static表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。 在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate = 2.25;static关键字只能用于类定义体内部的声明中，定义时不能标示为static。 在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。 cosnt成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。 static成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数。2、不能被声明为virtual const数据成员初始化 const数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。 const数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static cosnt。 123456789101112class Test&#123;public: Test():a(0)&#123;&#125; enum &#123;size1=100,size2=200&#125;;private: const int a;//只能在构造函数初始化列表中初始化 static int b;//在类的实现文件中定义并初始化 const static int c;//与 static const int c;相同。&#125;; int Test::b=0;//static成员变量不能在构造函数初始化列表中初始化，因为它不属于某个对象。cosnt intTest::c=0;//注意：给静态成员变量赋值时，不需要加static修饰符，但要加cosnt。 static成员初始化 类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是：数据类型 类名::静态数据成员名=值； 12345678class foo&#123;public: foo();private:staticint i;&#125;; intfoo::i=20; 这表明： 1、初始化在类体外进行，而前面不加static，以免与一般静态变量或对象相混淆 2、初始化时不加该成员的访问权限控制符private、public等 3、初始化时使用作用域运算符来表明它所属的类，因此，静态数据成员是类的成员而不是对象的成员。 static cosnt 和 const static成员初始化 这两种写法的作用一样，为了便于记忆，在此值说明一种通用的初始化方法： 12345678class Test&#123;public: static const int mask1; const static int mask2;&#125;;constTest::mask1=0xffff;constTest::mask2=0xffff;//它们的初始化没有区别，虽然一个是静态常量一个是常量静态。静态都将存储在全局变量区域，其实最后结果都一样。可能在不同编译器内，不同处理，但最后结果都一样。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毒酒问题]]></title>
    <url>%2F2020%2F08%2F27%2F%E6%B5%8B%E8%AF%95%E6%AF%92%E9%85%92%2F</url>
    <content type="text"><![CDATA[有1000瓶药水，其中只有一瓶有毒。现在用小白鼠进行实验，小白鼠只要服用任意量有毒药水就会在24小时内死亡。问至少要用多少只小白鼠进行实验才能检测出哪瓶药水有毒？ 给1000个瓶分别标上如下标签（10位长度）： 0000000001 （第1瓶） 0000000010 （第2瓶） 0000000011 （第3瓶） …… 1111101000 （第1000瓶） 从编号最后1位是1的所有的瓶子里面取出1滴混在一起（比如从第一瓶，第三瓶，。。。里分别取出一滴混在一起）并标上记号为1。以此类推，从编号第一位是1的所有的瓶子里面取出1滴混在一起并标上记号为10。现在得到有10个编号的混合液，小白鼠排排站，分别标上10，9，。。。1号，并分别给它们灌上对应号码的混合液。24小时过去了，过来验尸：从左到右，死了的小白鼠贴上标签1，没死的贴上0，最后得到一个序号，把这个序号换成10进制的数字，就是有毒的那瓶水的编号。]]></content>
      <categories>
        <category>题集</category>
      </categories>
      <tags>
        <tag>逻辑题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TIME_WAIT和CLOSE_WAIT状态解析]]></title>
    <url>%2F2020%2F08%2F26%2FTIME_WAIT%E5%92%8CCLOSE_WAIT%2F</url>
    <content type="text"><![CDATA[什么是TIME-WAIT和CLOSE-WAIT ? 众所周知，由于socket是全双工的工作模式，一个socket的关闭，是需要四次握手来完成的: 1)主动关闭连接的一方，调用close()；协议层发送FIN包 ; 2)被动关闭的一方收到FIN包后，协议层回复ACK；然后被动关闭的一方，进入CLOSE_WAIT状态，主动关闭的一方等待对方关闭，则进入FIN_WAIT_2状态；此时，主动关闭的一方等待被动关闭一方的应用程序，调用close操作 ; 3)被动关闭的一方在完成所有数据发送后，调用close()操作；此时，协议层发送FIN包给主动关闭的一方，等待对方的ACK，被动关闭的一方进入LAST_ACK状态； 4)主动关闭的一方收到FIN包，协议层回复ACK；此时，主动关闭连接的一方，进入TIME_WAIT状态；而被动关闭的一方，进入CLOSED状态 ; 5)等待2MSL时间，主动关闭的一方，结束TIME_WAIT，进入CLOSED状态 ; 通过上面的一次socket关闭操作，可以得出以下几点： 1)主动关闭连接的一方 – 也就是主动调用socket的close操作的一方，最终会进入TIME_WAIT状态 ; 2)被动关闭连接的一方，有一个中间状态，即CLOSE_WAIT，因为协议层在等待上层的应用程序，主动调用close操作后才主动关闭这条连接 ; 3)TIME_WAIT会默认等待2MSL时间后，才最终进入CLOSED状态； 4)在一个连接没有进入CLOSED状态之前，这个连接是不能被重用的！ TIME_WAIT有什么用？ socket其实就是一个五元组，包括：源IP, 源端口, 目的IP, 目的端口, 类型(TCP or UDP)。这个五元组，即标识了一条可用的连接。比如说，如果本地出口IP是110.122.144.166，那么你的浏览器在连接某一个Web服务器，例如百度的时候，这条socket连接的五元组可能就是：[110.122.144.166:45678, tcp, 110.88.92.104:80] ,源IP为你的出口IP地址 110.122.144.166，源端口为随机端口 45678，目的IP为百度的某一个负载均衡服务器IP 110.88.92.104，端口为HTTP标准的80端口。如果这个时候，你再开一个浏览器，访问百度，将会产生一条新的连接：[110.122.144.166:43678, tcp, 110.88.92.104:80] , 这条新的连接的源端口为一个新的随机端口 43678。 如果来做个类比的话，TIME_WAIT的出现，对应的是你的程序里的异常处理，它的出现，就是为了解决网络的丢包和网络不稳定所带来的其他问题： 1)防止前一个连接【五元组，这里继续以 110.122.144.166:45678, tcp, 110.88.92.104:80 为例】上延迟的数据包或者丢失重传的数据包，被后面复用的连接【前一个连接关闭后，此时你再次访问百度，新的连接可能还是由110.122.144.166:45678, tcp, 110.88.92.104:80 这个五元组来表示，也就是源端口凑巧还是45678】错误的接收（异常：数据丢了，或者传输太慢了），参见下图： SEQ=3的数据包丢失，重传第一次，没有得到ACK确认； 如果没有TIME_WAIT，或者TIME_WAIT时间非常端，那么关闭的连接【110.122.144.166:45678, tcp, 110.88.92.104:80 的状态变为了CLOSED，源端口可被再次利用】，马上被重用【对110.88.92.104:80新建的连接，复用了之前的随机端口45678】，并连续发送SEQ=1,2 的数据包; 此时，前面的连接上的SEQ=3的数据包再次重传，同时，seq的序号刚好也是3（这个很重要，不然，SEQ的序号对不上，就会RST掉），此时，前面一个连接上的数据被后面的一个连接错误的接收; 2)确保连接方能在时间范围内，关闭自己的连接。其实，也是因为丢包造成的，参见下图： 主动关闭方关闭了连接，发送了FIN； 被动关闭方回复ACK同时也执行关闭动作，发送FIN包；此时，被动关闭的一方进入LAST_ACK状态; 主动关闭的一方回去了ACK，主动关闭一方进入TIME_WAIT状态； 但是最后的ACK丢失，被动关闭的一方还继续停留在LAST_ACK状态; 此时，如果没有TIME_WAIT的存在，或者说，停留在TIME_WAIT上的时间很短，则主动关闭的一方很快就进入了CLOSED状态，也即是说，如果此时新建一个连接，源随机端口如果被复用，在connect发送SYN包后，由于被动方仍认为这条连接【五元组】还在等待ACK，但是却收到了SYN，则被动方会回复RST; 造成主动创建连接的一方，由于收到了RST，则连接无法成功; 所以，这里看到了，TIME_WAIT的存在是很重要的，如果强制忽略TIME_WAIT，还是有很高的机率，造成数据混乱，或者短暂性的连接失败。那么，为什么说TIME_WAIT状态会是持续2MSL（2倍的max segment lifetime）呢？这个2MSL，是RFC 793里定义的，这个定义，更多的是一种保障（IP数据包里的TTL，即数据最多存活的跳数，真正反应的才是数据在网络上的存活时间），确保最后丢失了ACK，被动关闭的一方再次重发FIN并等待回复的ACK，一来一去两个来回。内核里，写死了这个MSL的时间为：30秒（RFC里建议的MSL其实是2分钟，但是很多实现都是30秒），所以TIME_WAIT的即为1分钟。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程和线程的五种状态（生命周期）]]></title>
    <url>%2F2020%2F08%2F17%2F%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BA%94%E7%A7%8D%E7%8A%B6%E6%80%81%EF%BC%88%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[进程和线程在创建到销毁的过程中，都会经历五种状态的转换。具体如下： 进程 创建：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态。 就绪：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行。 执行：进程处于就绪状态被调度后，进程进入执行状态。 阻塞：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 线程 新建：创建线程对象 就绪：线程对象已经启动了,但是还没有获取到cpu的执行权 运行：获取到了cpu的执行权 阻塞：没有cpu的执行权,回到就绪 死亡：代码运行完毕,线程消亡 可以看出，进程和线程的状态转换基本是一样的。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>进程和线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[malloc底层实现原理]]></title>
    <url>%2F2020%2F07%2F18%2Fmalloc%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[对于malloc，以前只知道如何用，却不知道它的内部实现原理。这次特意学习了一下，做个记录。下面分析均是基于linux环境下的malloc实现。先总结结论，再逐步展开。 结论 1）当开辟的空间小于128K时，调用brk（）函数，malloc的底层实现是系统调用函数brk（），其主要移动指针_edata(这里的_edata指的是Linux地址空间中堆段的末尾地址，不是数据段的末尾地址) 2）当开辟的空间大于128K时，mmap（）系统调用函数会在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟。 使用场景 当一个进程发生缺页中断的时候，进程会陷入核心态，执行以下操作： 1）检查要访问的虚拟地址是否合法 2）查找/分配一个物理页 3）填充物理页内容（读取磁盘，或者直接置0，或者什么都不做） 4）建立映射关系（虚拟地址到物理地址的映射关系） 5）重复执行发生缺页中断的那条指令 内存分配的原理 从操作系统角度看，进程分配内存有两种方式，分别由两个系统调用完成：brk 和 mmap (不考虑共享内存) 1）brk是将数据段（.data）的最高地址指针_edata往高地址推 2）mmap是在进程的虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空闲的虚拟内存。 这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。 具体分配过程情况一：malloc小于128K的内存，使用brk分配 将_edata往高地址推(只分配虚拟空间，不对应物理内存(因此没有初始化)，第一次读/写数据时，引起内核缺页中断，内核才分配对应的物理内存，然后虚拟地址空间建立映射关系)，如下图： 1、进程启动的时候，其（虚拟）内存空间的初始布局如图1所示。 2、进程调用A=malloc(30K)以后，内存空间如图2。 malloc函数会调用brk系统调用，将_edata指针往高地址推30K，就完成虚拟内存分配，要注意：_edata+30K只是完成虚拟地址的分配，A这块内存现在还是没有物理页与之对应的，等到进程第一次读写A这块内存的时候，发生缺页中断，这个时候，内核才分配A这块内存对应的物理页。也就是说，如果用malloc分配了A这块内容，然后从来不访问它，那么，A对应的物理页是不会被分配的。 3、进程调用B=malloc(40K)以后，内存空间如图3。 情况二：malloc大于128K的内存，使用mmap分配（munmap释放） 4、进程调用C=malloc(200K)以后，内存空间如图4。 默认情况下，malloc函数分配内存，如果请求内存大于128K（可由M_MMAP_THRESHOLD选项调节），那就不是去推_edata指针了，而是利用mmap系统调用，从堆和栈的中间分配一块虚拟内存，这样做主要是因为:brk分配的内存需要等到高地址内存释放以后才能释放（例如，在B释放之前，A是不可能释放的，因为只有一个_edata 指针，这就是内存碎片产生的原因），而mmap分配的内存可以单独释放。 5、进程调用D=malloc(100K)以后，内存空间如图5。 6、进程调用free(C)以后，C对应的虚拟内存和物理内存一起释放。 7、进程调用free(B)以后，如图7所示。 B对应的虚拟内存和物理内存都没有释放，因为只有一个_edata指针，如果往回推，那么D这块内存怎么办呢？当然，B这块内存，是可以重用的，如果这个时候再来一个40K的请求，那么malloc很可能就把B这块内存返回回去了。 8、进程调用free(D)以后，如图8所示B和D连接起来，变成一块140K的空闲内存。 9，默认情况下，当最高地址空间的空闲内存超过128K（可由M_TRIM_THRESHOLD选项调节）时，执行内存紧缩操作（trim）。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩，变成图9所示。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>malloc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优先队列的理解-与堆排序的比较]]></title>
    <url>%2F2020%2F07%2F12%2F%E5%A4%A7%E9%A1%B6%E5%A0%86%E5%B0%8F%E9%A1%B6%E5%A0%86%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[优先队列 priority_queue，头文件#include 。 priority_queue&lt;int, vector, greater&gt; 表示队列内部是小顶堆，队列输出为升序序列（输出过程是小的先输出）。 priority_queue&lt;int, vector, less&gt; 表示队列内部是大顶堆，队列输出为降序序列。（优先队列默认即为大顶堆） 这里要与堆排序中的升序降序情况区别开来，在堆排序中，一般是对数组中的元素进行排序，如果要进行升序排序（即排序后的结果是升序的，并没有规定按什么顺序输出，排完之后数组中的元素变为升序），则利用大顶堆，每次调整后将堆顶元素（当前堆中最大元素）和最后一个元素交换，即从后往前变成有序的。同理，在降序排序中，要利用小顶堆，也是每次调整后将堆顶元素（当前堆中最小元素）和最后一个元素交换，从后往前变成有序的。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mmap详解]]></title>
    <url>%2F2020%2F07%2F02%2Fmmap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[mmap基础概念 mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示： 由上图可以看出，进程的虚拟地址空间，由多个虚拟内存区域构成。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即具有同样特性的连续地址范围。上图中所示的text数据段（代码段）、初始数据段、BSS数据段、堆、栈和内存映射，都是一个独立的虚拟内存区域。而为内存映射服务的地址空间处在堆栈之间的空余部分。linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示： vm_area_struct结构中包含区域起始和终止地址以及其他相关信息，同时也包含一个vm_ops指针，其内部可引出所有针对这个区域可以使用的系统调用函数。这样，进程对某一虚拟内存区域的任何操作需要用要的信息，都可以从vm_area_struct中获得。mmap函数就是要创建一个新的vm_area_struct结构，并将其与文件的物理磁盘地址相连。 mmap内存映射原理 mmap内存映射的实现过程，总的来说可以分为三个阶段： （一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域 1、进程在用户空间调用库函数mmap，原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); 2、在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址 3、为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化 4、将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中 （二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系 5、为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护着和这个已打开文件相关各项信息。 6、通过该文件的文件结构体，链接到file_operations模块，调用内核函数mmap，其原型为：int mmap(struct file *filp, struct vm_area_struct *vma)，不同于用户空间库函数。 7、内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址。 8、通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，这片虚拟地址并没有任何数据关联到主存中。 （三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝 注：前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。 9、进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常。 10、缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。 11、调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中。 12、之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。 注：修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步,这样所写的内容就能立即保存到文件里了。 mmap和常规文件操作的区别 首先简单看一下常规文件系统操作（调用read/fread等类函数）中，函数的调用过程： 1、进程发起读文件请求。 2、内核通过查找进程文件符表，定位到内核已打开文件集上的文件信息，从而找到此文件的inode。 3、inode在address_space上查找要请求的文件页是否已经缓存在页缓存中。如果存在，则直接返回这片文件页的内容。 4、如果不存在，则通过inode定位到文件磁盘地址，将数据从磁盘复制到页缓存。之后再次发起读页面过程，进而将页缓存中的数据发给用户进程。 总结来说，常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。写操作也是一样，待写入的buffer在内核空间不能直接访问，必须要先拷贝至内核空间对应的主存，再写回磁盘中（延迟写回），也是需要两次数据拷贝。 而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。 总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高。 mmap优点总结 由上文讨论可知，mmap优点共有一下几点： 1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。 2、实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。 3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。 4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。 mmap相关函数 函数原型 12345678910111213141516171819202122232425262728293031323334353637383940void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); 返回说明:成功执行时，mmap()返回被映射区的指针。失败时，mmap()返回MAP_FAILED[其值为(void *)-1]， error被设为以下的某个值： EACCES：访问出错 EAGAIN：文件已被锁定，或者太多的内存已被锁定 EBADF：fd不是有效的文件描述词 EINVAL：一个或者多个参数无效 ENFILE：已达到系统对打开文件的限制 ENODEV：指定文件所在的文件系统不支持内存映射 ENOMEM：内存不足，或者进程已超出最大内存映射数量 EPERM：权能不足，操作不允许 ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志 SIGSEGV：试着向只读区写入 SIGBUS：试着访问不属于进程的内存区 参数: start：映射区的开始地址 length：映射区的长度 prot：期望的内存保护标志，不能与文件的打开模式冲突。是以下的某个值，可以通过or运算合理地组合在一起 PROT_EXEC ：页内容可以被执行 PROT_READ ：页内容可以被读取 PROT_WRITE ：页可以被写入 PROT_NONE ：页不可访问 flags：指定映射对象的类型，映射选项和映射页是否可以共享。它的值可以是一个或者多个以下位的组合体 MAP_FIXED //使用指定的映射起始地址，如果由start和len参数指定的内存区重叠于现存的映射空间，重叠部分将会被丢弃。如果指定的起始地址不可用，操作将会失败。并且起始地址必须落在页的边界上。 MAP_SHARED //与其它所有映射这个对象的进程共享映射空间。对共享区的写入，相当于输出到文件。直到msync()或者munmap()被调用，文件实际上不会被更新。 MAP_PRIVATE //建立一个写入时拷贝的私有映射。内存区域的写入不会影响到原文件。这个标志和以上标志是互斥的，只能使用其中一个。 MAP_DENYWRITE //这个标志被忽略。 MAP_EXECUTABLE //同上 MAP_NORESERVE //不要为这个映射保留交换空间。当交换空间被保留，对映射区修改的可能会得到保证。当交换空间不被保留，同时内存不足，对映射区的修改会引起段违例信号。 MAP_LOCKED //锁定映射区的页面，从而防止页面被交换出内存。 MAP_GROWSDOWN //用于堆栈，告诉内核VM系统，映射区可以向下扩展。 MAP_ANONYMOUS //匿名映射，映射区不与任何文件关联。 MAP_ANON //MAP_ANONYMOUS的别称，不再被使用。 MAP_FILE //兼容标志，被忽略。 MAP_32BIT //将映射区放在进程地址空间的低2GB，MAP_FIXED指定时会被忽略。当前这个标志只在x86-64平台上得到支持。 MAP_POPULATE //为文件映射通过预读的方式准备好页表。随后对映射区的访问不会被页违例阻塞。 MAP_NONBLOCK //仅和MAP_POPULATE一起使用时才有意义。不执行预读，只为已存在于内存中的页面建立页表入口。 fd：有效的文件描述词。如果MAP_ANONYMOUS被设定，为了兼容问题，其值应为-1 offset：被映射对象内容的起点 相关函数 12345678int munmap( void * addr, size_t len ) //成功执行时，munmap()返回0。失败时，munmap返回-1，error返回标志和mmap一致；//该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小；//当映射关系解除后，对原来映射地址的访问将导致段错误发生。 int msync( void *addr, size_t len, int flags )//一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。//可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。 mmap使用细节 1、使用mmap需要注意的一个关键点是，mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。 2、内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。具体情形参见“情形三”。 3、映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。 在上面的知识前提下，我们下面看看如果大小不是页的整倍数的具体情况： 情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。 分析：因为单位物理页面的大小是4096字节，虽然被映射的文件只有5000字节，但是对应到进程虚拟地址区域的大小需要满足整页大小，因此mmap函数执行后，实际映射到虚拟内存区域8192个 字节，5000~8191的字节部分用零填充。映射后的对应关系如下图所示： 此时： （1）读/写前5000个字节（0-4999），会返回操作文件内容。 （2）读字节5000-8191时，结果全为0。写5000-8191时，进程不会报错，但是所写的内容不会写入原文件中 。 （3）读/写8192以外的磁盘部分，会返回一个SIGSECV错误。 ##情形二：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射15000字节到虚拟内存中，即映射大小超过了原始文件的大小。 分析：由于文件的大小是5000字节，和情形一一样，其对应的两个物理页。那么这两个物理页都是合法可以读写的，只是超出5000的部分不会体现在原文件中。由于程序要求映射15000字节，而文件只占两个物理页，因此8192字节~15000字节都不能读写，操作时会返回异常。如下图所示： 此时： （1）进程可以正常读/写被映射的前5000字节(0-4999)，写操作的改动会在一定时间后反映在原文件中。 （2）对于5000-8191字节，进程可以进行读写过程，不会报错。但是内容在写入前均为0，另外，写入后不会反映在文件中。 （3）对于8192-14999字节，进程不能对其进行读写，会报SIGBUS错误。 （4）对于15000以外的字节，进程不能对其读写，会引发SIGSEGV错误。 情形三：一个文件初始大小为0，使用mmap操作映射了1000*4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。 分析：如果在映射建立之初，就对文件进行读写操作，由于文件大小为0，并没有合法的物理页对应，如同情形二一样，会返回SIGBUS错误。 但是如果每次操作ptr读写前，先增加文件的大小，那么ptr在文件大小内部的操作就是合法的。例如，文件扩充4096字节，ptr就能操作ptr ~ [ (char)ptr + 4095]的空间。只要文件扩充的范围在1000个物理页（映射范围）内，ptr都可以对应操作相同的大小。这样，方便随时扩充文件空间，随时写入文件，不造成空间浪费。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>mmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程学习笔记（五）--select、poll、epoll比较]]></title>
    <url>%2F2020%2F06%2F26%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%94%EF%BC%89--select-poll-epoll%2F</url>
    <content type="text"><![CDATA[select介绍 select创建了3个文件描述符集（fd_set）并拷贝到内核中，分别监听读、写、异常动作。select可以监听的文件描述符受到单个进程所能打开的fd的限制，默认为1024。采用轮询方式，遍历所有的fd，最后返回一个文件描述符是否就绪的mask掩码，并根据mask掩码给fd_set赋值。将之前的fd_set拷贝传出到用户态并返回就绪的文件描述符的总个数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。应用程序索引就绪文件描述符的时间复杂度是O(n)。再次调用select时，需要将新的fd_set监听文件描述符拷贝传入进内核。select只能工作在相对较低下的LT模式。 select的缺点 （1）select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。 （2）对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。 （3）需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll介绍 将struct_pollfd结构体数组拷贝到内核中进行监听。poll采用链表poll_list来进行文件描述符的存储，因此poll可以监听的文件描述符数为系统可以打开的最大文件描述符数（65535）。采用轮询方式，查询每个fd的状态，如果就绪，内核就修改fd对应的revents的值，而events成员保持不变，因此下次调用poll时，应用程序无需重置pollfd类型的事件集参数。将之前传入的struct_pollfd结构体数组拷贝传出到用户态，并返回就绪文件描述符的总个数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判读。应用程序索引就绪文件描述符的时间复杂度是O(n)。poll只能工作在相对较低下的LT模式。 poll的缺点 （1）大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 （2）poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 epoll介绍 执行epoll_create()函数会在内核创建一颗红黑树rb_node以及就绪链表rdllist(存放已经就绪的文件描述符)，监听的文件描述符数为系统可以打开的最大文件描述符数（65535）。接着用户执行的epoll_ctl()函数将epoll_event结构体拷贝传入内核，内核会在红黑树上添加相应的结点，并注册回调函数ep_poll_callback()，内核在检测到某文件描述符可读/可写时就调用回调函数callback,该回调函数将文件描述符放入就绪链表rdllist中。epoll_wait()函数只需要观察rdllist中有无就绪的文件描述符即可，内核将就绪的文件描述符事件复制到传入的epoll_event结构体数组中返回给用户空间，所以用户只用遍历依次处理即可，即应用程序索引就绪文件描述符的时间复杂度是O（1）。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存传递的，减少了不必要的拷贝。再次调用epoll系统调用，不用重建红黑树，直接沿用已经存在的即可。epoll支持ET模式，当内核将该事件通知给用户后，用户必须立即处理，这样就减少了可读、可写和异常事件被触发的次数。 epoll的优点 （1）没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 （2）效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 （3）内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 epoll对文件描述符操作的两种模式 （1）LT（level_trigger）模式：是缺省的工作方式，并且同时支持block和no-block_socket，当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 （2）ET（edge_trigger）模式：)是高速工作方式，只支持no-block_socket，当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 select、poll、epoll区别 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) 如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。 为什么epoll比select和poll更高效？（1）减少了用户态和内核态之间文件描述符的拷贝 select创建了3个文件描述符集（fd_set）并拷贝到内核中，分别监听读、写、异常事件。内核分配相关数据结构（fd_set_bits），内核在检测到有就绪事件后，就修改用户传进来的fd_set的值以告知用户有就绪的文件描述符。将文件描述符fd_set拷贝传出到用户态并返回就绪的文件描述符的总个数。内核删除和文件描述符相关的数据结构，由于内核修改了用户传进来的fd_set文件描述符集，下次调用select前必须要重置fd_set，然后重新传给内核，内核再重新拷贝一份，重新分配数据结构。 poll系统调用将struct_pollfd结构体数组拷贝到内核中进行监听，内核分配相关数据结构poll_list,用来存储监听的文件描述符，然后调用所有fd对应的poll(将current挂到各个fd对应的设备等待队列上)，内核在检测到有就绪事件后，就修改fd对应的revents的值用来告知用户有就绪的文件描述符，而events成员保持不变，因此下次调用poll时，应用程序无需重置pollfd类型的事件集参数。将之前传入的struct_pollfd结构体数组拷贝传出到用户态，并返回就绪文件描述符的总个数。内核删除和文件描述符相关的数据结构，下次调用poll需要将struct pollfd重新传给内核，内核在重新拷贝一份，重新分配数据结构。 epoll执行epoll_create()函数会在内核创建一颗红黑树rb_node以及就绪链表rdllist(存放已经就绪的文件描述符)，接着用户执行的epoll_ctl()函数将epoll_event结构体拷贝传入内核，内核会在红黑树上添加相应的结点，内核将就绪的文件描述符事件复制到传入的epoll_event结构体数组中返回给用户空间，系统调用在返回时采用mmap共享存储区，需要拷贝的次数大大减少。由于epoll创建的有关文件描述符的数据结构本身就存在于内核态中。下一次调用epoll系统调用时，不需要再次拷贝用户空间所要监听的文件描述符，也不需要重新构建红黑树和就绪链表等相关数据结构，直接沿用已经存在的数据结构。 （2）减少了对就绪文件描述符的遍历 select和poll采用轮询的方式来检查文件描述符是否处于就绪状态。并且内核修改用户传进来的fd_set和pollfd结构体的成员的revents值以告知用户有文件描述符就绪，但是用户并不知道有哪些文件描述符处于就绪态，需要遍历查找就绪文件描述符，因此，应用程序索引就绪文件描述符的时间复杂度为O（n）。而epoll采用回调机制。在调用epoll_ctl时，已经将用户感兴趣的事件传给了内核，内核会维持一个内核事件表，记录用户感兴趣的事件，就绪事件发生时，驱动设备调用回调函数ep_poll_callback()将就绪的fd挂到rdllist上。用户调用epoll_wait时，将rdllist上就绪的文件描述符发送给用户。此时发送给用户的都是就绪的fd。因此，应用程序索引就绪文件描述符的时间复杂度为O（1）。 （3）select和poll只支持LT模式，而epoll支持高效的ET模式，并且epoll还支持EPOLLONESHOT事件。 LT模式（电平触发）：LT模式是默认的工作模式，当检测到文件描述符上有事件发生并将此事件通知给应用程序，应用程序可以不立即处理该事件，下次调用会再次响应应用程序并通知此事件。 ET模式（边沿触发）：当检测到文件描述符上有事件发生并将此事件通知给应用程序，应用程序必须立即处理该事件，如果没处理或者没处理完，下次调用不会再响应应用程序并通知此事件。 ET模式很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高，epoll工作在ET模式的时候，必须使用非阻塞的套接字，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 注意即使使用ET模式，一个socket上的某个事件还是可能被触发多次，这在并发程序中就会引发一个问题。比如一个线程在读取完某个socket上的数据开始处理这些数据的时候，而在数据的处理过程中这个socket上又有新数据可读，这时另一个线程被唤醒来处理新数据，于是就出现了两个线程同时操作一个socket的局面。因此需要使用epoll的EPOLLONESHOT事件实现。对于注册了EPOLLONESHOT事件的文件描述符，操作系统最多触发其上的一个读、写或异常事件，且只触发一次。当一个线程在处理socket时，其它线程是不可能有机会操作该socket的。注册了EPOLLONESHOT事件的socket一旦被某个线程处理完，该线程就应该立即重置这个socket上的EPOLLONESHOT事件，以确保这个socket下次可读时，其EPOLLIN事件可被触发，进而让其它线程有机会处理这个socket。使用EPOLLONESHOT事件能进一步减少可读、可写和异常事件的被触发的次数。 无论哪种情况下，eopll都比select和poll高效吗？epoll适用于连接较多，活动数量较少的情况。 (1)epoll为了实现返回就绪的文件描述符，维护了一个红黑树和好多个等待队列，内核开销很大。如果此时监听了很少的文件描述符，底层的开销会得不偿失； (2)epoll中注册了回调函数，当有事件发生时，服务器设备驱动调用回调函数将就绪的fd挂在rdllist上，如果有很多的活动，同一时间需要调用的回调函数数量太多，服务器压力太大。 select和poll适用于连接较少的情况。 当select和poll上监听的fd数量较少，内核通知用户现在有就绪事件发生，应用程序判断当前是哪个fd就绪所消耗的时间复杂度就会大大减小。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程学习笔记（四）--几种高性能方案]]></title>
    <url>%2F2020%2F06%2F14%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89--%E9%AB%98%E6%80%A7%E8%83%BD%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[I/O多路复用 我们假设设计了这样一个应用程序，该程序从标准输入接收数据输入，然后通过套接字发送出去，同时，该程序也通过套接字接收对方发送的数据流。我们可以使用fgets方法等待标准输入，但是一旦这样做，就没有办法在套接字有数据的时候读出数据；我们也可以使用read方法等待套接字有数据返回，但是这样做，也没有办法在标准输入有数据的情况下，读入数据并发送给对方。 I/O多路复用的设计初衷就是解决这样的场景。我们可以把标准输入、套接字等都看做I/O的一路，多路复用的意思，就是在任何一路I/O有“事件”发生的情况下，通知应用程序去处理相应的I/O事件，这样我们的程序就变成了“多面手”，在同一时刻仿佛可以处理多个I/O事件。像刚才的例子，使用I/O复用以后，如果标准输入有数据，立即从标准输入读入数据，通过套接字发送出去；如果套接字有数据可以读，立即可以读出数据。 select函数 select函数就是这样一种常见的I/O多路复用技术，使用select函数，通知内核挂起进程，当一个或多个I/O事件发生后，控制权返还给应用程序，由应用程序进行I/O事件的处理。select函数的使用方法 select函数的使用方法有点复杂，我们先看一下它的声明： 12int select(int maxfd, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct *timeval);返回：若有就绪描述符则为其数目，若超时则为 0，若出错则为 -1 在这个函数中，maxfd表示的是待测试的描述符基数，它的值是待测试的最大描述符加1。比如现在的select待测试的描述符集合是{0,1,4}，那么maxfd就是5，紧接着的是三个描述符集合，分别是读描述符集合readset、写描述符集合writeset和异常描述符集合exceptset，这三个分别通知内核，在哪些描述符上检测数据可以读，可以写和有异常发生。 那么如何设置这些描述符集合呢？以下的宏可以帮助到我们。 1234void FD_ZERO(fd_set *fdset); void FD_SET(int fd, fd_set *fdset); void FD_CLR(int fd, fd_set *fdset); int FD_ISSET(int fd, fd_set *fdset); 如果刚入门，理解这些宏可能有些困难。我们可以这样想象，下面一个向量代表了一个描述符集合，其中，这个向量的每个元素都是二机制数中的0或者1。 a[maxfd-1], …, a[1], a[0] 我们按照这样的思路来理解这些宏：其中0代表不需要处理，1代表需要处理。实际上，很多系统是用一个整型数组来表示一个描述字集合的，一个32位的整型数可以表示32个描述字，例如第一个整型数表示0-31描述字，第二个整型数可以表示32-63描述字，以此类推。这个时候再来理解为什么描述字集合{0,1,4}，对应的maxfd是5，而不是4，就比较方便了。因为这个向量对应的是这样的：a[4],a[3],a[2],a[1],a[0]。待测试的描述符个数显然是5，而不是4。 三个描述符集合中的每一个都可以设置成空，这样就表示不需要内核进行相关的检测。最后一个参数是timeval结构体时间： 12345struct timeval &#123; long tv_sec; /* seconds */ long tv_usec; /* microseconds */ &#125;; 这个参数设置成不同的值，会有不同的可能：第一个可能是设置成空(NULL)，表示如果没有I/O事件发生，则select一直等待下去。第二个可能是设置一个非零的值，这个表示等待固定的一段时间后从select阻塞调用中返回。第三个可能是将tv_sec和tv_usec都设置成0，表示根本不等待，检测完毕立即返回。这种情况使用得比较少。 select函数检测套接字可读有以下几种情况：第一种情况是套接字接收缓冲区有数据可以读，如果我们使用read函数去执行读操作，肯定不会被阻塞，而是会直接读到这部分数据。第二种情况是对方发送了FIN，使用read函数执行读操作，不会被阻塞，直接返回0。第三种情况是针对一个监听套接字而言的，有已经完成的连接建立，此时使用accept函数去执行不会阻塞，直接返回已经完成的连接。第四种情况是套接字有错误待处理，使用read函数去执行读操作，不阻塞，且返回-1。总结成一句话就是，内核通知我们套接字有数据可以读了，使用read函数不会阻塞。 select检测套接字可写，完全是基于套接字本身的特性来说的，具体来说有以下几种情况。第一种是套接字发送缓冲区足够大，如果我们使用非阻塞套接字进行write操作，将不会被阻塞，直接返回。第二种是连接的写半边已经关闭，如果继续进行写操作将会产生SIGPIPE信号。第三种是套接字上有错误待处理，使用write函数去执行写操作，不阻塞，且返回 -1。总结成一句话就是，内核通知我们套接字可以往里写了，使用write函数就不会阻塞。 poll：另一种I/O多路复用 select方法是多个UNIX平台支持的非常常见的I/O多路复用技术，它通过描述符集合来表示检测的I/O对象，通过三个不同的描述符集合来描述I/O事件：可读、可写和异常。但是select有一个缺点，那就是所支持的文件描述符的个数是有限的。在Linux系统中，select的默认最大值为1024。 poll是除了select之外，另一种普遍使用的I/O多路复用技术，和select相比，它和内核交互的数据结构有所变化，另外，也突破了文件描述符的个数限制。下面是poll函数的原型： 12int poll(struct pollfd *fds, unsigned long nfds, int timeout);返回值：若有就绪描述符则为其数目，若超时则为 0，若出错则为 -1 这个函数里面输入了三个参数，第一个参数是一个pollfd的数组。其中pollfd的结构如下： 123456struct pollfd &#123; int fd; /* file descriptor */ short events; /* events to look for */ short revents; /* events returned */ &#125;; 这个结构体由三个部分组成，首先是描述符fd，然后是描述符上待检测的事件类型events，注意这里的events可以表示多个不同的事件，具体的实现可以通过使用二进制掩码位操作来完成，例如，POLLIN和POLLOUT可以表示读和写事件。 123#define POLLIN 0x0001 /* any readable data available */ #define POLLPRI 0x0002 /* OOB/Urgent readable data */ #define POLLOUT 0x0004 /* file descriptor is writeable */ 和select非常不同的地方在于，poll每次检测之后的结果不会修改原来的传入值，而是将结果保留在revents字段中，这样就不需要每次检测完都得重置待检测的描述字和感兴趣的事件。我们可以把revents理解成“returned events”。 events类型的事件可以分为两大类。第一类是可读事件，有以下几种： 1234#define POLLIN 0x0001 /* any readable data available */ #define POLLPRI 0x0002 /* OOB/Urgent readable data */ #define POLLRDNORM 0x0040 /* non-OOB/URG data available */ #define POLLRDBAND 0x0080 /* OOB/Urgent readable data */ 一般我们在程序里面有POLLIN即可。套接字可读事件和select的readset基本一致，是系统内核通知应用程序有数据可以读，通过read函数执行操作不会被阻塞。 第二类是可写事件，有以下几种： 123#define POLLOUT 0x0004 /* file descriptor is writeable */ #define POLLWRNORM POLLOUT /* no write type differentiation */ #define POLLWRBAND 0x0100 /* OOB/Urgent data can be written */ 一般我们在程序里面统一使用POLLOUT。套接字可写事件和select的writeset基本一致，是系统内核通知套接字缓冲区已准备好，通过write函数执行写操作不会被阻塞。以上两大类的事件都可以在“returned events”得到复用。还有另一大类事件，没有办法通过poll向系统内核递交检测请求，只能通过“returned events”来加以检测，这类事件是各种错误事件。 123#define POLLERR 0x0008 /* 一些错误发送 */ #define POLLHUP 0x0010 /* 描述符挂起 */ #define POLLNVAL 0x0020 /* 请求的事件无效 */ 我们再回过头看一下poll函数的原型。参数nfds描述的是数组fds的大小，简单说，就是向poll申请的事件检测的个数。最后一个参数timeout，描述了poll的行为。如果是一个小于0的数，表示在有事件发生之前永远等待；如果是0，表示不阻塞进程，立即返回；如果是一个大于0的数，表示poll调用方等待指定的毫秒数后返回。关于返回值，当有错误发生时，poll函数的返回值为-1；如果在指定的时间到达之前没有任何事件发生，则返回0，否则就返回检测到的事件个数，也就是“returned events”中非0的描述符个数。 poll函数有一点非常好，如果我们不想对某个pollfd结构进行事件检测，可以把它对应的pollfd结构的fd成员设置成一个负值。这样，poll函数将忽略这样的events事件，检测完成以后，所对应的“returned events”的成员值也将设置为0。和select函数对比一下，我们发现poll函数和select不一样的地方就是，在select里面，文件描述符的个数已经随着fd_set的实现而固定，没有办法对此进行配置；而在poll函数里，我们可以控制pollfd结构的数组大小，这意味着我们可以突破原来select函数最大描述符的限制，在这种情况下，应用程序调用者需要分配pollfd数组并通知poll函数该数组的大小。 poll是另一种在各种UNIX系统上被广泛支持的I/O多路复用技术，虽然名声没有select那么响，能力一点不比select差，而且因为可以突破select文件描述符的个数限制，在高并发的场景下尤其占优势。 非阻塞I/O 当应用程序调用阻塞I/O完成某个操作时，应用程序会被挂起，等待内核完成操作，感觉应用程序像是被“阻塞”了一样。实际上，内核所做的事情是将CPU时间切换给其他有需要的进程，网络应用程序在这种情况下就会得不到CPU时间做该做的事情。非阻塞I/O则不然，当应用程序调用非阻塞I/O完成某个操作时，内核立即返回，不会把CPU时间切换给其他进程，应用程序在返回后，可以得到足够的CPU时间继续完成其他事情。 非阻塞I/O读操作 如果套接字对应的接收缓冲区没有数据可读，在非阻塞情况下read调用会立即返回，一般返回EWOULDBLOCK或EAGAIN出错信息。在这种情况下，出错信息是需要小心处理，比如后面再次调用read操作，而不是直接作为错误直接返回。这就好像去书店买书没买到离开一样，需要不断进行又一次轮询处理。 非阻塞I/O写操作 在阻塞I/O情况下，write函数返回的字节数，和输入的参数总是一样的。而在非阻塞I/O的情况下，如果套接字的发送缓冲区已达到了极限，不能容纳更多的字节，那么操作系统内核会尽最大可能从应用程序拷贝数据到发送缓冲区中，并立即从write等函数调用中返回。可想而知，在拷贝动作发生的瞬间，有可能一个字符也没拷贝，有可能所有请求字符都被拷贝完成，那么这个时候就需要返回一个数值，告诉应用程序到底有多少数据被成功拷贝到了发送缓冲区中，应用程序需要再次调用write函数，以输出未完成拷贝的字节。 write等函数是可以同时作用到阻塞I/O和非阻塞I/O上的，为了复用一个函数，处理非阻塞和阻塞I/O多种情况，设计出了写入返回值，并用这个返回值表示实际写入的数据大小。也就是说，非阻塞I/O和阻塞I/O处理的方式是不一样的。非阻塞I/O需要这样：拷贝→返回→再拷贝→再返回。而阻塞I/O需要这样：拷贝→直到所有数据拷贝至发送缓冲区完成→返回。不过在实战中，可以不用区别阻塞和非阻塞I/O，使用循环的方式来写入数据就好了。只不过在阻塞I/O的情况下，循环只执行一次就结束了。 下面通过一张表来总结一下read和write在阻塞模式和非阻塞模式下的不同行为特性： 关于read和write还有几个结论: 1.read总是在接收缓冲区有数据时就立即返回，不是等到应用程序给定的数据充满才返回。当接收缓冲区为空时，阻塞模式会等待，非阻塞模式立即返回-1，并有EWOULDBLOCK或EAGAIN错误。 2.和read不同，阻塞模式下，write只有在发送缓冲区足以容纳应用程序的输出字节时才返回；而非阻塞模式下，则是能写入多少就写入多少，并返回实际写入的字节数。 3.阻塞模式下的write有个特例，就是对方主动关闭了套接字，这个时候write调用会立即返回，并通过返回值告诉应用程序实际写入的字节数，如果再次对这样的套接字进行write操作，就会返回失败。失败是通过返回值-1来通知到应用程序的。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程学习笔记（三）--数据传输、报文读取]]></title>
    <url>%2F2020%2F06%2F01%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89--%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E3%80%81%E6%8A%A5%E6%96%87%E8%AF%BB%E5%8F%96%2F</url>
    <content type="text"><![CDATA[TIME_WAIT相关理解TIME_WAIT发生的场景 应用服务需要通过发起TCP连接对外提供服务。每个连接会占用一个本地端口，当在高并发的情况下，TIME_WAIT状态的连接过多，多到把本机可用的端口耗尽，应用服务对外表现的症状，就是不能正常工作了。当过了一段时间之后，处于TIME_WAIT的连接被系统回收并关闭后，释放出本地端口可供使用，应用服务对外表现为可以正常工作。这样周而复始，便会出现了一会儿不可以，过一两分钟又可以正常工作的现象。 至于为什么会产生这么多的TIME_WAIT连接，这要从TCP的四次挥手说起。先来回顾一下四次挥手的过程，如下图。 TCP连接终止时，主机1先发送FIN报文，主机2进入CLOSE_WAIT状态，并发送一个ACK应答，同时，主机2通过read调用获得EOF，并将此结果通知应用程序进行主动关闭操作，发送FIN报文。主机1在接收到FIN报文后发送ACK应答，此时主机1进入TIME_WAIT状态。主机1在TIME_WAIT停留持续时间是固定的，是最长分节生命期MSL（maximum segment lifetime）的两倍，一般称之为2MSL。和大多数BSD派生的系统一样，Linux系统里有一个硬编码的字段，名称为TCP_TIMEWAIT_LEN，其值为60秒。也就是说，Linux系统停留在TIME_WAIT的时间为固定的60秒。一定要记住，只有发起连接终止的一方会进入TIME_WAIT状态。 TIME_WAIT的作用 为什么不直接进入CLOSED状态，而要停留在TIME_WAIT这个状态？这要从两个方面来说。 首先，这样做是为了确保最后的ACK能让被动关闭方接收，从而帮助其正常关闭。TCP在设计的时候，做了充分的容错性设计，比如，TCP假设报文会出错，需要重传。在这里，如果图中主机1的ACK报文没有传输成功，那么主机2就会重新发送FIN报文。如果主机1没有维护TIME_WAIT状态，而直接进入CLOSED状态，它就失去了当前状态的上下文，只能回复一个RST操作，从而导致被动关闭方出现错误。现在主机1知道自己处于TIME_WAIT的状态，就可以在接收到FIN报文之后，重新发出一个ACK报文，使得主机2可以进入正常的CLOSED状态。 第二个理由和连接“化身”和报文迷走有关系，为了让旧连接的重复分节在网络中自然消失。我们知道，在网络中，经常会发生报文经过一段时间才能到达目的地的情况，产生的原因是多种多样的，如路由器重启，链路突然出现故障等。如果迷走报文到达时，发现TCP连接四元组（源IP，源端口，目的IP，目的端口）所代表的连接不复存在，那么很简单，这个报文自然丢弃。我们考虑这样一个场景，在原连接中断后，又重新创建了一个原连接的“化身”，说是化身，其实是因为这个连接和原先的连接四元组完全相同，如果迷失报文经过一段时间也到达，那么这个报文会被误认为是新连接的一个TCP分节，这样就会对TCP通信产生影响。所以，TCP就设计出了这么一个机制，在一个连接之内，经过2MSL这个时间，足以让两个方向上的所有分组都被丢弃，使得原来连接的分组在网络中都自然消失，再出现的分组一定都是新化身所产生的。 要注意，2MSL的时间是从主机1接收到FIN后发送ACK开始计时的，如果在TIME_WAIT时间内，因为主机1的ACK没有传输到主机2，主机1又接收到了主机2重发的FIN报文，那么2MSL时间将重新计时。道理很简单，因为2MSL的时间，目的是为了让旧连接的所有报文都能自然消亡，现在主机1重新发送了ACK报文，自然需要重新计时，以便防止这个ACK报文对新可能的连接化身造成干扰。 TIME_WAIT的危害与优化 过多的TIME_WAIT的主要危害有两种。第一是内存资源占用，这个目前看来不是太严重，基本可以忽略。第二是对端口资源的占用，一个TCP连接至少消耗一个本地端口。要知道，端口资源也是有限的，一般可以开启的端口为32768～61000，也可以通过net.ipv4.ip_local_po rt_range指定，如果TIME_WAIT状态过多，会导致无法创建新连接。 那么如何优化TIME_WAIT呢？可以通过net.ipv4.tcp_tw_reuse选项，主要有两点：（1）只适用于连接发起方（C/S模型中的客户端）；（2）对应的TIME_WAIT状态的连接创建时间超过1秒才可以被复用。使用这个选项，还有一个前提，需要打开对TCP时间戳的支持，即net.ipv4.tcp_time stamps=1（默认即为1）。 要知道，TCP协议也在与时俱进，RFC1323中实现了TCP拓展规范，以便保证TCP的高可用，并引入了新的TCP选项，两个4字节的时间戳字段，用于记录TCP发送方的当前时间戳和从对端接收到的最新时间戳。由于引入了时间戳，前面提到的2MSL问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。 TCP的一些机制TCP的保持活跃机制 TCP有一个保持活跃的机制叫做Keep-Alive。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的TCP连接已经死亡，系统内核将错误信息通知给上层应用程序。上述的可定义变量，分别被称为保活时间、保活时间间隔和保活探测次数。在Linux系统中，这些变量分别对应sysctl变量net.ipv4.tcp_keepalive_time、net.ipv4.tcp_keepalive_intvl、net.ipv4.tcp_keepalve_probes，默认设置是7200秒（2小时）、75秒和9次探测。 如果开启了TCP保活，需要考虑以下几种情况：第一种，对端程序是正常工作的。当TCP保活的探测报文发送给对端，对端会正常响应，这样TCP保活时间会被重置，等待下一个TCP保活时间的到来。第二种，对端程序崩溃并重启。当TCP保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个RST报文，这样很快就会发现TCP连接已经被重置。第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当TCP保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP会报告该TCP连接已经死亡。 TCP保活机制默认是关闭的，当我们选择打开时，可以分别在连接的两个方向上开启，也可以单独在一个方向上开启。如果开启服务器端到客户端的检测，就可以在客户端非正常断连的情况下清除在服务器端保留的“脏数据”；而开启客户端到服务器端的检测，就可以在服务器无响应的情况下，重新发起连接。 如果使用TCP自身的keep-Alive机制，在Linux系统中，最少需要经过2小时11分15秒才可以发现一个“死亡”连接。这个时间是怎么计算出来的呢？其实是通过2小时，加上75秒乘以9的总和。实际上，对很多对时延要求敏感的系统中，这个时间间隔是不可接受的。所以，必须在应用程序这一层来寻找更好的解决方案。我们可以通过在应用程序中模拟TCP的Keep-Alive机制，来完成在应用层的连接探活。我们可以设计一个PING-PONG的机制，需要保活的一方，比如客户端，在保活时间达到后，发起对连接的PING操作，如果服务器端对PING操作有回应，则重新设置保活时间，否则对探测次数进行计数，如果最终探测次数达到了保活探测次数预先设置的值之后，则认为连接已经无效。这里有两个比较关键的点：第一个是需要使用定时器，这可以通过使用I/O复用自身的机制来实现；第二个是需要设计一个PING-PONG的协议。 理解TCP协议中的动态数据传输从TCP角度看待数据流的发送和接收 我们已经熟悉如何通过套接字发送数据，比如使用write或者send方法来进行数据流的发送。我们已经知道，调用这些接口并不意味着数据被真正发送到网络上，其实，这些数据只是从应用程序中被拷贝到了系统内核的套接字缓冲区中，或者说是发送缓冲区中，等待协议栈的处理。至于这些数据是什么时候被发送出去的，对应用程序来说，是无法预知的。对这件事情真正负责的，是运行于操作系统内核的TCP协议栈实现模块。 流量控制和生产者-消费者模型 我们可以把理想中的TCP协议可以想象成一队运输货物的货车，运送的货物就是TCP数据包，这些货车将数据包从发送端运送到接收端，就这样不断周而复始。我们仔细想一下，货物达到接收端之后，是需要卸货处理、登记入库的，接收端限于自己的处理能力和仓库规模，是不可能让这队货车以不可控的速度发货的。接收端肯定会和发送端不断地进行信息同步，比如接收端通知发送端：“后面那20车你给我等等，等我这里腾出地方你再继续发货。”其实这就是发送窗口和接收窗口的本质，我们把这个叫做“TCP的生产者-消费者”模型。发送窗口和接收窗口是TCP连接的双方，一个作为生产者，一个作为消费者，为了达到一致协同的生产-消费速率、而产生的算法模型实现。说白了，作为TCP发送端，也就是生产者，不能忽略TCP的接收端，也就是消费者的实际状况，不管不顾地把数据包都传送过来。如果都传送过来，消费者来不及消费，必然会丢弃；而丢弃反过使得生产者又重传，发送更多的数据包，最后导致网络崩溃。 TCP的生产者-消费者模型，只是在考虑单个连接的数据传递，但是，TCP数据包是需要经过网卡、交换机、核心路由器等一系列的网络设备的，网络设备本身的能力也是有限的，当多个连接的数据包同时在网络上传送时，势必会发生带宽争抢、数据丢失等，这样，TCP就必须考虑多个连接共享在有限的带宽上，兼顾效率和公平性的控制，这就是拥塞控制的本质。举个形象一点的例子，有一个货车行驶在半夜三点的大路上，这样的场景是断然不需要拥塞控制的。我们可以把网络设备形成的网络信息高速公路和生活中实际的高速公路做个对比。正是因为有多个TCP连接，形成了高速公路上的多队运送货车，高速公路上开始变得熙熙攘攘，这个时候，就需要拥塞控制的接入了。在TCP协议中，拥塞控制是通过拥塞窗口来完成的，拥塞窗口的大小会随着网络状况实时调整。拥塞控制常用的算法有“慢启动”，它通过一定的规则，慢慢地将网络发送数据的速率增加到一个阈值。超过这个阈值之后，慢启动就结束了，另一个叫做“拥塞避免”的算法登场。在这个阶段，TCP会不断地探测网络状况，并随之不断调整拥塞窗口的大小。 现在我们可以发现，在任何一个时刻，TCP发送缓冲区的数据是否能真正发送出去，至少取决于两个因素，一个是当前的发送窗口大小，另一个是拥塞窗口大小，而TCP协议中总是取两者中最小值作为判断依据。比如当前发送的字节为100，发送窗口的大小是200，拥塞窗口的大小是80，那么取200和80中的最小值，就是80，当前发送的字节数显然是大于拥塞窗口的，结论就是不能发送出去。这里千万要分清楚发送窗口和拥塞窗口的区别。发送窗口反应了作为单TCP连接、点对点之间的流量控制模型，它是需要和接收端一起共同协调来调整大小的；而拥塞窗口则是反应了作为多个TCP连接共享带宽的拥塞控制模型，它是发送端独立地根据网络状况来动态调整的。 服务器端程序重启时，地址被占用的原因和解决方法。 我们已经知道，网络编程中，服务器程序需要绑定本地地址和一个端口，然后就监听在这个地址和端口上，等待客户端连接的到来。在实战中，可能会经常碰到一个问题，当服务器端程序重启之后，总是碰到“Address in use”的报错信息，服务器程序不能很快地重启。那么这个问题是如何产生的？我们又该如何避免呢？我们从一个TCP服务器端程序开始说起： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static int count; static void sig_int(int signo) &#123; printf(&quot;\nreceived %d datagrams\n&quot;, count); exit(0); &#125; int main(int argc, char **argv) &#123; int listenfd; listenfd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htonl(INADDR_ANY); server_addr.sin_port = htons(SERV_PORT); int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr)); if(rt1 &lt; 0) &#123; error(1, errno, &quot;bind failed &quot;); &#125; int rt2 = listen(listenfd, LISTENQ); if (rt2 &lt; 0) &#123; error(1, errno, &quot;listen failed &quot;); &#125; signal(SIGPIPE, SIG_IGN); int connfd; struct sockaddr_in client_addr; socklen_t client_len = sizeof(client_addr); if((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) &#123; error(1, errno, &quot;bind failed &quot;); &#125; char message[MAXLINE]; count = 0; for(;;) &#123; int n = read(connfd, message, MAXLINE); if(n &lt; 0) &#123; error(1, errno, &quot;error read&quot;); &#125; else if(n == 0) &#123; error(1, 0, &quot;client closed \n&quot;); &#125; message[n] = 0; printf(&quot;received %d bytes: %s\n&quot;, n, message); count++; &#125; &#125; 这个服务器端程序绑定到一个本地端口，使用的是通配地址ANY，当连接建立之后，从该连接中读取输入的字符流。启动服务器，之后我们使用Telnet登录这个服务器，并在屏幕上输入一些字符，例如：network，good。和我们期望的一样，服务器端打印出Telnet客户端的输入。在Telnet端关闭连接之后，服务器端接收到EOF，也顺利地关闭了连接。服务器端也可以很快重启，等待新的连接到来。 12345$./addressused received 9 bytes: network received 6 bytes: good client closed $./addressused 接下来，我们改变一下连接的关闭顺序。和前面的过程一样，先启动服务器，再使用Telnet作为客户端登录到服务器，在屏幕上输入一些字符。注意接下来的不同，不在Telnet端关闭连接，而是直接使用Ctrl+C的方式在服务器端关闭连接。 1234$telneet 127.0.0.1 9527 network bad Connection closed by foreign host. 我们看到，连接已经被关闭，Telnet客户端也感知连接关闭并退出了。接下来，我们尝试重启服务器端程序。你会发现，这个时候服务端程序重启失败，报错信息为：bind failed: Address already in use。 123456$./addressused received 9 bytes: networkreceived 6 bytes: good client closed $./addressused bind faied: Address already in use(98) 此时我们想到了TIME_WAIT，当连接的一方主动关闭连接，在接收到对端的FIN报文之后，主动关闭连接的一方会在TIME_WAIT这个状态里停留一段时间，这个时间大约为2MSL。如果我们此时使用netstat去查看服务器程序所在主机的TIME_WAIT的状态连接，你会发现有一个服务器程序生成的TCP连接，当前正处于TIME_WAIT状态。通过服务器端发起的关闭连接操作，引起了一个已有的TCP连接处于TME_WAIT状态，正是这个TIME_WAIT的连接，使得服务器重启时，继续绑定在127.0.0.1地址和9527端口上的操作，返回了Address already in use的错误。 重用套接字选项 我们知道，一个TCP连接是通过四元组（源地址、源端口、目的地址、目的端口）来唯一确定的，如果每次Telnet客户端使用的本地端口都不同，就不会和已有的四元组冲突，也就不会有TIME_WAIT的新旧连接化身冲突的问题。事实上，即使在很小的概率下，客户端Telnet使用了相同的端口，从而造成了新连接和旧连接的四元组相同，在现代Linux操作系统下，也不会有什么大的问题，原因是现代Linux操作系统对此进行了一些优化。第一种优化是新连接SYN告知的初始序列号，一定比TIME_WAIT老连接的末序列号大，这样通过序列号就可以区别出新老连接。第二种优化是开启了tcp_timestamps，使得新连接的时间戳比老连接的时间戳大，这样通过时间戳也可以区别出新老连接。在这样的优化之下，一个TIME_WAIT的TCP连接可以忽略掉旧连接，重新被新的连接所使用。这就是重用套接字选项，通过给套接字配置可重用属性，告诉操作系统内核，这样的TCP连接完全可以复用TIME_WAIT状态的连接。代码片段如下： 12int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on)); SO_REUSEADDR套接字选项，允许启动绑定在一个端口，即使之前存在一个和该端口一样的连接。前面的例子已经表明，在默认情况下，服务器端历经创建socket、bind和listen。重启时，如果试图绑定到一个现有连接上的端口，bind操作会失败，但是如果我们在创建socket和bind之间，使用上面的代码片段设置SO_REUSEADDR套接字选项，情况就会不同。 SO_REUSEADDR套接字选项还有一个作用，那就是本机服务器如果有多个地址，可以在不同地址上使用相同的端口提供服务。比如，一台服务器有192.168.1.101和10.10.2.102两个地址，我们可以在这台机器上启动三个不同的HTTP服务，第一个以本地通配地址ANY和端口80启动；第二个以192.168.101和端口80启动；第三个以10.10.2.102和端口80启动。这样目的地址为192.168.101，目的端口为80的连接请求会被发往第二个服务；目的地址为10.10.2.102，目的端口为80的连接请求会被发往第三个服务；目的端口为80的所有其他连接请求被发往第一个服务。我们必须给这三个服务设置SO_REUSEADDR套接字选项，否则第二个和第三个服务调用bind绑定到80端口时会出错。总之，可以总结成一句话：服务器端程序，都应该设置SO_REUSEADDR套接字选项，以便服务端程序可以在极短时间内复用同一个端口启动。 有人可能觉得这不是安全的。其实，单独重用一个套接字不会有任何问题。我们已经知道，TCP连接是通过四元组唯一区分的，只要客户端不使用相同的源端口，连接服务器是没有问题的，即使使用了相同的端口，根据序列号或者时间戳，也是可以区分出新旧连接的。而且，TCP的机制绝对不允许在相同的地址和端口上绑定不同的服务器，即使我们设置SO_REUSEADDR套接字选项，也不可能在ANY通配符地址下和端口9527上重复启动两个服务器实例。如果我们启动第二个服务器实例，不出所料会得到Address already in use的报错，即使当前还没有任何一条有效TCP连接产生。 那么tcp_tw_reuse的内核配置选项和SO_REUSEADDR套接字选项有什么区别呢？其实，这两个东西一点关系也没有。tcp_tw_reuse是内核选项，主要用在连接的发起方。TIME_WAIT状态的连接创建时间超过1秒后，新的连接才可以被复用，注意，这里是连接的发起方；SO_REUSEADDR是用户态的选项，SO_REUSEADDR选项用来告诉操作系统内核，如果端口已被占用，但是TCP连接状态位于TIME_WAIT，可以重用端口。如果端口忙，而TCP处于其他状态，重用端口时依旧得到“Address already in use”的错误信息。注意，这里一般都是连接的服务方。 报文读取和解析 我们知道TCP的报文是以字节流的形式呈现给应用程序的，那么随之而来的一个问题就是，应用程序如何解读字节流呢？这就要说到报文格式和解析了。报文格式实际上定义了字节的组织形式，发送端和接收端都按照统一的报文格式进行数据传输和解析，这样就可以保证彼此能够完成交流。 报文格式最重要的是如何确定报文的边界。常见的报文格式有两种方法，一种是发送端把要发送的报文长度预先通过报文告知给接收端；另一种是通过一些特殊的字符来进行边界的划分。 显式编码报文长度，就是把要发送的报文长度预先通过报文告知接收端，如下图。 由图可以看出，这个报文的格式很简单，首先4个字节大小的消息长度，其目的是将真正发送的字节流的大小显式通过报文告知接收端，接下来是4个字节大小的消息类型，而真正需要发送的数据则紧随其后。 另外一种报文格式就是通过设置特殊字符作为报文边界。HTTP是一个非常好的例子。 HTTP通过设置回车符、换行符做为HTTP报文协议的边界。 由此看来，TCP数据流特性决定了字节流本身是没有边界的，一般我们通过显式编码报文长度的方式，以及选取特殊字符区分报文边界的方式来进行报文格式的设计。而对报文解析的工作就是要在知道报文格式的情况下，有效地对报文信息进行还原。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程学习笔记（二）--连接与通信]]></title>
    <url>%2F2020%2F05%2F25%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89--%E8%BF%9E%E6%8E%A5%E4%B8%8E%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[使用套接字格式建立连接服务端准备连接的过程 一、创建套接字： 1int socket(int domain, int type, int protocol); 二、绑定地址： 1bind(int fd, sockaddr * addr, socklen_t len); bind函数后面的第二个参数是通用地址格式sockaddr。这里有一个地方值得注意，那就是虽然接收的是通用地址格式，实际上传入的参数可能是IPv4、IPv6或者本地套接字格式。bind函数会根据len字段判断传入的参数addr该怎么解析，len字段表示的就是传入的地址长度，它是一个可变值。这里其实可以把bind函数理解成这样： 1bind(int fd, void * addr, socklen_t len); 不过BSD设计套接字的时候大约是1982年，那个时候的C语言还没有void指针的支持，为了解决这个问题，BSD的设计者们创造性地设计了通用地址格式来作为支持bind和accept等这些函数的参数。对于使用者来说，每次需要将IPv4、IPv6或者本地套接字格式转化为通用套接字格式，就像下面的IPv4套接字地址格式的例子一样： 12struct sockaddr_in name; bind (sock, (struct sockaddr *) &amp;name, sizeof (name); 设置bind的时候，对地址和端口可以有多种处理方式。我们可以把地址设置成本机的IP地址，这相当告诉操作系统内核，仅仅对目标IP是本机IP地址的IP包进行处理。但是这样写的程序在部署时有一个问题，我们编写应用程序时并不清楚自己的应用程序将会被部署到哪台机器上。这个时候，可以利用通配地址的能力帮助我们解决这个问题。 对于IPv4的地址来说，使用INADDR_ANY来完成通配地址的设置；对于IPv6的地址来说，使用IN6ADDR_ANY来完成通配地址的设置。如下： 12struct sockaddr_in name;name.sin_addr.s_addr = htonl (INADDR_ANY); /* IPV4 通配地址 */ 除了地址，还有端口。一般来说，服务器端的程序一定要绑定到一个众所周知的端口上。服务器端的IP地址和端口数据，相当于打电话拨号时需要知道的对方号码，如果没有电话号码，就没有办法和对方建立连接。 三、监听端口： 初始化创建的套接字，可以认为是一个”主动”套接字，其目的是之后主动发起请求（通过调用connect函数）。通过listen函数，可以将原来的”主动”套接字转换为”被动”套接字，告诉操作系统内核：“我这个套接字是用来等待用户请求的。”当然，操作系统内核会为此做好接收用户请求的一切准备，比如完成连接队列。listen函数的原型是这样的： 1int listen (int socketfd, int backlog); 第一个参数socketfd为套接字描述符，第二个参数backlog，官方的解释为未完成连接队列的大小，这个参数的大小决定了可以接收的并发数目。这个参数越大，并发数目理论上也会越大。但是参数过大也会占用过多的系统资源，一些系统，比如Linux并不允许对这个参数进行改变。 四、接收请求 当客户端的连接请求到达时，服务器端应答成功，连接建立，这个时候操作系统内核需要把这个事件通知到应用程序，并让应用程序感知到这个连接。accept这个函数的作用就是连接建立之后，操作系统内核和应用程序之间的桥梁。它的原型是： 1int accept(int listensockfd, struct sockaddr *cliaddr, socklen_t *addrlen); 函数的第一个参数listensockfd是套接字，可以叫它为listen套接字，因为这就是前面通过bind，listen一系列操作而得到的套接字。函数的返回值有两个部分，第一个部分cliadd是通过指针方式获取的客户端的地址，addrlen告诉我们地址的大小。另一个部分是函数的返回值，这个返回值是一个全新的描述字，代表了与客户端的连接。这里一定要注意有两个套接字描述字，第一个是监听套接字描述字listensockfd，它是作为输入参数存在的；第二个是返回的已连接套接字描述字。为什么要把两个套接字分开呢？这是因为网络程序的一个重要特征就是并发处理，不可能一个应用程序运行之后只能服务一个客户，所以监听套接字一直都存在，它是要为成千上万的客户来服务的，直到这个监听套接字关闭；而一旦一个客户和服务器连接成功，完成了TCP三次握手，操作系统内核就为这个客户生成一个已连接套接字，让应用服务器使用这个已连接套接字和客户进行通信处理。如果应用服务器完成了对这个客户的服务，比如一次网购下单，一次付款成功，那么关闭的就是已连接套接字，这样就完成了TCP连接的释放。请注意，这个时候释放的只是这一个客户连接，其它被服务的客户连接可能还存在。最重要的是，监听套接字一直都处于“监听”状态，等待新的客户请求到达并服务。 客户端发起连接的过程 一、创建套接字：和服务端一样的做法。 二、connect:客户端和服务器端的连接建立，是通过connect函数完成的。这是connect的构建函数： 1int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen); 函数的第一个参数sockfd是连接套接字，通过前面讲述的socket函数创建。第二个、第三个参数servaddr和addrlen分别代表指向套接字地址结构的指针和该结构的大小。套接字地址结构必须含有服务器的IP地址和端口号。如果是TCP套接字，那么调用connect函数将激发TCP的三次握手过程，而且仅在连接建立成功或出错时才返回。其中出错返回可能有以下几种情况： 1.三次握手无法建立，客户端发出的SYN包没有任何响应，于是返回TIMEOUT错误。这种情况比较常见的原因是对应的服务端IP写错。 2.客户端收到了RST（复位）回答，这时候客户端会立即返回CONNECTION-REFUSED错误。这种情况比较常见于客户端发送连接请求时的请求端口写错，因为RST是TCP在发生错误时发送的一种TCP分节。产生RST的三个条件是：目的地为某端口的SYN到达，然而该端口上没有正在监听的服务器（如前所述）；TCP想取消一个已有连接；TCP接收到一个根本不存在的连接上的分节。 3.客户发出的SYN包在网络上引起了”destination-unreachable”，即目的不可达的错误。这种情况比较常见的原因是客户端和服务器端路由不通。 TCP三次握手 先看一下最初的过程，服务器端通过socket，bind和listen完成了被动套接字的准备工作，被动的意思就是等着别人来连接，然后调用accept，就会阻塞在这里，等待客户端的连接来临；客户端通过调用socket和connect函数之后，也会阻塞。接下来的事情是由操作系统内核完成的，更具体一点的说，是操作系统内核网络协议栈在工作。 下面是具体的过程： 1. 客户端的协议栈向服务器端发送了SYN包，并告诉服务器端当前发送序列号j，客户端进入SYNC_SENT状态； 2.服务器端的协议栈收到这个包之后，和客户端进行ACK应答，应答的值为j+1，表示对SYN包j的确认，同时服务器也发送一个SYN包，告诉客户端当前我的发送序列号为k，服务器端进入SYNC_RCVD状态； 3.客户端协议栈收到ACK之后，使得应用程序从connect调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为ESTABLISHED，同时客户端协议栈也会对服务器端的SYN包进行应答，应答数据为k+1； 4.应答包到达服务器端后，服务器端协议栈使得accept阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入ESTABLISHED状态。 使用套接字进行读写发送数据 发送数据时常用的有三个函数，分别是write、send和sendmsg。 123ssize_t write (int socketfd, const void *buffer, size_t size); ssize_t send (int socketfd, const void *buffer, size_t size, int flags); ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags); 每个函数都是单独使用的，使用的场景略有不同：第一个函数是常见的文件写函数，如果把socketfd换成文件描述符，就是普通的文件写入。如果想指定选项，发送带外数据，就需要使用第二个带flag的函数。所谓带外数据，是一种基于TCP协议的紧急数据，用于客户端-服务器在特定场景下的紧急处理。如果想指定多重缓冲区传输数据，就需要使用第三个函数，以结构体msghdr的方式发送数据。 当TCP三次握手成功，TCP连接成功建立后，操作系统内核会为每一个连接创建配套的基础设施，比如发送缓冲区。发送缓冲区的大小可以通过套接字选项来改变，当我们的应用程序调用write函数时，实际所做的事情是把数据从应用程序中拷贝到操作系统内核的发送缓冲区中，并不一定是把数据通过套接字写出去。这里有几种情况：第一种情况很简单，操作系统内核的发送缓冲区足够大，可以直接容纳这份数据，那么皆大欢喜，我们的程序从write调用中退出，返回写入的字节数就是应用程序的数据大小。第二种情况是，操作系统内核的发送缓冲区是够大了，不过还有数据没有发送完，或者数据发送完了，但是操作系统内核的发送缓冲区不足以容纳应用程序数据，在这种情况下，你预料的结果是什么呢？报错？还是直接返回？操作系统内核并不会返回，也不会报错，而是应用程序被阻塞，也就是说应用程序在write函数调用处停留，不直接返回。术语“挂起”也表达了相同的意思，不过“挂起”是从操作系统内核角度来说的。 那么什么时候才会返回呢？实际上，每个操作系统内核的处理是不同的。大部分UNIX系统的做法是一直等到可以把应用程序数据完全放到操作系统内核的发送缓冲区中，再从系统调用中返回。当TCP连接建立之后，它就开始运作起来。可以把发送缓冲区想象成一条包裹流水线，有个聪明且忙碌的工人不断地从流水线上取出包裹（数据），这个工人会按照TCP/IP的语义，将取出的包裹（数据）封装成TCP的MSS包，以及IP的MTU包，最后走数据链路层将数据发送出去。这样我们的发送缓冲区就又空了一部分，于是又可以继续从应用程序搬一部分数据到发送缓冲区里，这样一直进行下去，到某一个时刻，应用程序的数据可以完全放置到发送缓冲区里。在这个时候，write阻塞调用返回。注意返回的时刻，应用程序数据并没有全部被发送出去，发送缓冲区里还有部分数据，这部分数据会在稍后由操作系统内核通过网络发送出去。 读取数据 read函数，这个函数的原型如下： 1ssize_t read (int socketfd, void *buffer, size_t size); read函数要求操作系统内核从套接字描述字socketfd读取最多多少个字节（size），并将结果存储到buffer中。返回值告诉我们实际读取的字节数目，也有一些特殊情况，如果返回值为0，表示EOF（end-of-file），这在网络中表示对端发送了FIN包，要处理断连的情况；如果返回值为-1，表示出错。当然，如果是非阻塞I/O，情况会略有不同。注意这里是最多读取size个字节。如果我们想让应用程序每次都读到size个字节，就需要编写下面的函数，不断地循环读取。 1234567891011121314151617181920212223/* 从 socketfd 描述字中读取 &quot;size&quot; 个字节. */ ssize_t readn(int fd, void *vptr, size_t size) &#123; size_t nleft; ssize_t nread; char *ptr; ptr = vptr; nleft = size; while (nleft &gt; 0) &#123; if ( (nread = read(fd, ptr, nleft)) &lt; 0) &#123; if (errno == EINTR) nread = 0; /* 这里需要再次调用 read */ else return(-1); &#125; else if (nread == 0) break; /* EOF(End of File) 表示套接字关闭 */ nleft -= nread; ptr += nread; &#125; return(n - nleft); /* 返回的是实际读取的字节数 */ &#125; 需要注意： 1、阻塞式套接字最终发送返回的实际写入字节数和请求字节数是相等的。 2、发送成功仅仅表示的是数据被拷贝到了发送缓冲区中，并不意味着连接对端已经收到所有的数据。至于什么时候发送到对端的接收缓冲区，或者更进一步说，什么时候被对方应用程序缓冲所接收，对我们而言完全都是透明的。 3、对于send来说，返回成功仅仅表示数据写到发送缓冲区成功，并不表示对端已经成功收到。对于read来说，需要循环读取数据，并且需要考虑EOF等异常条件。 UDP编程的情况 UDP和TCP编程非常不同，下面这张图是UDP程序设计时的主要过程。 可以看到服务器端创建UDP套接字之后，绑定到本地端口，调用recvfrom函数等待客户端的报文发送；客户端创建套接字之后，调用sendto函数往目标地址和端口发送UDP报文，然后客户端和服务器端进入互相应答过程。recvfrom和sendto是UDP用来接收和发送报文的两个主要函数： 12ssize_t recvfrom(int sockfd, void *buff, size_t nbytes, int flags, struct sockaddr *from, socklen_t *addrlen); ssize_t sendto(int sockfd, const void *buff, size_t nbytes, int flags, const struct sockaddr *to, socklen_t *addrlen); 先来看一下recvfrom函数，sockfd、buff和nbytes是前三个参数。sockfd是本地创建的套接字描述符，buff指向本 地的缓存，nbytes表示最大接收数据字节。第四个参数flags是和I/O相关的参数，这里我们还用不到，设置为0。后面两个参数from和addrlen，实际上是返回对端发送方的地址和端口等信息，这和TCP非常不一样，TCP是通过accept函数拿到的描述字信息来决定对端的信息。另外UDP报文每次接收都会获取对端的信息，也就是说报文和报文之间是没有上下文的。函数的返回值告诉我们实际接收的字节数。 接下来看一下sendto函数。sendto函数中的前三个参数为sockfd、buff和nbytes。sockfd是本地创建的套接字描述符，buff指向发送的缓存，nbytes表示发送字节数。第四个参数flags依旧设置为0。后面两个参数to和addrlen，表示发送的对端地址和端口等信息。函数的返回值告诉我们实际接收的字节数。 UDP是无连接的数据报程序，和TCP不同，不需要三次握手建立一条连接。UDP程序通过recvfrom和sendto函数直接收发数据报报文。 本地套接字 实际上，本地套接字是IPC，也就是本地进程间通信的一种实现方式。除了本地套接字以外，其它技术，诸如管道、共享消息队列等也是进程间通信的常用方法，但因为本地套接字开发便捷，接受度高，所以普遍适用于在同一台主机上进程间通信的各种场景。 本地套接字是一种特殊类型的套接字，和TCP/UDP套接字不同。TCP/UDP即使在本地地址通信，也要走系统网络协议栈，而本地套接字，严格意义上说提供了一种单主机跨进程间调用的手段，减少了协议栈实现的复杂度，效率比TCP/UDP套接字都要高许多。类似的IPC机制还有UNIX管道、共享内存和RPC调用等。 本地字节流套接字和TCP服务器端、客户端编程最大的差异就是套接字类型的不同。本地字节流套接字识别服务器不再通过IP地址和端口，而是通过本地文件。本地套接字的编程接口和IPv4、IPv6套接字编程接口是一致的，可以支持字节流和数据报两种协议。本地套接字的实现效率大大高于IPv4和IPv6的字节流、数据报套接字实现。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程学习笔记（一）--几种概念]]></title>
    <url>%2F2020%2F05%2F23%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89--%E5%87%A0%E7%A7%8D%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[客户端-服务端模型 一个连接可以通过客户端-服务器端的IP和端口唯一确定，这叫做套接字对，按照下面的四元组表示：（clientaddr:clientport, serveraddr: serverport)。下图表示了一个客户端-服务器之间的连接： 保留网段 国际标准组织在IPv4地址空间里面，专门划出了一些网段，这些网段不会用做公网上的IP，而是仅仅保留做内部使用，我们把这些地址称作保留网段。下表是三个保留网段，其可以容纳的计算机主机个数分别是 16777216 个、1048576 个和 65536 个。 子网掩码 在网络IP划分的时候，我们需要区分两个概念。第一是网络（network）的概念，直观点说，它表示的是这组IP共同的部分，比如在192.168.1.1-192.168.1.255这个区间里，它们共同的部分是192.168.1.0。第二是主机（host）的概念，它表示的是这组IP不同的部分，上面的例子中1-255就是不同的那些部分，表示有255个可用的不同IP。例如IPv4地址，192.0.2.12，我们可以说前面三个bytes是子网，最后一个byte是host，或者换个方式，我们能说host为8位，子网掩码为192.0.2.0/24（255.255.255.0）。 很久以前，有子网（subnet）的分类，在这里，一个IPv4地址的第一个，前两个或前三个字节是属于网络的一部分。如果你很幸运地可以拥有一个字节的网络，而另外三个字节是host地址，那在你的网络里，你有价值三个字节，也就是24个比特的主机地址，这是什么概念呢？2的24次方，大约是一千六百万个地址左右。这是一个“Class A”（A 类）网络。 再来重新看一下保留网段的这张表格，表格第一行就是这样的一个A类网络，10是对应的网络字节部分，主机的字节是3，我们将一个字节的子网记作255.0.0.0。相对的，“ClassB”（B类）的网络，网络有两个字节，而host只有两个字节，也就是说拥有的主机个数为65536。“ClassC”（C类）的网络，网络有三个字节，而host只有一个字节，也就是说拥有的主机个数为256。 网络地址位数由子网掩码（Netmask）决定，你可以将IP地址与子网掩码进行“位与”操作，就能得到网络的值。子网掩码一般看起来像是255.255.255.0（二进制为11111111.11111111.11111111.00000000），比如你的IP是192.0.2.12，使用这个子网掩码时，你的网络就会是192.0.2.12与255.255.255.0所得到的值：192.0.2.0，192.0.2.0就是这个网络的值。 子网掩码能接受任意个位，而不单纯是上面讨论的8，16或24个比特而已。所以你可以有一个子网掩码255.255.255.252（二进制位11111111.11111111.11111111.11111100），这个子网掩码能切出一个30个位的网络以及2个位的主机，这个网络最多有四台host。为什么是4台host呢？因为不变的部分只有最后两位，所有的可能为2的2次方，即4台host。 注意，子网掩码的格式永远都是二进制格式：前面是一连串的1，后面跟着一连串的0。不过一大串的数字会有点不好用，比如像255.192.0.0这样的子网掩码，人们无法直观地知道有多少个1，多少个0，后来人们发明了新的办法，你只需要将一个斜线放在IP地址后面，接着用一个十进制的数字用以表示网络的位数，类似这样：192.0.2.12/30,这样就很容易知道有30个1，2个0，所以主机个数为4。 例如，从172.16.0.0/12这个IP中得出信息，172.16.0.0为B类网，12为网络号，默认B类网的网络号（也就是子网掩码中1的个数）是16位，而此处为12位，那么便有2^(16-12)=16个连续子网。而对于192.168.0.0/16，192.168.0.0为C类网，16为网络号，默认C类网的网络号是24位，而此处为16位，那么便有2^(24-16)=256个连续的子网。注意，这里说的子网是说网络，并不是说可连接的主机数。从以上的分析可以看出，子网掩码决定了不同类型网络中子网的个数。 全球域名系统 全球域名按照从大到小的结构，形成了一棵树状结构。实际访问一个域名时，是从最底层开始写起，例如www.google.com，www.tinghua.edu.cn等。结构如下图： 套接字和地址 在网络编程中，我们经常会提到socket这个词，它的中文翻译为套接字，有的时候也叫做套接口。在网络编程中，到底应该怎么理解socket呢？首先看一张图： 这张图表达的其实是网络编程中，客户端和服务器工作的核心逻辑。具体来说，客户端进程向操作系统内核发起write字节流写操作，内核协议栈将字节流通过网络设备传输到服务器端，服务器端从内核得到信息，将字节流从内核读入到进程中，并开始业务逻辑的处理，完成之后，服务器端再将得到的结果以同样的方式写给客户端。可以看到，一旦连接建立，数据的传输就不再是单向的，而是双向的，这也是TCP的一个显著特性。 以上所有的操作，都是通过socket来完成的。无论是客户端的connect，还是服务端的accept，或者read/write操作等，socket是我们用来建立连接，传输数据的唯一途径。 在使用套接字时，首先要解决通信双方寻址的问题。我们需要套接字的地址建立连接，就像打电话时首先需要查找电话簿，找到你想要联系的那个人，你才可以建立连接，开始交流。下面先看一下套接字的通用地址结构： 1234567/* POSIX.1g 规范规定了地址族为 2 字节的值. */typedef unsigned short int sa_family_t;/* 描述通用套接字地址 */struct sockaddr&#123;sa_family_t sa_family; /* 地址族. 16-bit*/char sa_data[14]; /* 具体的地址值 112-bit */&#125;; 在这个结构体里，第一个字段是地址族，它表示使用什么样的方式对地址进行解释和保存，好比电话簿里的手机格式，或者是固话格式，这两种格式的长度和含义都是不同的。地址族常用的有：AF_LOCAL（本地地址，对应的是Unix套接字，这种情况一般用于本地socket通信，很多情况下也可以写成AF_UNIX、AF_FILE）、AF_INET（因特网使用的IPv4地址）、AF_INET6（因特网使用的IPv6地址）。这里的AF_表示的含义是AddressFamily，但是很多情况下，我们也会看到以PF_表示的宏，比如PF_INET、PF_INET6等，实际上PF_的意思是ProtocolFamily，也就是协议族的意思。我们用AF_xxx这样的值来初始化socket地址，用PF_xxx这样的值来初始化socket。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP协议体系架构]]></title>
    <url>%2F2020%2F05%2F17%2FTCP-IP%E5%8D%8F%E8%AE%AE%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[在学习完TCP/IP协议后，个人感觉有几个重要的概念值得重视，所以记录在此。 体系结构 TCP-IP协议的体系结构如下图，其中，数据链路层、网络层、传输层在内核中实现，因为这些既高效又稳定，而应用层负责处理应用程序的逻辑，因此在用户态实现。 数据链路层之ARP协议 ARP协议属于数据链路层中的协议。网络层使用IP地址寻址一台机器，而数据链路层使用物理地址寻址一台机器，因此网络层必须先将目标机器的IP地址转换为其物理地址，才能使用数据链路层提供的服务，这就是ARP协议的用途。 网络层及网络层协议 网络层实现数据包的选路和转发。通信的两台主机一般不是直接相连的，而是通过多个中间节点（路由器）连接的，网络层的任务就是选择这些中间节点，以确定两台主机之间的通信路径。同时，网络层对上层协议隐藏了网络拓扑连接的细节，使得在传输层和网络应用程序看来，通信的双方是直接相连的。网络层的协议有ICMP协议和IP协议。 传输层之TCP协议 TCP协议（传输控制协议）为应用层提供可靠的、面向连接的和基于流的服务。TCP协议使用超时重传、数据确认等方式来确保数据包正确地发送至目的端，因此TCP服务是可靠的。TCP服务是基于流的。基于流的数据没有边界限制，它源源不断地从通信的一端流入另一端。发送端可以逐个字节地向数据流写入数据，接收端也可以逐个字节地将它们读出。 传输层之UDP协议 UDP协议为应用层提供不可靠、无连接和基于数据报的服务。使用UDP协议的应用程序通常要自己处理数据确认、超时重传等逻辑。UDP协议是无连接的，即通信双方不保持一个长久的联系，因此应用程序每次发送数据都要明确指定接收端的地址（IP地址等信息）。基于数据报的服务，是相对基于流的服务而言的。每个UDP数据报都有一个长度，接收端必须以该长度为最小单位将其所有内容一次性读出，否则数据将被截断。 协议封装 所谓封装，其实就是将上层的数据加上本层的头部或尾部。应用层数据经过层层封装，最终被封装成帧的形式，帧是最后在物理网络上传送的字节序列。 协议分用 当帧到达目的主机时，将沿着协议栈自底向上依次传递。各层协议通过处理本层负责的头部数据，以获得所需的信息，这就是分用。最终会将应用数据传递给应用层使用。 协议类型 由于IP协议、ARP协议、RARP协议都使用帧传输数据，所以帧的头部需要提供某个字段来区分它们。以以太网帧为例，它使用2字节的类型字段来标识上层协议。如果主机接收到的以太网帧类型字段的值为0x800，则为IP数据报，以太网驱动程序就将帧交付给IP模块。若值为0x806，则为ARP请求或应答报文。若值为0x835，则帧的数据部分为RARP请求或应答报文。 socket Socket是一套应用程序编程接口，即API。能够实现系统调用，使得应用程序能够访问内核中协议提供的服务。 由socket定义的API提供两点功能：一是将应用程序的数据从用户缓冲区复制到TCP/UDP内核发送缓冲区，以交付内核来发送数据，或从内核TCP/UDP接受缓冲区复制数据到用户缓冲区，以读取数据。二是应用程序可以通过它们来修改内核中各层协议的某些头部信息或其他数据结构，从而精细地控制底层通信的行为。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈TCP协议]]></title>
    <url>%2F2020%2F05%2F17%2F%E6%B5%85%E8%B0%88TCP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[TCP协议和UDP协议的特点 TCP协议相对于UDP协议的特点是：面向连接、字节流和可靠传输。 这里需要明确一下什么叫字节流，什么叫数据报。 字节流：发送端执行的写操作次数和接收端执行的读操作次数之间没有任何数量关系，发送端和接收端分别与TCP缓冲区交互，应用程序对数据的发送和接收是没有边界限制的。 数据报：发送端应用程序每执行一次写操作，UDP模块就将其封装成一个UDP数据报并发送之。接收端必须及时针对每一个UDP数据报执行读操作，否则就会丢包。并且，如果用户没有指定足够的应用程序缓冲区来读取UDP数据，则UDP数据将被截断。 下面的图能够更加清晰的描述二者的区别。 TCP头部结构 注意：16位窗口大小是TCP流量控制的一个手段。这里的窗口指的是接收通告窗口，它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。 TCP连接的建立和关闭 处于FIN_WAIT_2状态的客户端需要等待服务器发送结束报文段，才能转移至TIME_WAIT状态，否则它将一直停留在这个状态。连接停留在FIN_WAIT_2状态的情况可能发生在：客户端执行半关闭后，未等服务器关闭连接就强行退出了，此时客户端连接由内核来接管，称为孤儿连接。 TCP拥塞控制 拥塞控制的目的是提高网络利用率，降低丢包率，并保证网络资源对每条数据流的公平性。拥塞控制的四个部分：慢启动、拥塞避免、快速重传、快速恢复。 拥塞控制其实是控制发送端向网络一次连续写入（收到其中第一个数据的确认之前）的数据量，称为SWND（发送窗口）。接收方可通过其接收通告窗口RWND来控制发送端的SWND，但是显然不够，所以发送端引入了一个称为拥塞窗口（CWND）的状态变量。实际的SWND值是RWND和CWND中的较小者。如下图： 慢启动算法的理由是：TCP模块刚开始发送数据时并不知道网络的实际情况，需要用一种试探性的方式平滑地增加CWND的大小。但是刚开始这个CWND的值是以指数形式扩大，如果不进行干预，必然使得CWND很快膨胀，并最终导致网络拥塞。因此TCP拥塞控制中定义了另一个重要的状态变量：慢启动门限，当CWND的大小超过该值时，TCP拥塞控制将进入拥塞避免阶段。 拥塞避免算法使得CWND按照线性方式增加，从而减缓其扩大。 很多情况下，发送端都可能收到重复的确认报文段，比如TCP报文段丢失。拥塞控制算法需要判断当收到重复的确认报文段时，网络是否真的发生了拥塞。具体做法是：发送端如果连续收到3个重复的确认报文段，就认为是拥塞发生了。然后将启用快速重传和快速恢复算法来处理拥塞。过程如下： 1）当收到第3个重复确认报文段时，重新计算慢启动门限值，然后立即重传丢失的报文段，并设置CWND。（重新开始慢启动） 2）每次收到1个重复的确认时，设置CWND，此时发送端可以发送新的TCP报文段。 3）当收到新数据的确认时，设置CWND为新的慢启动门限值。 快速重传和快速恢复完成之后，拥塞控制恢复到拥塞避免阶段。 TCP/IP通信实例逻辑 其中，Kongming20上运行wget客户端程序，ernest-laptop上运行squid代理服务器程序(HTTP代理服务器)。客户端通过代理服务器的中转，获取Internet上的主机www.baidu.com的首页。 HTTP代理服务器的工作原理 正向代理要求客户端自己设置代理服务器的地址。客户的每次请求都将直接发送到该代理服务器，并由代理服务器来请求目标资源。 反向代理则被设置在服务端，因而客户端无需进行任何设置。反向代理是指用代理服务器来接收Internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从内部服务器上得到的结果返回给客户端。这种情况下，代理服务器对外就表现为一个真实的服务器。 访问DNS服务器 IP头部的源端IP地址和目的端IP地址在转发过程中是始终不变的，但是帧头部的源端物理地址和目的端物理地址在转发过程中则是一直在变化的，因此在此过程中，在不停的找路由器的mac地址。 HTTP通信过程]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[含有汇编代码的编译错误]]></title>
    <url>%2F2020%2F05%2F04%2F%E5%90%AB%E6%9C%89%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81%E7%9A%84%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[含有汇编代码的vs2017工程编译错误 当一个项目工程中含有汇编代码，在编译的时候可能会出现以下的错误。 ‘yasm’ 不是内部或外部命令 这是因为yasm.exe的路径不对，如果没有装yasm，则在 http://www.tortall.net/projects/yasm/wiki/Download 这里下载yasm，然后将vsyasm.exe 改名yasm.exe复制到VC安装目录，例如：D:\soft\vs2017\Common7\IDE。重新编译，即可成功。 Microsoft.CppCommon.targets(172,5): error MSB6006: “cmd.exe”已退出，代码为 9009。 还是因为项目工程中有汇编代码，而汇编代码没有编译通过，所以导致这个错误，解决方法参考第一个错误。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>编译错误</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2020%2F04%2F06%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Git常用命令安装Git在Linux上安装Git 在Ubuntu Linux中，使用 sudo apt-get install git 完成安装。 如果是其他Linux版本，可以直接通过源码安装。先从Git官网下载源码，然后解压，依次输入：./config，make，sudo make install这几个命令安装就好了。 在Mac OS X上安装Git 一是安装homebrew，然后通过homebrew安装Git，具体方法请参考homebrew的文档：http://brew.sh/。 第二种方法更简单，也是推荐的方法，就是直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode，选择菜单“Xcode”-&gt;“Preferences”，在弹出窗口中找到“Downloads”，选择“Command Line Tools”，点“Install”就可以完成安装了。 在Windows上安装Git 从Git官网直接下载 https://git-scm.com/downloads 然后按默认选项安装即可。 安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 安装完成后，还需要最后一步设置，在命令行输入： 12git config --global user.name &quot;Your Name&quot;git config --global user.email &quot;email@example.com&quot; 注意config命令的–global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 创建版本库、提交文件 选择一个合适的地方，创建一个空目录，然后创建文本文件，可以使用Notepad++编辑文本文件，默认编码设置为UTF-8 without BOM。 1234567$ mkdir learngit$ cd learngit$ pwd //查看当前工作目录$ git init //把这个目录变成Git可以管理的仓库，此时以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，最好不要修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。如果没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -ah命令就可以看见。$ git add readme.txt //把文件（readme.txt）添加到仓库$ git commit -m &quot;wrote a readme file&quot; //把文件提交到仓库，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样就能从历史记录里方便地找到改动记录。//为什么Git添加文件需要add，commit一共两步呢？因为commit可以一次提交很多文件，所以你可以多次add不同的文件。 查看仓库状态、文件修改、版本回退和前进1234567891011121314$ git status //可以让我们时刻掌握仓库当前的状态$ git diff readme.txt //查看difference，知道了对readme.txt作了什么修改$ git log //显示从最近到最远的提交日志$ git log --pretty=oneline //简化版的查看提交日志$ git reset --hard HEAD^ //回退到上一个版本，在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。回退到前面版本，如果还想再回到最新版本，可以用 git reset --hard 版本号（不用写全）$ cat readme.txt //查看文件内容$ git reflog //记录每一次命令（可以查看版本号）$ git checkout -- readme.txt //撤销修改$ git reset HEAD readme.txt //把暂存区的修改回退到工作区$ rm test.txt //删除了工作区的文件$ git rm test.txt //从版本库中删除该文件，还需要git commit -m &quot;remove test.txt，才能彻底删除文件。$ git checkout -- test.txt //误删后因为版本库里还有，所以可以很轻松地把误删的文件恢复到最新版本。//git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。//注意：从来没有被添加到版本库就被删除的文件，是无法恢复的！ 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD ，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。 远程仓库]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[malloc和free详解]]></title>
    <url>%2F2020%2F03%2F15%2Fmalloc%E5%92%8Cfree%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[malloc和free详解malloc的实质 malloc函数的实质体现在，它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。调用malloc函数时，它沿连接表寻找一个大到足以满足用户请求所需要的内存块。然后，将该内存块一分为二（一块的大小与用户请求的大小相等，另一块的大小就是剩下的字节）。接下来，将分配给用户的那块内存传给用户，并将剩下的那块（如果有的话）返回到连接表上。调用free函数时，它将用户释放的内存块连接到空闲链上。到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段，那么空闲链上可能没有可以满足用户要求的片段了。于是，malloc函数请求延时，并开始在空闲链上翻箱倒柜地检查各内存片段，对它们进行整理，将相邻的小空闲块合并成较大的内存块。如果无法获得符合要求的内存块，malloc函数会返回NULL指针，因此在调用malloc动态申请内存块时，一定要进行返回值的判断。 malloc()到底从哪里得来了内存空间 １、malloc()到底从哪里得到了内存空间？答案是从堆里面获得空间。也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。就是这样！ 说到这里，不得不另外插入一个小话题。什么是堆？说到堆，又忍不住说到了栈！什么是栈？下面就另外开个小部分专门而又简单地说一下这个题外话。 2、什么是堆：堆是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。 什么是栈：栈是线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立。每个函数都有自己的栈，栈被用来在函数之间传递参数。操作系统在切换线程的时候会自动的切换栈，就是切换SS/ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。 通过上面对概念的描述，可以知道：栈是由编译器自动分配释放，存放函数的参数值、局部变量的值等。操作方式类似于数据结构中的栈。堆一般由程序员分配释放，若不释放，程序结束时可能由OS回收。注意这里说是可能，并非一定。所以再强调一次，记得要释放！注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。 举个例子，如果你在函数上面定义了一个指针变量，然后在这个函数里申请了一块内存让指针指向它。实际上，这个指针的地址是在栈上，但是它所指向的内容却是在堆上面的！这一点要注意！所以，再想想，在一个函数里申请了空间后，比如说下面这个函数： 1234void Function(void) &#123; char *p = (char *)malloc(100 * sizeof(char)); &#125; 就这个例子，千万不要认为函数返回，函数所在的栈被销毁指针也跟着销毁，申请的内存也就一样跟着销毁了！这绝对是错误的！因为申请的内存在堆上，而函数所在的栈被销毁跟堆完全没有啥关系。所以，还是那句话：记得释放！ free()到底释放了什么 free()释放的是指针指向的内存！注意！释放的是内存，不是指针！这点非常非常重要！指针是一个变量，只有程序结束时才被销毁。释放了内存空间后，原来指向这块空间的指针还是存在！只不过现在指针指向的内容的垃圾，是未定义的，所以说是垃圾。因此，前面我已经说过了，释放内存后把指针指向NULL，防止指针在后面不小心又被解引用了。这一点非常重要！ malloc()以及free()的机制 事实上，仔细看一下free()的函数原型，也许也会发现似乎很神奇，free()函数非常简单，只有一个参数，只要把指向申请空间的指针传递给free()中的参数就可以完成释放工作！这里要追踪到malloc()的申请问题了。申请的时候实际上占用的内存要比申请的大。因为超出的空间是用来记录对这块内存的管理信息。先看一下在《UNIX环境高级编程》中第七章的一段话： 大多数实现所分配的存储空间比所要求的要稍大一些，额外的空间用来记录管理信息——分配块的长度，指向下一个分配块的指针等等。这就意味着如果写过一个已分配区的尾端，则会改写后一块的管理信息。这种类型的错误是灾难性的，但是因为这种错误不会很快就暴露出来，所以也就很难发现。将指向分配块的指针向后移动也可能会改写本块的管理信息。 以上这段话已经给了我们一些信息了。malloc()申请的空间实际就是分了两个不同性质的空间。一个就是用来记录管理信息的空间，另外一个就是可用空间了。而用来记录管理信息的实际上是一个结构体。在C语言中，用结构体来记录同一个对象的不同信息是天经地义的事！下面看看这个结构体的原型： 12345struct mem_control_block &#123; int is_available; //这是一个标记？ int size; //这是实际空间的大小 &#125;; 对于size,这个是实际空间大小。而is_available是否是一个标记？free()就是根据这个结构体的信息来释放malloc()申请的空间！而结构体的两个成员的大小我想应该是操作系统的事了。但是这里有一个问题，malloc()申请空间后返回一个指针应该是指向第二种空间，也就是可用空间！不然，如果指向管理信息空间的话，写入的内容和结构体的类型有可能不一致，或者会把管理信息屏蔽掉，那就没法释放内存空间了，所以会发生错误！接下来分析free()的源码： 1234567void free(void *ptr) &#123; struct mem_control_block *free; free = ptr - sizeof(struct mem_control_block); free-&gt;is_available = 1; return; &#125; 看一下函数第二句，这句非常重要和关键。其实这句就是把指向可用空间的指针倒回去，让它指向管理信息的那块空间，因为这里是在值上减去了一个结构体的大小！后面那一句free-&gt;is_available = 1;这里is_available应该只是一个标记而已！因为从这个变量的名称上来看，is_available翻译过来就是“是可以用”。这个变量的值是1，表明是可以用的空间！如果把它改为0或者是其他值不知道会发生什么事？！但是有一点可以肯定，就是释放绝对不会那么顺利进行！因为这是一个标记！ 当然，这里可能还是有人会有疑问，为什么这样就可以释放呢？就free()这个源代码来看，什么也没有释放。但是它确实是确定了管理信息的那块内存的内容。所以，free()只是记录了一些信息，然后告诉操作系统那块内存可以去释放，然后由操作系统来释放那段内存。之前一个错误的认识，就是认为指向那块内存的指针不管移到那块内存中的哪个位置都可以释放那块内存！但是，这是大错特错！释放是不可以释放一部分的！首先这点应该要明白。而且，从free()的源代码看，ptr只能指向可用空间的首地址，不然，减去结构体大小之后一定不是指向管理信息空间的首地址。所以，要确保指针指向可用空间的首地址！如若验证，可以写一个程序然后移动指向可用空间的指针，看程序会不会崩溃！]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>malloc和free</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。]]></title>
    <url>%2F2020%2F03%2F06%2F%E7%BB%86%E8%83%9E%E5%88%86%E8%A3%82%E6%89%BE%E8%A7%84%E5%BE%8B%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一个细胞的生命周期是3小时，1小时分裂一次，求n小时后容器内有多少个细胞。 假设经过三个小时的细胞分裂后再死亡。根据题意，细胞的生命周期是三个小时，一个小时后，第一个细胞分裂，此时细胞总数变成2，但是这两个细胞的生存时间是不一样的，如果都当成新生细胞即存活时间为0，那么给定的3小时生命周期也就没意义了，所以这个时候其中一个细胞的生存时间变成了1，另外一个刚分裂出来的是0，下面简单表示一下分裂进程（-1表示死亡） 12345678910111213时间 细胞状态 (生存时间) 细胞总数0 0 11 1 0 22 2 1 0 0 43 -1 2 1 1 0 0 0 0 74 -1 2 2 1 1 1 1 0 0 0 0 0 0 0 135 -1 -1 2 2 2 2 1 1 1 1 1 1 10 0 0 0 0 0 0 0 0 0 0 0 0 24… … …f0 = 1f1 = 2f2 = 4f3 = 7 可以发现到第四个小时的时候，规律出来了，在第四个小时死亡的细胞是三小时前也就是第一个小时的时候同时出生的细胞，而在第一个小时同时出生的细胞数等于第一个小时前一个小时的细胞总数所以有递推式：f(n) = 2f(n - 1) - f(n - 4)]]></content>
      <categories>
        <category>题集</category>
      </categories>
      <tags>
        <tag>逻辑题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP协议如何保证数据传输的可靠性]]></title>
    <url>%2F2020%2F03%2F06%2FTCP%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%2F</url>
    <content type="text"><![CDATA[TCP协议如何保证数据传输的可靠性 TCP协议传输的特点主要就是面向字节流、传输可靠、面向连接。 TCP协议保证数据传输可靠性的方式主要有：校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞控制。 校验和 计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。 发送方：在发送数据之前计算检验和，并进行校验和的填充。 接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。 注意：如果接收方比对校验和与发送方不一致，那么数据一定传输有误。但是如果接收方比对校验和与发送方一致，数据不一定传输成功。 确认应答与序列号 序列号：TCP传输时将每个字节的数据都进行了编号，这就是序列号。序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一。 确认应答：TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文。这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。 超时重传 在进行TCP传输时，由于确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发送完数据后，迟迟没有等到接收方的ACK报文，这该怎么办呢？而没有收到ACK报文的原因可能是什么呢？ 首先，发送方没有介绍到响应的ACK报文原因可能有两点： 1.数据在传输过程中由于网络原因等直接全体丢包，接收方根本没有接收到。 2.接收方接收到了响应的数据，但是发送的ACK报文响应却由于网络原因丢包了。 TCP在解决这个问题的时候引入了一个新的机制，叫做超时重传机制。简单理解就是发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送。如果是刚才第一个原因，接收方收到二次重发的数据后，便进行ACK应答。如果是第二个原因，接收方发现接收的数据已存在（判断存在的根据就是序列号，所以上面说序列号还有去除重复数据的作用），那么直接丢弃，仍旧发送ACK应答。 那么发送方发送完毕后等待的时间是多少呢？如果这个等待的时间过长，那么会影响TCP传输的整体效率，如果等待时间过短，又会导致频繁的发送重复的包。如何权衡？ 由于TCP传输时保证能够在任何环境下都有一个高性能的通信，因此这个最大超时时间（也就是等待的时间）是动态计算的。 在Linux中（BSD Unix和Windows下也是这样）超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。重发一次后，仍未响应，那么等待2x500ms的时间后，再次重传。等待4x500ms的时间继续重传。以一个指数的形式增长。累计到一定的重传次数，TCP就认为网络或者对端出现异常，强制关闭连接。 连接管理 连接管理就是三次握手与四次挥手的过程。保证可靠的连接，是保证可靠性的前提。 流量控制 接收端在接收到数据后，对其进行处理。如果发送端的发送速度太快，导致接收端的结束缓冲区很快的填充满了。此时如果发送端仍旧发送数据，那么接下来发送的数据都会丢包，继而导致丢包的一系列连锁反应，超时重传呀什么的。而TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。 在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道，窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小。这个数字越大，证明接收端接收缓冲区的剩余空间越大，网络的吞吐量越大。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。 注：16位的窗口大小最大能表示65535个字节（64K），但是TCP的窗口大小最大并不是64K。在TCP首部中40个字节的选项中还包含了一个窗口扩大因子M，实际的窗口大小就是16为窗口字段的值左移M位。每移一位，扩大两倍。 拥塞控制 TCP传输的过程中，发送端开始发送数据的时候，如果刚开始就发送大量的数据，那么就可能造成一些问题。网络可能在开始的时候就很拥堵，如果给网络中在扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。 所以TCP引入了慢启动的机制，在开始发送数据时，先发送少量的数据探路。探清当前的网络状态如何，再决定多大的速度进行传输。这时候就引入一个叫做拥塞窗口的概念。发送刚开始定义拥塞窗口为1，每次收到ACK应答，拥塞窗口加1。在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小比对，取较小的值作为实际发送的窗口。 拥塞窗口的增长是指数级别的。慢启动的机制只是说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。为了控制拥塞窗口的增长，不能使拥塞窗口单纯的加倍，设置一个拥塞窗口的阈值，当拥塞窗口大小超过阈值时，不能再按照指数来增长，而是线性的增长。在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，发生超时重传时，慢启动的阈值会为原来的一半（这里的原来指的是发生网络拥塞时拥塞窗口的大小），同时拥塞窗口重置为1。 拥塞控制是TCP在传输时尽可能快的将数据传输，并且避免拥塞造成的一系列问题。是可靠性的保证，同时也是维护了传输的高效性。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次完整的http请求过程]]></title>
    <url>%2F2020%2F03%2F05%2F%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84http%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一次完整的http请求过程（在浏览器输入URL后，执行的全部过程）1.首先进行域名解析，域名解析具体过程讲一下： 浏览器搜索自己的DNS缓存，缓存中维护一张域名与IP地址的对应表； 若没有，则搜索操作系统的DNS缓存； 若没有，则操作系统将域名发送至本地域名服务器（递归查询方式），本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则，通过以下方式迭代查找： 本地域名服务器向根域名服务器发起请求，根域名服务器返回com域的顶级域名服务器的地址； 本地域名服务器向com域的顶级域名服务器发起请求，返回权限域名服务器地址； 本地域名服务器向权限域名服务器发起请求，得到IP地址； 本地域名服务器将得到的IP地址返回给操作系统，同时自己将IP地址缓存起来； 操作系统将IP地址返回给浏览器，同时自己也将IP地址缓存起来； 至此，浏览器已经得到了域名对应的IP地址。2.浏览器发起HTTP请求；3.接下来到了传输层，选择传输协议，TCP或者UDP，TCP是可靠的传输控制协议，对HTTP请求进行封装，加入了端口号等信息；4.然后到了网络层，通过IP协议将IP地址封装为IP数据报；然后此时会用到ARP协议，主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址，找到目的MAC地址；5.接下来到了数据链路层，把网络层交下来的IP数据报添加首部和尾部，封装为MAC帧，现在根据目的mac开始建立TCP连接，三次握手，接收端在收到物理层上交的比特流后，根据首尾的标记，识别帧的开始和结束，将中间的数据部分上交给网络层，然后层层向上传递到应用层；6.服务器响应请求并请求客户端要的资源，传回给客户端；7.断开TCP连接，浏览器对页面进行渲染呈现给客户端。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>https和http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从https协议谈对称加密和非对称加密]]></title>
    <url>%2F2020%2F03%2F05%2F%E4%BB%8Ehttps%E5%8D%8F%E8%AE%AE%E8%B0%88%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[首先，我们为什么要用https协议，在此我们举例说明：你在网上商城，发送一个购物的请求，要购买一件商品，但你的数据包被黑客截获了，黑客在网上商城服务器回复你之前回复你，让你提供银行卡账号和密码，如果你未能识别出这是黑客行文，那么后果就可以自己想象了。 为了解决这个问题，一般的思路就是加密。加密后的数据包黑客就算截获了了也无法解密，也就无法知道你要干嘛，就无从构造回复报文。加密分为两种方式：对称加密和非对称加密。 在对称加密算法中，加密和解密使用的密钥是相同的，因此在使用对称加密算法的时候一定要保证密钥不被泄露。 在非对称加密算法中，加密使用的密钥和解密使用的密钥是不同的，一把是作为公开的公钥，另一把是作为谁都不能给的密钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。 在效率方面，对称加密算法的效率比非对称加密算法的效率要高的多。 接下来我们详细说下对称加密。 假如使用对称加密，在购物时你和网上商城约定了一个密钥，你发送请求的时候用这个密钥加密，网上商城使用同样的密钥解密，这样看起来没有一起都很OK，但有个问题，你和商城怎样约定密钥而不被截获了，既在加密建立前如何安全的传送密钥？如果直接传送密钥的信息，那么这信息可能被黑客截获，之后所有的通信黑客都可以解密查看了，也就没有秘密了。我们总不能和商城的人约定一个时间地点然后线下传送密钥吧，就算是线下接头那是不是也要有个约定的暗号什么的，不然你们又不认识，但在传输暗号的时候还是可能被黑客截获，那么线下和你接头的人也说不好是谁呢… So，只要是使用对称加密，如何安全的传送密钥就是一个绕不开的问题，如果只使用对称加密，就会陷入一个密钥传送的死循环，幸好此时我们的非对称加密挺身而出。 网站使用非对称加密的时候，他的密钥放在自己的口袋里谁也不给，但他会把公钥放在一个指定的地方谁都可以获取，只要你拿到了公钥，在你网站交流的时候，你用公钥加密你的信息，这时就算被人截获但因为缺少私钥，所以黑客也解不开你的信息。目前为止，一切开起来很顺利，但网站在给你回复信息的时候有个问题：网站的回复信息是拿他自己的私钥加密的，这个信息谁都可以用公钥来解密的。看来要解决这个问题，只使用网站的公私钥还不行，客户端也得有自己的公私钥，客户端把自己的公钥给网站，把私钥放在自己口袋，在和网站通信的时候客户端使用网站的公钥加密，网站使用客户端的私钥加密回复信息，至此解决了非对称加密的保密性问题。 但对于非对称加密也有和对称加密一样的问题，如何将公钥给到对方，前面其实我们也说过一个方法，就是把各自的公钥放在公网上，这样谁都可以去取；还有另一种方法，就是在建立连接的时候把公钥传给对方。但这两种方式都有一个问题，你怎么确保给到你的公钥就是你信任的人呢，有没有可能有人假冒对方呢，答案是完全有可能。 解决信任问题，最好的方法就是证明，证明什么呢，证明“你是你”！在现实生活中要证明你是你，你需要拿着公安局给你的身份证或者户口本来证明，别人不一定信任你，但身份证的颁发机构是公安局，是权威机构，别人看到身份证也就相信了你是你。其实在网络中也一样，你也需要一个权威机构给你一个证明，证明你是你，证明他是他，证明我是我…在网络世界里，权威部门颁发给你的身份证被称为“证书”。 在证书中包含：公钥、证书的所有者、证书的发布机构、和证书的有效期。这样来看证书其实和身份证很像~，证书是怎么来的呢，有没有可能有假的证书呢，就像假的身份证一样？ 要生成证书需要发起一个证书请求，然后将这个请求发给权威机构去认证，这个权威机构不是公安局而是CA（Certificate Authority），把生成证书的请求发给权威机构后，权威机构会给这个证书卡个公章，我们称之为签名算法，接着，继续我们的怀疑精神，有没有可能会仿造签名呢，该怎么解决呢？签名算法解决了伪造签名的问题，签名算法用自己的私钥来进行签名，这样能用他的公钥解开的签名就能证明这个签名是真的。 签名算法一般先对信息做一个hash运算，得到一个hash值，我们都知道这个过程是不可逆的，也就是无法根据hash值推导出原来的信息。在把信息发送出去的时候呢，把这个hash值加密后作为签名一起发出去。 CA用自己的私钥给网站的公钥的签名，就相当于CA成了网站的担保人，担保这个公钥是这个网站的公钥而不是别人伪造的。 那么你在和网站通信的时候就不会得到一个公钥了，而是一个证书，一个由CA担保的证书，但我们都知道，信任会传递，不信任也会传递，我们凭什么相信一个我们并不了解的CA机构呢，他又不是国家的公安局，而且我们得到的证书要解密的话还需要CA的公钥，我们怎么获取CA的公钥呢，怎么去相信获得的是CA的公钥呢，这是不是又是一个信任的死循环呢？当然不是，首先CA的公钥也要有人给他做担保人，谁呢？更牛的CA，你不相信小的CA机构，但如果是大的CA机构呢，就这样CA一层层的做担保，直到大到那种全球认可的CA机构他们不再需要担保人，因为他们自身就是root CA。 在使用Https的时候还有一种常见的证书，就是自签名证书（self-signed certificate），有点像是我给自己带盐，你爱信不信的意思。 到现在为止我们知道了，在使用https的时候我们无法只使用对称加密算法，但可以只使用非对称加密，之前我们提到过，非对称加密算法在效率上要远低于对称加密算法，因此在传输大数据量的时候我们希望能使用对称加密来提高效率，因此https将两种加密算法搭配使用，具体的过程如下： 1.客户端发送Client Hello信息到服务器，信息以明文传输TLS版本信息、加密套件候选列表、压缩算法候选列表等。另外还会给对方一个随机数，这个随机数客户端和服务器都会留着。 2.服务器会回复Server Hello消息，告诉客户端用那个协议、加密套件、压缩算法等，并且服务器也会给客户端一个自己的随机数，现在每个人手里都有两个随机数了。 3.然后服务器会给客户端自己的证书 4.服务器会告诉客户端Server Hello done，我就给你这些信息。 5.客户端会去验证这个证书，在验证的过程中会不断的上溯CA、CA的CA，一直到一个你信任的CA出来做担保。 6.证书验证通过后，客户端会生成随机数Pre-master，发送Client Key Exchange，用证书中的公钥加密发给服务器。 7.服务器有了第三（客户端给了两个，自己生成一个）个随机数，客户端也有了三个随机数，然后双方都通过“自己的随机数”+“对端的随机数”+“Pre-master”一起算出对称密钥。 8.然后双方都发送给对方一个Encrypted Handshake Message，将已经协商好的参数等，采用密钥加密发给对方，作为握手验证，双方验证通过后就可以采用对称加密通信了。 总结 加密分为对称加密和非对称加密，对称加密效率高，但是解决不了秘钥的传输问题；非对称加密可以解决这个问题，但效率不高。 非对称加密需要通过证书来验证公钥的合法性。 https是综合了对称加密和非对称加密算法的http协议。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>https和http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法学习笔记（2）-数组]]></title>
    <url>%2F2020%2F01%2F14%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89-%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[前记 前篇总结复杂度分析，本篇学习数组。 数组 数组（Array）是一种线性表数据结构。它用一组连续的内存空间来存储一组具有相同类型的数据。 数组和链表的区别，很多人都说，“链表适合插入、删除，时间复杂度O(1)；数组适合查找，查找时间复杂度为O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。 数组为了保持内存数据的连续性，会导致插入、删除这两个操作比 较低效。 插入操作 如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是O(n)。因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为(1+2+…n)/n=O(n)。 如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须依次搬移k之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第k个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第k位的数据搬移到数组元素的最后，把新的元素直接放入第k个位置。 删除操作 跟插入数据类似，如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为O(1)；如果删除开头的数据，则最坏情况时间复杂度为O(n)；平均情况时间复杂度也为O(n)。 警惕数组的访问越界问题 数组越界在C语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。 容器能否完全替代数组？ 针对数组类型，很多语言都提供了容器类，比如Java中的ArrayList、C++STL中的vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？ 数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为10的数组，当第11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。如果使用vector等容器，我们就完全不需要关心底层的扩容逻辑，vector已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为2倍大小。 不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建vector的时候事先指定数据大小。 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验： 1.如果数据大小事先已知，并且对数据的操作非常简单，用不到vector提供的大部分方法，也可以直接使用数组 2.还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如int Object[][]array；而用容器的话则需要这样定义：vector&lt;vector&gt; v; 总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。]]></content>
      <categories>
        <category>算法学习</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法学习笔记（1）-复杂度分析]]></title>
    <url>%2F2020%2F01%2F13%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前记 众所周知，数据结构和算法是编程当中的内功，只有把内功修炼深厚，才能应对各种招式的变化。如果每天做一些机械性质的增删改查，那是注定在编程道路上走不远的，因此，从本篇开始，进行数据结构和算法的学习，并以笔记的形式进行知识点的总结。 基本复杂度分析 复杂度分析是算法学习的精髓，可以说掌握了复杂度分析，算法学习就成功了一半。而最常用的复杂度表示方法就是大O表示法，这是表示代码执行时间或所占空间随数据规模增长的变化趋势的一种方法。当n很大时，你可以把它想象成100000，而公式中的低阶、常量、系数三部分并不影响增长趋势，所以都可以忽略，我们只需保留一个最大量级就可以了。 时间复杂度分析 1 只关注循环执行次数最多的一段代码。 2 加法法则：总的时间复杂度等于量级最大的那段代码的时间复杂度。即抽象公式：T(n)=T1(n)+T2(n)=Max(O(f(n)),O(g(n)))。 3 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。 常见的复杂度有O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)、O(2^n)、O(n!)，其中O(2^n)和O(n!)为非多项式量级。 O(logn)比较难以分析，借用以下例子加以理解： 1234i = 1;while(i &lt;= n)&#123; i = i * 2;&#125; 可以看出i从1开始，每次循环就乘以2，当大于n时，循环结束，因此可以看出这是一个等比数列：2^0,2^1,2^2,2^3……2^k = n，其中k代表执行的次数，即k=logn（以2为底，用大O表示的话可以省略底数）。 另外，还有一种非寻常的情况，即代码的复杂度由两个数据的规模来决定，如下： 12345678910111213int cal(int m, int n) &#123; int sum_1 = 0; int i = 1; for (; i &lt; m; ++i) &#123; sum_1 = sum_1 + i; &#125; int sum_2 = 0; int j = 1; for (; j &lt; n; ++j) &#123; sum_2 = sum_2 + j; &#125; return sum_1 + sum_2;&#125; 可以看出，m和n表示两个数据规模，我们无法事先评估,m和n谁的量级大，所以复杂度就是O(m+n)。 空间复杂度分析 空间复杂度一般比较简单，能够通过肉眼看出来，例如下面代码： 12345678910void print(int n) &#123; int i = 0; int[] a = new int[n]; for (i; i &lt;n; ++i) &#123; a[i] = i * i; &#125; for (i = n-1; i &gt;= 0; --i) &#123; print out a[i] &#125;&#125; 可以看到，申请了一个大小为n的int类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是O(n)。 最好、最坏时间复杂度 顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。看代码： 1234567891011int find(int[] array, int n, int x) &#123; int i = 0; int pos = -1; for (; i &lt; n; ++i) &#123; if (array[i] == x) &#123; pos = i; break; &#125; &#125; return pos;&#125; 上述代码中，在一个数组中查找x，如果x是第一个数，则最快，而如果x不存在数组中，则要遍历n次，因此，最好复杂度O(1)，最坏复杂度O(n)。 平均情况时间复杂度 还是上述代码，为了方便你理解，我们假设在数组中与不在数组中的概率都为1/2。另外，要查找的数据出现在0～n-1这n个位置的概率也是一样的，为1/n。所以，根据概率乘法法则，要查找的数据出现在0～n-1中任意位置的概率就是1/(2n)。因此平均时间复杂度的计算过程为：1/2n+2/2n+……+n/2n+n/2=(3n+1)/4。这个值就是加权平均值，用大O法表示即：O(n)。 均摊时间复杂度 首先看代码： 1234567891011121314int[] array = new int[n];int count = 0;void insert(int val) &#123; if (count == array.length) &#123; int sum = 0; for (int i = 0; i &lt; array.length; ++i) &#123; sum = sum + array[i]; &#125; array[0] = sum; count = 1; &#125; array[count] = val; ++count;&#125; 这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用for循环遍历数组求和，并清空数组，将求和之后的sum值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。 最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为count的位置就可以了，所以最好情况时间复杂度为O(1)。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为O(n)。 假设数组的长度是n，根据数据插入的位置的不同，我们可以分为n种情况，每种情况的时间复杂度是O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是O(n)。而且，这n+1种情况发生的概率一样，都是1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：1/(n+1)+1/(n+1)+……+n/(n+1)=O(1)。 每一次O(n)的插入操作，都会跟着n-1次O(1)的插入操作，所以把耗时多的那次操作均摊到接下来的n-1次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是O(1)。这就是均摊分析的大致思路。 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系（即有规律），这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。]]></content>
      <categories>
        <category>算法学习</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构知识点]]></title>
    <url>%2F2019%2F12%2F10%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[树 1、一个节点所拥有子树的个数被称为它的度。度为0的节点被称为叶节点。树的度等于树中所有节点的度的最大值。 2、一个节点的层次通过令根节点位于第一层来定义（有些书中将根节点的层次定义为0）。如果一个节点位于层次n，那么它的孩子位于层次n+1。树的高度或深度定义为树中节点的最大层次。 3、位于二叉树第i层的节点个数最多为2^(i-1),i&gt;=1。深度为k的二叉树的最大节点个数为2^k-1，k&gt;=1。 4、二叉树的遍历分为前序、中序、后序遍历，例如前序遍历是指：在遍历某一节点的左右子树之前先访问该节点。中序和后序与此类似。 5、二叉搜索树（BST）的节点放置规则：任何节点的键值一定大于其左子树中的每一个节点的键值，并小于其右子树中的每一个节点的键值。因此，从根节点一直往左走，直到无左路可走，即得最小元素，从根节点一直往右走，直到无右路可走，即得最大元素。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑右移和算术右移]]></title>
    <url>%2F2019%2F12%2F09%2F%E9%80%BB%E8%BE%91%E5%8F%B3%E7%A7%BB%E5%92%8C%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[逻辑右移就是不考虑符号位，右移一位，左边补零即可。 算术右移需要考虑符号位，右移一位，若符号位为1，就在左边补1；否则，就补0。 所以算术右移也可以进行有符号位的除法，右移n位就等于除以2的n次方。 例如，8位二进制数11001101分别右移一位。 逻辑右移就是01100110 算术右移就是11100110]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归中的return]]></title>
    <url>%2F2019%2F12%2F06%2F%E5%85%B3%E4%BA%8E%E9%80%92%E5%BD%92%E4%B8%AD%E7%9A%84return%2F</url>
    <content type="text"><![CDATA[递归中的return常用来作为递归终止的条件，但是对于返回数值的情况，要搞明白它是怎么返回的。递归的方式就是自己调用自己，而在有返回值的函数中，上一层的函数还没执行完就调用下一层，因此，当达到递归终止条件时，首先return的是最底层调用的函数，return之后，继续执行上一层调用该函数之后的代码，此时我们看到的是上一层的情况，当上一层剩余的代码执行完之后，表示上一层的函数也结束，此时再返回上上一层，执行递归代码之后的代码，如此往复循环，直到返回到最上层，结束整个递归过程。需要注意的是，上一层执行递归之后的代码的时候，会调用下一层返回的值，也可以理解为在执行上一层代码的时候会调用下一层的实现过程，直到下一层执行完返回一个数值，然后再加上上一层的数值，就构成了上一层return的东西，如此往复。下面介绍例子。 123456static int Sum(int n) &#123; if (n &lt;= 1) //#1 return n; //#2 return n+Sum(n - 1); //#3 &#125; 上面是一个递归求和的代码，例如我们传参100进去，第一次执行到#3位置的时候，调用Sum(99)，此时Sum(100)还没有执行完，就已经开始执行Sum(99)了，Sum(100)要等待Sum(99)执行完后才开始执行自己未执行完的程序。同理当Sum(99)执行到#3位置的时候，也会调用Sum(98)，此时Sum(99)还没有执行完，Sum(99)要等到Sum(98)执行完之后才开始执行自己未执行完的程序…..就这样一直循环到n=1的时候，也就是在执行Sum(1)的时候满足递归结束条件，即return 1;这个时候表示Sum(1)已经执行完毕，接下来要执行Sum(2)中未执行完的内容，也就是return 2+Sum(1);而Sum(1)已经返回1，因此Sum(2)返回2+1=3，Sum(2)执行完毕，开始执行Sum(3)未执行完的内容…..如此往复，一直到Sum(99)执行完毕后，再执行Sum(100)中未执行完的内容，也就是return 100+Sum(99),而Sum(99)已经执行完毕，有返回值，因此Sum(100)=100+Sum(99)=5050。至此，整个递归过程结束，返回累加值。]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法积累]]></title>
    <url>%2F2019%2F11%2F20%2F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[贪心算法思想 假设一个问题比较复杂，暂时找不到全局最优解，那么我们可以考虑把原问题拆成几个小问题（分而治之思想），分别求每个小问题的最优解，再把这些“局部最优解”叠起来，就“当作”整个问题的最优解了。 使用贪心算法的前提： 1、原问题复杂度过高； 2、求全局最优解的数学模型难以建立； 3、求全局最优解的计算量过大； 4、没有太大必要一定要求出全局最优解，“比较优”就可以。]]></content>
      <categories>
        <category>算法学习</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F11%2F12%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[内存管理x86-32硬件-内存架构 1、地址是访问内存空间的索引。 2、80386是32位机器，即可寻址的范围是2^32=4G字节。 3、物理内存空间是计算机提交到总线上的用于访问计算机上的内存和外设的最终地址。一个计算机中只有一个物理地址空间。 4、线性地址空间是在操作系统的虚拟内存管理下，每个运行的应用程序能访问的地址空间。每个运行的程序都认为自己独享整个计算机系统的地址空间，这样可以让多个运行的应用程序之间相互隔离。 5、逻辑地址空间是应用程序直接使用的地址空间。 内存使用与分段 1、重定位：修改程序中的地址（是相对地址）。 2、编译时重定位的程序只能放在内存固定位置，载入时重定位的程序一旦载入内存就不能动了。因此重定位最适合的时机是运行时重定位，即在运行每条指令时才完成重定位。（每执行一条指令都要从逻辑地址算出物理地址）每个进程有各自的基地址，在每条指令执行的第一步先从PCB中取出这个基地址。 3、内存如何使用？首先找一块空地址，得到基地址，然后将基地址写入PCB寄存器中，在程序运行中，每执行一条指令，首先从PCB中取出基地址，再加上程序中的逻辑地址，即可翻译成物理地址，这样内存就使用起来了。当进程间切换时，PCB中的值也会跟着变化。 分段和分页机制 1、分段和分页是两种不同的地址变换机制，它们都对整个地址变换操作提供独立的处理阶段。尽管两种机制都使用存储在内存中的变换表，但所用的表结构不同。实际上，段表存储在线性地址空间，而页表存储在物理地址空间。因而段变换表可由分页机制重新定位而无需段机制的信息或合作。段变换机制把虚拟地址（逻辑地址）变换成线性地址，并且在线性地址中访问自己的表，但是并不知晓分页机制把这些线性地址转换到物理地址的过程。类似地，分页机制也不知道程序产生地址的虚拟地址空间。分页机制只是简单地把线性地址转换成物理地址，并且在物理内存中访问自己的转换表。 CPU管理 进程 1、进程就是一个程序的执行过程。 2、只有进程从内核态转移到用户态时，才可能发生抢占，进程在内核态下运行是不会被抢占的。 3、多线程是指操作系统在单个进程内支持多个并发执行路径的能力。 4、进程中所有线程共享该进程的状态和资源，它们驻留在同一块地址空间中，并且可以访问到相同的数据。当一个线程改变了内存中的一个数据项时，其他线程在访问该数据项时能看到变化后的结果。 5、在大多数操作系统中，独立进程间的通信通常需要内核的介入，以提供保护和通信所需要的机制。但是由于在同一个进程中的线程共享内存和文件，它们无需调用内核就可以通信。 6、进程的终止会导致进程中所有线程的终止。 7、进程从创建（Linux下调用fork()）到结束的整个过程就是进程的生命期，进程在其生命期中的运行轨迹实际上就表现为进程状态的多次切换，如进程创建以后会成为就绪态；当该进程被调度以后会切换到运行态；在运行的过程中如果启动了一个文件读写操作，操作系统会将该进程切换到阻塞态（等待态）从而让出CPU；当文件读写完毕以后，操作系统会在将其切换成就绪态，等待进程调度算法来调度该进程执行…… 8、用户态到内核态只能通过中断的方式。 进程同步与死锁 1、临界区：一次只允许一个进程进入该进程修改其信号量的那一段代码。 2、临界区代码保护原则：互斥进入，即如果一个进程在临界区中执行，则其他进程不允许进入。 3、好的临界区保护原则：（1）有空让进：当若干进程要求进入空闲临界区时，应尽快使一进程进入临界区。（2）有限等待：从进程发出进入请求到允许进入，不能无限等待。 线程 1、线程保留了并发的优点，避免了进程切换代价。 2、用户级线程，在用户态下切换。如果某个线程调用硬件在内核中发生阻塞，内核就会切换到其他进程，那么在之前那个进程下的用户级线程就会卡在那不动。 3、用户级线程用了两个栈，而内核级线程用了两套栈。即用户级线程切换的时候，TCB切换，用户栈也跟着切换；内核级线程切换的时候，TCB切换，用户栈和内核栈都要跟着切换。 4、内核级线程在内核栈之间切换的时候，通过TCB找到内核栈指针，然后通过ret切到某个内核程序，最后再用CS:PC切到用户程序。 系统调用 1、在通常情况下，调用系统调用和调用一个普通的自定义函数在代码上并没有什么区别，但调用后发生的事情有很大不同。调用自定义函数是通过 call 指令直接跳转到该函数的地址，继续运行。而调用系统调用，是调用系统库中为该系统调用编写的一个接口函数，叫 API（Application Programming Interface）。API并不能完成系统调用的真正功能，它要做的是去调用真正的系统调用，过程是：把系统调用的编号存入EAX；把函数参数存入其它通用寄存器；触发 0x80 号中断（int 0x80），进入内核态，调用相关的内核函数。]]></content>
      <categories>
        <category>操作系统学习</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective C++（2）]]></title>
    <url>%2F2019%2F09%2F30%2Feffective%20C%2B%2B%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.如果你打算在一个内含引用的类内支持赋值操作，你必须自己定义拷贝赋值操作符。 2.如果某个基类将拷贝赋值操作符声明为private，编译器就会拒绝为其子类生成一个拷贝赋值操作符。 3.当子类对象经由一个基类指针被删除，而该基类带着一个非虚析构函数，则在实际执行的时候，对象的子类部分没被销毁。将基类的析构函数声明为虚函数之后，子类的析构函数也自动成为虚析构函数，在主函数中基类指针指向的是派生类对象，当delete释放指针所指向的存储空间时，会执行派生类的析构函数，派生类的析构函数执行完之后会紧接着执行基类的析构函数，以释放从基类继承过来的成员变量所消耗的资源。 4.auto_ptrs有个不寻常的性质，若通过拷贝构造或拷贝赋值运算符复制它们，它们会变成null，而复制所得的指针将取得资源的唯一拥有权。 5.应该尽量延后变量的定义，直到能够给它初值实参为止，因为这样不仅能够避免构造和析构非必要对象，还可以避免毫无意义的默认构造行为。 6.将大多数inline限制在小型、频繁调用的函数身上。 7.public继承意味着“is a”的关系，虚函数意味着接口必须被继承，非虚函数意味着接口和实现都必须被继承。 8.private继承使得基类所有成员在子类中的访问权限变为private。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[零碎知识点]]></title>
    <url>%2F2019%2F09%2F28%2FC%2B%2B%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[C++ 1、逗号表达式是将括号中所有表达式的值算出来，但是只使用最后一个表达式的值。 2、构造函数是可以私有化的，但一般不会这样做，因为私有化的构造函数不能被new到，并且类不能通过该私有构造函数初始化（可以调用静态方法初始化）。 3、一个类中可以有任意个构造函数（可以函数重载），但只能有一个析构函数。无论何时，只要类的对象被创建，就会执行构造函数。 4、类的静态数据成员只能在类内声明，类外定义和初始化。因为静态成员属于整个类，而不属于某个对象，如果在类内初始化，会导致每个对象都包含该静态成员，这是矛盾的。const的静态成员可以在类内初始化，是因为它既然是const的，那后面的程序就不会再去试图初始化了。 5、当用#include“file.h”时，先搜索当前工作目录，如果没有，再去搜索标准库，库没有再搜索资源库；当用#include&lt;file.h&gt;时，编译器先从标准库开始搜索，如果没再搜索资源库目录，若还未找到则搜索当前工作目录。 6、字符数组的复制要用strcpy()函数,不能直接用赋值操作符赋值。不能将数组的内容拷贝给其他数组作为初始值，也不能用数组为其他数组赋值。 7、数组名就是数组首元素的地址，在用scanf函数输入的时候，不用加&amp;。 8、定义数组时可以对第一维的长度不指定，但第二维的长度不能省去。 9、C++运算符是有优先级的，一般是算术运算符&gt;关系运算符&gt;逻辑运算符&gt;条件运算符，所以运算符顺序是!（一元算术运算符）&gt; !=（关系运算符）&gt; &amp;&amp;（逻辑运算符）&gt; ?:（条件运算符） 10、内存对齐的3大规则: （1）对于结构体的各个成员，第一个成员的偏移量是0，排列在后面的成员其当前偏移量必须是当前成员类型的整数倍。 （2）结构体内所有数据成员各自内存对齐后，结构体本身还要进行一次内存对齐，保证整个结构体占用内存大小是结构体内最大数据成员的最小整数倍。 （3）如程序中有#pragma pack(n)预编译指令，则所有成员对齐以n字节为准(即偏移量是n的整数倍)，不再考虑当前类型以及最大结构体内类型。 11、✳是scanf函数中的一种修饰符，表示忽略该输入项，使用方法为：放在%与格式d（或者s，c等）之间，如：scanf(“%x%✳d%o”,&amp;x,&amp;y); 并且，scanf不能指明浮点数的精度。 12、子类实现父类虚函数叫重写，不叫重载。父类有纯虚函数，子类可以不实现，此时子类仍是抽象类。 13、继承类构造函数中，成员初始化列表同时出现对虚基类和非虚基类构造函数的调用时，虚基类的构造函数先于非虚基类的构造函数执行。 14、C语言中&amp;&amp;是一种双目运算符，表示与运算，而当左边所给表达式或变量为0时，不再计算右侧，整个表达式为零。 15、C语言中有数字三种表示：十进制、八进制(0开头)、十六进制(0x开头)。 16、内联函数是指用inline关键字修饰的函数。在类内定义的函数被默认成内联函数。内联函数从源代码层看，有函数的结构，而在编译后，却不具备函数的性质。内联函数不是在调用时发生控制转移，而是在编译时将函数体嵌入在每一个调用处。编译时，类似宏替换，使用函数体替换调用处的函数名。一般在代码中用inline修饰，但是能否形成内联函数，需要看编译器对该函数定义的具体处理。 17、结构化程序由三种基本结构组成，三种基本结构组成的算法只能完成符合结构化的任务。 18、字符数组整体输入输出只是库函数里面用循环来完成一个一个元素的输入输出的，宏观上看上去就成了整体输入输出了。本质上说，与整型数组单个元素输入输出并没有区别，差别在于整型数组并不知道什么位置终止，需要人为地控制输入输出终止的条件，字符数组则很简单，输出默认’\0’终止，输入则默认空白字符或者换行。 19、read是UNIX或类UNIX系统中的系统函数，而fread才是C库里面的库函数。 20、在类定义时，无法使用构造函数，因而无法完成对象的初始化，类还没有定义完，不能初始化对象。只有在定义类对象时才会调用构造函数。 21、一般成员变量需要在类内进行初始化。静态成员变量必须在类外初始化，int型静态成员常量在类中初始化。 22、由于类的构造次序是由基类到派生类，所以在构造函数中调用虚函数，这个虚函数不会呈现出多态；相反，类的析构是从派生类到基类，当调用继承层次中某一层次的类的析构函数时往往意味着其派生类部分已经析构掉，所以也不会呈现出多态。（effeetive c++ 条款9）。 23、虚函数可以声明为inline，因为加上inline只是我们对编译器的一种建议，是否为inline还得看编译器的选择。相反，内联函数不能为虚函数，因为函数的内联属性是在编译器确定的，是静态行为，而虚函数的性质是在运行期确定的，是动态行为，二者是矛盾的，所以要想作为内联函数，就不要将它写成虚函数。 24、在C中使用malloc时不需要强制类型转换，因为在C中从void※到其他类型的指针是自动隐式转换的；在C++中使用malloc时必须要强制类型转换，否则会报错，因为C++是不支持void※类型隐式转换为其他类型的，但在c++中一般用new而不用malloc。malloc有一个参数。 25、宏定义不做语法检查。预处理是在编译之前的处理，而编译的工作之一便是语法检查，所以预处理不做语法检查。 26、C++中引入友元函数，是为在该类中提供一个对外（除了他自己意外）访问的窗口;这个友元函数不属于该类的成员函数，他是定义在类外的普通函数，只是在类中声明该函数可以直接访问类中的private或者protected成员。 27、使用友元函数注意的要点： 1）类中通过使用关键字friend来修饰友元函数，但该函数并不是类的成员函数，其声明可以放在类的私有部分，也可放在共有部分。友元函数的定义在类体外实现，不需要加类限定。 2）一个类中的成员函数可以是另外一个类的友元函数，而且一个函数可以是多个类友元函数。 3）友元函数可以访问类中的私有成员和其他数据，但是访问不可直接使用数据成员，需要通过对对象进行引用。 4）友元函数在调用上同一般函数一样，不必通过对对象进行引用。 28、程序占用三种类型的内存：静态内存、栈内存、堆内存； 静态内存：用来保存局部static对象、类static数据成员以及定义在任何函数之外的变量。 栈内存：用来保存定义在函数内的非static对象。 堆内存：在程序运行时分配。 分配在静态内存或栈内存中的对象由编译器自动创建和销毁。对于栈对象，仅在其定义的程序块运行时才存在；static对象在使用之前分配，在程序结束时销毁。动态对象的生存周期由程序（用户）来控制。 29、数组指针和指针数组的区别： 指针数组：首先它是一个数组，数组的元素都是指针，数组占多少个字节由数组本身的大小决定，每一个元素都是一个指针，在32 位系统下任何类型的指针永远是占4 个字节。它是“储存指针的数组”的简称。 数组指针：首先它是一个指针，它指向一个数组。在32位系统下任何类型的指针永远是占4个字节，至于它指向的数组占多少字节，不知道，具体要看数组大小。它是“指向数组的指针”的简称。 30、C语言中实数常数的科学表示法规定格式为：“实数e整数”或“实数E整数”，其中幂是整数，不能写成实数。e(或E)前后的实数和整数都不能省略掉。C语言规定。0开头的是八进制数，0x(0x)开头的是十六进制数。而八进制数数字是0～7，出现8是错误的。实数的小数点前后的数字都可以不写。 31、逗号表达式的求解过程是：先求解表达式1，再求解表达式2。整个逗号表达式的值是表达式2的值。例如逗号表达式a=3+5,a+4，对此表达式的求解，赋值运算符的优先级别高于逗号运算符，因此应先求解a=3+5，经计算和赋值后得到a的值为8，然后求解a+4，得12，整个逗号表达式的值为12(a仍为8)。 32、文件指针指向的是一块内存区域，这块区域存储着打开的文件的相关信息，包括文件读取指针当前位置、文件读取缓冲区大小等信息，并不是指向文件的。fscanf是从文件中格式化读取，fprintf是向文件中格式化写入。 33、类的方法后面加了const后，该方法的实现中不能修改类的成员。 34、文件读写操作的几种模式： r代表read的简写，+代表可读可写，w代表write，b代表bit二进制位，t代表text。 r 打开只读文件，该文件必须存在。 r+ 打开可读可写的文件，该文件必须存在(这里的写文件是指将之前的文件覆盖。 rt 打开只读文本文件，该文本必须存在。 rt+ 读写打开一个文本文件，允许读和写，该文件必须存在(这里的写文件是指将之前的文件覆盖。 rb 只读打开一个二进制文件，该文件必须存在。 rb+ 读写打开一个二进制文件，允许读和写，该文件必须存在(这里的写文件是指将之前的文件覆盖。 w 打开只写文件，若文件存在，则文件长度清零，即文件内容会消失，若文件不存在则建立该文件。 w+ 打开可读写文件，若文件存在，则文件长度清零，即文件内容会消失，若文件不存在则建立该文件(这里的读文件，同样需要使用rewind()函数)。 wt 打开只写文本文件，若文件存在，则文件长度清零，即文件内容会消失，若文件不存在则建立该文件。 wt+ 打开可读写文本文件，若文件存在，则文件长度清零，即文件内容会消失，若文件不存在则建立该文件。 wb 打开只写二进制文件，若文件存在，则文件长度清零，即文件内容会消失，若文件不存在则建立该文件。 wb+ 打开可读写二进制文件，若文件存在，则文件长度清零，即文件内容会消失，若文件不存在则建立该文件。 a 以附加的方式打开只写文件，若文件不存在，则建立文件，存在则在文件尾部添加数据,即追加内容。 a+ 以附加的方式打开可读写文件，不存在则建立文件，存在则写入数据到文件尾(这里的读文件，同样需要使用rewind()函数，但是写文件不需要rewind()函数，a是追加)。 at 文本数据的追加，不存在则创建，只能写。 at+ 读写打开一个文本文件，允许读或在文本末追加数据(这里的读文件，同样需要使用rewind()函数，但是写文件不需要rewind()函数，a是追加)。 ab 二进制数据的追加，不存在则创建，只能写。 ab+ 读写打开一个二进制文件，不存在则创建,允许读或在文本末追加数据(这里的读文件，同样需要使用rewind()函数，但是写文件不需要rewind()函数，a是追加)。 35、静态局部变量和全局变量的区别：静态局部变量虽然和全局变量都存放在全局数据区，延长了生命周期，但是作用域不同！静态局部变量仍然是个局部变量，只对函数内可见。 36、栈空间上面的局部变量默认初始化为随机值。全局整形变量和静态static整形变量默认初始值为0。 37、c++中包含纯虚函数的类称为抽象类，由于抽象类中包含了没有定义的纯虚函数，所以不能定义抽象类的对象。 38、抽象类只能用作其他类的基类，不能定义抽象类的对象。抽象类不能用于参数类型、函数返回值或显示转换的类型。抽象类可以定义抽象类的指针和引用，此指针可以指向它的派生类，进而实现多态性。 39、逻辑运算符的优先级：! &gt; &amp;&amp; &gt; ||。!运算符比许多C++运算符具有更高的优先级。因此，为了避免错误，应始终将其操作数括在括号中，除非打算将其应用于没有其他操作符的变量或简单表达式。 40、运算符优先级：！&gt; 算术运算符 &gt; 关系运算符 &gt; （&amp;&amp; ||）&gt; 条件运算符&gt; 赋值运算符 &gt; 逗号运算符。 41、实型常量又称实数或浮点数。在C语言中可以用两种形式表示一个实型常量。 小数形式：小数形式是由数字和小数点组成的一种实数表示形式，例如0.123、.123、123.、0.0等都是合法的实型常量。注意：小数形式表示的实型常量必须要有小数点。 指数形式：这种形式类似数学中的指数形式。在数学中，一个可以用幂的形式来表示，如2.3026可以表示为0.23026×10^1 2.3026×10^0 23.026×10^-1等形式。在C语言中，则以“e”或“E”后跟一个整数来表示以“10”为底数的幂数。2.3026可以表示为0.23026E1、2.3026e0、23.026e-1。C语言语法规定，字母e或E之前必须要有数字，且e或E后面的指数必须为整数。如e3、5e3.6、.e、e等都是非法的指数形式。注意：在字母e或E的前后以及数字之间不得插入空格。 42、程序运行的过程中，其值不能被改变的量称为常量。常量有不同类型，其中12、0、-5为整型常量。’a’’b’为字符常量。而4.6、-8.7则为实型常量。一个实型常量可以赋给一个 float 型、double 型或 long double变量。根据变量的类型截取实型常量中相应的有效位数字。 43、用基类的指针指向不同的派生类的对象时，基类指针调用其虚成员函数，则会调用其真正指向对象的成员函数，而不是基类中定义的成员函数（只要派生类改写了该成员函数）。若不是虚函数，则不管基类指针指向的哪个派生类对象，调用时都会调用基类中定义的那个函数。 44、virtual函数是动态绑定，而缺省参数值却是静态绑定。意思是你可能会在“调用一个定义于派生类内的virtual函数”的同时，却使用基类为它所指定的缺省参数值。结论：绝不重新定义继承而来的缺省参数值！（可参考《Effective C++》条款37）例如： 1234567891011121314151617181920class A&#123;public: virtual void func(int val = 1) &#123; std::cout&lt;&lt;&quot;A-&gt;&quot;&lt;&lt;val &lt;&lt;std::endl;&#125; virtual void test() &#123; func();&#125;&#125;;class B : public A&#123;public: void func(int val=0)&#123;std::cout&lt;&lt;&quot;B-&gt;&quot;&lt;&lt;val &lt;&lt;std::endl;&#125;&#125;;int main(int argc ,char* argv[])&#123; B*p = new B; p-&gt;test();return 0;&#125; p-&gt;test()执行过程理解： (1) 由于B类中没有覆盖（重写）基类中的虚函数test()，因此会调用基类A中的test()； (2) A中test()函数中继续调用虚函数 fun()，因为虚函数执行动态绑定，p此时的动态类型（即目前所指对象的类型）为B✳，因此此时调用虚函数fun()时，执行的是B类中的fun()；所以先输出“B-&gt;”； (3) 缺省参数值是静态绑定，即此时val的值使用的是基类A中的缺省参数值，其值在编译阶段已经绑定，值为1，所以输出“1”； 最终输出“B-&gt;1”。所以记住上述结论：绝不重新定义继承而来的缺省参数值！ 45、char✳ strcpy(char ✳dest,char ✳src)；将从src开始包含’\0’的字符串拷贝到以dest开始的位置，进行覆盖char✳ strcat(char ✳dest,char ✳src);将src开始的字符串添加到dest字符串的末尾(覆盖dest的\0”)两者都返回指向dest的指针。 46、所谓的左值，说通俗一点就是可以被修改和引用的值，左值可以取地址。与之相对的就是右值。在使用时，左值可以作为右值，但右值不能作为左值。例如a++操作通过临时量返回其值，该值是一个常量，因此不能被修改（不是左值），而++a就是一个左值，可以修改。a++通过一个临时量temp返回其中值,该值是一个常量，并不是用户定义的那种可以引用，寻址的变量，不能对其进行修改或者赋值操作，只能将其用来赋值给其他左值。 47、cin&gt;&gt; 该操作符是根据后面变量的类型读取数据。输入结束条件：遇到Enter、Space、Tab键。对结束符的处理：丢弃缓冲区中使得输入结束的结束符(Enter、Space、Tab) 48、const只对它左边的东西起作用，唯一的例外就是const本身就是最左边的修饰符，那么它才会对右边的东西起作用。 49、模板的实参是用来实例化类类型参数（typename）的，因此实参必须为有已确定内存空间大小的数据类型（指针、用户自定义类···）；也不能为抽象类，可为具体类（抽象类的限制）。不是任意的数据类型。 网络 1、斜杠记法标识子网掩码，/20的意思就是掩码中有20个1，用十进制表示，就是255.255.240.0 二进制中255有8个1，240是1111 0000有4个1，一共20个1。/24即255.255.255.0。 2、HTTP状态码中400代表请求报文语法有误，服务器无法识别。 3、https使用的是非对称加密，举例子就是A生成一个公钥A，发送给B。B收到后对称生成一个秘钥B并用A加密，发送给A。最后A接收到后用私钥得到秘钥B，之后A与B之间就可以利用秘钥B进行加密通信了，并不用每次做一次非对称加密。 java 1、通常情况，JVM中使用类加载器的优先级是：根类加载器（bootstrap class loader）扩展类加载器（extensions class loader）系统类加载器（system class loader）用户类加载器（user class loader）。 2、Java8的Stream中的中间操作方法： （1）过滤：filter() （2）截断流：limit() （3）跳过元素：skip(n) （4）筛选：distinct() （5）映射：map() flatMap() （6）排序：sorted() 数据库 1、数据库中某一个字段的值并不唯一，但是需要创建索引加速查询速度，应该选择的索引类型为普通索引。即普通索引允许被索引列有重复值。 2、 数据结构和算法 1、采用插入方式构建一颗大小为n的红黑树的时间复杂度是：O(n*log(n))。 2、]]></content>
      <categories>
        <category>技术积累</category>
      </categories>
      <tags>
        <tag>零碎知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective C++（1）]]></title>
    <url>%2F2019%2F09%2F17%2Feffective%20C%2B%2B%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[01.C++总体来说包含四大部分内容，分别是：C语言部分（没有模板、异常、重载等概念）；面向对象部分（类、封装、继承、多态、虚函数等）；泛型编程部分（模板技术）；STL（容器、算法、迭代器等）。 02.对单纯常量，尽量以const对象或enums代替#define，因为宏定义是预处理器干的活，宏定义的记号名称有可能未被编译器看到，也许在编译器开始处理源码之前它就被预处理器移走了，因此编译会出错。而如果使用const等定义一个常量，编译器是一定会看到的，当然就会进入记号表内。 03.对于class专属常量，为了将常量的作用域限制于class内，必须让该常量成为class的一个成员。而为确保此常量至多只有一份实体，必须让它成为一个static成员。如下： 12345678class A&#123;private: static const int Num = 5; //常量声明式 int scores[Num]; ... &#125;;const int A::Num; //Num的定义 上面程序中，在声明的时候已经给常量做了初始化，对于class的static类型的专属常量，只要不取它们的地址，或者不需要用到定义式，则不提供定义式也可以，因为在声明的时候已经给了初值，所以在定义式中不可以再设初值。 04.对于形似函数的宏，最好用inline函数替换#define。 05.const修饰指针的时候，如果const出现在星号左边，表示被指物是常量，如果出现在星号右边，表示指针自身是常量，如果出现在星号两边，表示被指物和指针两者都是常量。注意：当被指物是常量时，const写在类型前和类型后都可以。 06.声明STL的迭代器为const和声明指针为const是一样的操作，但是声明迭代器所指物为const需要用const_iterator。 07.non-const成员函数可以调用const成员函数，反之则不行。 08.确保对象在使用之前已经被初始化，读取未初始化的值会导致不明确的行为。 09.对于大多数类型而言，比起先调用默认构造函数后再调用拷贝赋值操作符，单只调用一次拷贝构造函数是比较高效的。对于内置类型来说，其初始化和赋值的成本相同，但为了一致性，最好也通过初始值列表来初始化。 10.如果成员变量是const或引用，则必须初始化，不能被赋值。 11.成员变量的初始化顺序是以其声明顺序被初始化的，并且父类的变量先初始化，再子类。 12.如果某编译单元内的某个全局static对象的初始化使用了另一编译单元内的某个全局static对象，它所用到的这个对象可能尚未被初始化，因为C++对“定义于不同编译单元内的全局static对象”的初始化次序并无明确定义。为解决此问题，可以用一个函数来代替这个全局对象。如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//有问题的代码class FileSystem&#123;public: ... std::size_t num() const; ...&#125;;extern FileSystem tfs; //给客户使用的对象class Directory&#123;public: Directory(params); ...&#125;;Directory::Directory(params)&#123; ... std::size dis = tfs.num(); //使用tfs对象 ...&#125;Directory tempDir(params);//修改后的代码class FileSystem&#123;public: ... std::size_t num() const; ...&#125;;FileSystem&amp; tfs() //用该函数替换tfs对象&#123; static FileSystem fs; return fs;&#125;class Directory&#123;public: Directory(params); ...&#125;;Directory::Directory(params)&#123; ... std::size dis = tfs().num(); //改用tfs() ...&#125;Directory&amp; tempDir() //用该函数替换tempDir对象&#123; static Directory td; return td;&#125;]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四年的青春，我们的故事还在继续]]></title>
    <url>%2F2019%2F08%2F14%2F%E6%88%91%E4%BB%AC%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[今天学会了插入图片，让我来试一波吧，哈哈哈哈哈…… 初次约会，多多关照 一起吃火锅 一起看灯展 一起去海滩 一起去海滩+1 一起去海滩+2 毕业了… 一起逛北京]]></content>
      <categories>
        <category>生活杂谈</category>
      </categories>
      <tags>
        <tag>生活杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型（5） -- 对象构造语义学]]></title>
    <url>%2F2019%2F08%2F13%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%EF%BC%885%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、继承体系下的对象构造步骤及虚函数调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class A&#123;public: A() &#123; printf(&quot;A this = %p\n&quot;, this); cout &lt;&lt; &quot;A::A()&quot; &lt;&lt; endl; &#125; virtual ~A() &#123;&#125; virtual void myvirfunc() &#123;&#125; virtual void myvirfunc2() &#123;&#125;&#125;;class B:public A&#123;public: B() &#123; printf(&quot;B this = %p\n&quot;, this); cout &lt;&lt; &quot;B::B()&quot; &lt;&lt; endl; &#125; virtual ~B() &#123;&#125; virtual void myvirfunc() &#123;&#125; virtual void myvirfunc2() &#123;&#125;&#125;;class C:public B&#123;public: C():m_c(11) &#123; myvirfunc(); //构造函数中，这里没有走虚函数表，而是直接通过虚函数地址，直接调用这个虚函数（静态方式调用） myvirfunc1(); //虚函数中再调虚函数，走虚函数表 printf(&quot;C this = %p\n&quot;, this); cout &lt;&lt; &quot;C::C()&quot; &lt;&lt; endl; &#125; virtual ~C() &#123;&#125; virtual void myvirfunc() &#123;&#125; virtual void myvirfunc1() &#123; myvirfunc2(); &#125; virtual void myvirfunc2() &#123;&#125; int m_c;&#125;;int main()&#123; C cobj; C *mycobj = new C(); mycobj-&gt;myvirfunc(); //代码实现上的多态 return 1;&#125; （1）继承关系为：C继承于B，B继承于A。当定义一个对象的时候，构造函数的调用顺序为：类A的构造函数、类B的构造函数、类C的构造函数。 （2）当类中有虚函数，并且在构造函数中调用时，如果被调用虚函数里面没有虚函数，则不是走虚函数表调用，而是直接通过虚函数地址静态调用。如果被调用虚函数里面再调用其他虚函数，则就会走虚函数表调用。 二、对象拷贝、析构函数对象的拷贝行为 （1）如果我们不写自己的拷贝构造函数和拷贝赋值运算符，编译器也会有默认的对象拷贝和对象赋值行为。 （2）当我们提供自己的拷贝赋值运算符和拷贝构造函数时，我们就接管了系统默认的拷贝行为，此时，我们有责任在拷贝赋值运算符和拷贝构造函数中写适当的代码，来完成对象的拷贝或者赋值的任务。 （3）要想禁止对象的默认拷贝构造和赋值，只要把拷贝构造函数和拷贝赋值运算符私有起来，只声明，不需要写函数体。 析构函数 编译器会给我们生成一个析构函数的情况： （1）如果继承一个基类，基类中带析构函数，那么编译器就会给我们合成出一个析构函数来调用基类中的析构函数。 （2）如果类成员是一个类类型成员，并且这个成员带析构函数，编译器也会合成出一个析构函数，这个析构函数存在的意义是要调用这个类类型成员所在类的析构函数。 如果我们有自己的析构函数，那么编译器就会在适当的情况下扩展我们的析构函数代码： （1）如果类成员是一个类类型成员，并且这个成员带析构函数，编译器就扩展这个类的析构函数代码，即先执行了本类的析构函数代码，再执行类类型的析构函数代码。 （2）如果继承一个基类，基类中带析构函数，那么编译器就会扩展我们类的析构函数来调用基类中的析构函数。 三、局部类对象、全局类对象的构造和析构函数 （1）对于局部类对象，只要出了对象的作用域，编译器总会在适当的地方插入调用对象析构函数的代码。因此局部对象应该现用现定义，这样可以减少某些情况下的开销（如果在开头处定义对象，而程序还没有运行到使用对象的时候就已经退出，此时就算没有用到对象，编译器也会调用局部类对象的析构函数，这会增加不必要的开销）。 （2）全局变量是放在数据段里的，在编译阶段就会把空间分配出来（全局变量的地址在编译期间就确定好的）。全局对象，在不给初值的情况下，编译器默认会把全局对象所在内存全部清0。 （3）全局对象构造和析构的步骤： a)全局对象获得地址（编译时确定好的，内存也是编译时分配好的，内存时运行期间一直存在） b)把全局对象的内存内容清0（也叫静态初始化） c)调用全局对象所对应的类的构造函数 d)main(){……} e)调用全局对象所对应类的析构函数 （4）全局对象在main函数执行之前就被构造完毕，可以在main函数中直接使用，在main函数执行完毕后才被析构掉。 12345678910111213141516171819class A&#123;public: A() &#123; cout &lt;&lt; &quot;A::A()&quot; &lt;&lt; endl; &#125; ~A() &#123; cout &lt;&lt; &quot;A::~A()&quot; &lt;&lt; endl; &#125; int m_i;&#125;;A g_aobj; //全局对象int main()&#123; A aobj; //局部对象 return 1;&#125; 四、局部静态对象的构造和析构123456789101112131415161718192021222324252627class A&#123;public: A() &#123; cout &lt;&lt; &quot;A::A()&quot; &lt;&lt; endl; &#125; ~A() &#123; cout &lt;&lt; &quot;A::~A()&quot; &lt;&lt; endl; &#125; int m_i;&#125;;const A &amp;myfunc()&#123; //局部静态对象 static A s_aobj1; printf(&quot;s_aobj1的地址是%p\n&quot;, &amp;s_aobj1); return s_aobj1;&#125;int main()&#123; myfunc(); myfunc(); return 1; &#125; （1）如果我们不调用myfunc()函数，那么根本不会触发A的构造函数。 （2）局部静态对象，内存地址是在编译期间就确定好的。 （3）静态局部变量刚开始也被初始化为0。 （4）局部静态对象的析构，是在main函数执行结束后才被调用的。（前提是这个静态局部对象被构造过） （5）不管myfunc()函数被调用几次，s_aobj1这种静态局部对象只会被构造1次。（只调用一次构造函数） 五、new和delete （1）new类对象时加不加括号的差别：如果是个空类，那么加不加括号没有区别（现实中，不可能光写一个空类）。如果类中有成员变量，则带括号的初始化会把一些和成员变量有关的内存清0，但不是整个对象的内存全部清0。当类中有构造函数，两种写法都会调用类的构造函数。 （2）new干了两个事：一个是调用operator new(malloc)，一个是调用了类A的构造函数。delete也干了两个事：一个是调用了类A的析构函数，一个是调用operator delete(free)。 六、临时对象拷贝构造函数相关的临时对象1234567891011121314151617181920212223242526272829303132class A&#123;public: A() &#123; cout &lt;&lt; &quot;A::A()构造函数被执行&quot; &lt;&lt; endl; &#125; A(const A&amp; tmpobj) &#123; cout &lt;&lt; &quot;A::A()拷贝构造函数被执行&quot; &lt;&lt; endl; &#125; ~A() &#123; cout &lt;&lt; &quot;A::~A()析构函数被执行&quot; &lt;&lt; endl; &#125;&#125;;A operator+(const A&amp; obj1, const A&amp; obj2)&#123; A tmpobj; return tmpobj; //此时编译器产生临时对象，把tmpobj对象的内容通过调用拷贝构造函数把tmpobj的内容拷贝构造给这个临时对象，然后返回的是这个临时对象。&#125;int main()&#123; A myobj1; A myobj2; A resultobj = myobj1 + myobj2; //这个从operator+里返回的临时对象直接构造到了resultobj里； return 1; &#125; 拷贝赋值运算符相关的临时对象class A { public: A() { cout &lt;&lt; &quot;A::A()构造函数被执行&quot; &lt;&lt; endl; } A(const A&amp; tmpobj) { cout &lt;&lt; &quot;A::A()拷贝构造函数被执行&quot; &lt;&lt; endl; } A &amp; operator=(const A&amp; tmpaobj) { cout &lt;&lt; &quot;A::operator()拷贝赋值运算符被执行&quot; &lt;&lt; endl; return *this; } ~A() { cout &lt;&lt; &quot;A::~A()析构函数被执行&quot; &lt;&lt; endl; } }; A operator+(const A&amp; obj1, const A&amp; obj2) { A tmpobj; return tmpobj; //编译器产生临时对象，把tmpobj对象的内容通过调用拷贝构造函数 把tmpobj的内容拷贝构造给这个临时对象,然后返回的是这个临时对象。 } int main() { A myobj1; A myobj2; A resultobj; resultobj = myobj1 + myobj2; //调用拷贝赋值运算符 //A resultobj = myobj1 + myobj2; //调用拷贝构造函数 return 1; }直接运算产生的临时对象class A { public: A() { cout &lt;&lt; &quot;A::A()构造函数被执行&quot; &lt;&lt; endl; } A(const A&amp; tmpobj) { cout &lt;&lt; &quot;A::A()拷贝构造函数被执行&quot; &lt;&lt; endl; m_i = tmpobj.m_i; } A &amp; operator=(const A&amp; tmpaobj) { cout &lt;&lt; &quot;A::operator()拷贝赋值运算符被执行&quot; &lt;&lt; endl; return *this; } ~A() { cout &lt;&lt; &quot;A::~A()析构函数被执行&quot; &lt;&lt; endl; } int m_i; }; A operator+(const A&amp; obj1, const A&amp; obj2) { A tmpobj; tmpobj.m_i = obj1.m_i + obj2.m_i; return tmpobj; //编译器产生临时对象，把tmpobj对象的内容通过调用拷贝构造函数 把tmpobj的内容拷贝构造给这个临时对象，然后返回的是这个临时对象。 } int main() { A myobj1; myobj1.m_i = 1; A myobj2; myobj2.m_i = 2; A resultobj = myobj1 +myobj2; //临时对象被接住，不会被立即析构 myobj1 + myobj2; //产生了临时对象，然后该临时对象立即被析构； printf(&quot;(myobj1 + myobj2).m_i = %d\n&quot;, (myobj1 + myobj2).m_i); //临时对象的析构是整行语句的最后一步，这样就能保证printf打印出来一个有效值。 编译器要往必要的地方，帮助我们插入 A tmpobja1 = (myobj1 + myobj1);这样的代码，来产生临时对象供编译器完成我们程序开发者代码要实现的意图。 return 1; }]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>C++对象模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型（4） -- 函数语义学]]></title>
    <url>%2F2019%2F08%2F11%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%EF%BC%884%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、普通成员函数调用方式1234567891011121314151617181920212223242526272829303132class MYACLS&#123;public: int m_i; void myfunc(int abc) &#123; m_i += abc; &#125;&#125;;//编译器视角void _ZN6MYACLS6myfuncEi(MYACLS *const this, int abc) //编译器会额外安插一个this指针，一般会扔到参数的开头&#123; this-&gt;m_i + abc;&#125;void gmyfunc(MYACLS *ptmp,int abc)&#123; ptmp-&gt;m_i += abc;&#125;int main()&#123; MYACLS myacls; myacls.myfunc(18); //调用成员函数 gmyfunc(&amp;myacls, 18); //调用全局函数 printf(&quot;MYACLS::myfunc的地址=%p\n&quot;, &amp;MYACLS::myfunc); //可以发现多次打印成员函数的地址，都不会改变，编译的时候已经确定好了 return 1;&#125; （1）c++语言设计的时候有一个要求：要求对普通成员函数的调用不应该比全局函数效率差。基于这种设计要求，编译器内部实际上是将对成员函数myfunc()的调用转换成了对全局函数的调用。 （2）成员函数有独立的内存地址，是跟着类走的，并且成员函数的地址是在编译的时候就确定好的。 （3）编译器额外增加了一个叫this的形参，是个指针，指向的其实就是生成的对象。 （4）常规成员变量的存取，都通过this形参来进行，比如上述 this-&gt;m_i + abc。 二、虚成员函数、静态成员函数调用方式虚成员函数（虚函数）调用方式1234567891011121314151617181920212223242526272829303132class MYACLS&#123;public: virtual void myvirfunc() &#123; printf(&quot;myvirfunc()被调用,this = %p\n&quot;, this); myvirfunc2(); //走虚函数表指针调用 MYACLS::myvirfunc2(); //直接调用虚函数，效率更高。这种写法压制了虚拟机制，不再通过查询虚函数表来调用 //这种用类名::虚函数名()明确调用虚函数的方式等价于直接调用一个普通函数； &#125; virtual void myvirfunc2() &#123; printf(&quot;myvirfunc2()被调用,this = %p\n&quot;, this); &#125;&#125;;int main()&#123; MYACLS myacls; myacls.myvirfunc(); //用对象调用虚函数。 MYACLS *pmyacls = new MYACLS(); pmyacls-&gt;myvirfunc(); //用指针调用虚函数 //编译器视角 //(*pmyacls-&gt;vptr[0])(pmyacls); //a)vptr，编译器给生成的虚函数表指针，指向虚函数表 //b)[0] 虚函数表中第一项。代表myvirfunc()地址 //c)传递一个参数进去，就是this，也是编译器给加的 //d)*就得到了虚函数的地址； //printf(&quot;MYACLS::myvirfunc2虚函数的地址为%p&quot;, &amp;MYACLS::myvirfunc2); //地址也是在编译阶段确定的，多次打印不会变&#125; （1）用对象调用虚函数，就像调用普通成员函数一样,不需要通过虚函数表。 （2）用指针调用虚函数，要通过虚函数表指针查找虚函数表，通过虚函数表在好到虚函数的入口地址，完成对虚函数的调用。 静态成员函数调用方式1234567891011121314151617181920212223242526272829303132333435363738class MYACLS&#123;public: int m_i; void myfunc(int abc) &#123; //m_i += abc; //这里需要用到this指针，而this指针为空，则会报告异常 mystfunc(); &#125; //静态成员函数 static int m_si; static void mystfunc() //不需要this参数 &#123; printf(&quot;mystfunc()被调用\n&quot;); m_si = 1; &#125;&#125;;int main()&#123; MYACLS myacls; MYACLS *pmyacls = new MYACLS(); myacls.mystfunc(); pmyacls-&gt;mystfunc(); MYACLS::mystfunc(); ((MYACLS *)0)-&gt;mystfunc(); //能够正常调用静态成员函数 ((MYACLS *)0)-&gt;myfunc(12); //有些成员函数希望支持独立于类对象之外的存取操作,归为类所有，跟静态成员函数看似相似 myacls.myfunc(12); //此时如果要存取非静态成员变量，就会出错。 pmyacls-&gt;myfunc(12); printf(&quot;MYACLS::mystfunc()地址 = %p\n&quot;, MYACLS::mystfunc); delete pmyacls; return 1;&#125; （1）静态成员函数没有this指针，这点最重要。 （2）无法直接存取类中普通的非静态成员变量，因为非静态成员变量是通过this指针来操作的。 （3）静态成员函数不能在后面使用const，也不能设置为virtual。 （4）可以用类对象调用，但不非一定要用类对象调用。 （5）静态成员函数等同于非成员函数，有的需要提供回调函数的这种场合，可以将静态成员函数作为回调函数； 三、静态、动态类型，绑定，多态实现深谈静态类型和动态类型 （1）静态类型：对象定义时的类型，编译期间就确定好的。 （2）动态类型：对象目前所指向的类型（运行的时候才决定的类型）。 （3）一般只有指针或者引用才有动态类型的说法。而且一般都是指父类的指针或者引用。另外，动态类型在执行过程中可以改变。 仔细看如下代码分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Base&#123;public: void myfunc() //普通成员函数 &#123; cout &lt;&lt; &quot;Base::myfunc()&quot; &lt;&lt; endl; &#125; virtual void myvirfunc(int value = 1) &#123; cout &lt;&lt; &quot;Base::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;class Derive :public Base&#123;public: void myfunc() //普通成员函数 &#123; cout &lt;&lt; &quot;Derive::myfunc()&quot; &lt;&lt; endl; &#125; virtual void myvirfunc(int value = 2) &#123; cout &lt;&lt; &quot;Derive::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;class Derive2 :public Base&#123;public:&#125;;class A&#123;public: virtual void myvirfunc() &#123;&#125;&#125;;int main()&#123; Base base; //base的静态类型是Base，没有动态类型，因为不是指针不是引用 Derive derive; //derive的静态类型是Derive，没有动态类型，因为不是指针不是引用 Base *pbase; //pbase的静态类型依旧是Base * ,至少目前没有动态类型，因为它没有指向任何对象 Base *pbase2 = new Derive(); //pbase2的静态类型依旧是Base * ，动态类型是Derive Base *pbase3 = new Derive2(); //pbase3的静态类型依旧是Base *，动态类型是Derive2 pbase = pbase2; //pbase的动态类型Derive pbase = pbase3; //pbase的动态类型改变为Derive2&#125; 静态绑定和动态绑定 （1）静态绑定：绑定的是静态类型，所对应的函数或者属性依赖于对象的静态类型，发生在编译期 （2）动态绑定：绑定的是动态类型，所对应的函数或者属性依赖于对象的动态类型，发生在运行期 （3）普通成员函数是静态绑定，而虚函数是动态绑定。缺省参数一般是静态绑定。 代码分析： 123456789101112131415161718192021222324252627282930313233class Base&#123;public: void myfunc() //普通成员函数 &#123; cout &lt;&lt; &quot;Base::myfunc()&quot; &lt;&lt; endl; &#125; virtual void myvirfunc(int value = 1) &#123; cout &lt;&lt; &quot;Base::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;class Derive :public Base&#123;public: void myfunc() //普通成员函数 &#123; cout &lt;&lt; &quot;Derive::myfunc()&quot; &lt;&lt; endl; &#125; virtual void myvirfunc(int value = 2) &#123; cout &lt;&lt; &quot;Derive::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;int main()&#123; Derive derive; Derive *pderive = &amp;derive; pderive-&gt;myfunc(); //Derive::myfunc() Base *pbase = &amp;derive; pbase-&gt;myfunc(); ////Base::myfunc() &#125; 普通成员函数是静态绑定，换句话说，myfunc()是普通成员函数。这里到底调用父类的myfunc还是子类的myfunc取决于调用者的静态类型。 因为这里pbase的静态类型是Base，所以调用的是Base里的myfunc()；pderive的静态类型是Derive，所以调用的是Derive的myfunc()。 结论：为了避免混淆，不应该在子类中重新定义一个继承来的非虚函数。 再看如下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041class Base&#123;public: void myfunc() //普通成员函数 &#123; cout &lt;&lt; &quot;Base::myfunc()&quot; &lt;&lt; endl; &#125; virtual void myvirfunc(int value = 1) //缺省参数的值为1 &#123; cout &lt;&lt; &quot;Base::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;class Derive :public Base&#123;public: void myfunc() //普通成员函数 &#123; cout &lt;&lt; &quot;Derive::myfunc()&quot; &lt;&lt; endl; &#125; virtual void myvirfunc(int value = 2) //缺省参数的值为2 &#123; cout &lt;&lt; &quot;Derive::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;int main()&#123; Derive derive; Derive *pderive = &amp;derive; Base *pbase = &amp;derive; pderive-&gt;myvirfunc(); //执行Derive的myvirfunc(); --- Derive::myvirfunc() pbase-&gt;myvirfunc(); //pbase动态类型是Derive，而虚函数是动态绑定，参照是它的动态类型；--- Derive::myvirfunc() //缺省value参数打印出来的居然是1：Derive::myvirfunc(),value = 1 //这就始于函数参数缺省值的静态绑定，所以缺省参数绑定到了父类函数的缺省参数上去了 Base &amp;yinbase = derive; //引用，效果和指针一样 yinbase.myvirfunc(); //Derive::myvirfunc(),value = 1 pbase = &amp;base; pbase-&gt;myvirfunc(); //----Base::myvirfunc(); Base::myvirfunc(),value = 1&#125; 虚函数是动态绑定,换句话说，myvirfunc()是虚函数，这里到底执行哪个myvivfunc()取决于调用者的动态类型。 这里pbase的动态类型分别Derive，Base，所以调用的也分别是Derive和Base的myvirfunc()，pderive的动态类型是Derive，所以调用的是Derive的myvirfunc()。 从上面代码中可以看出，虚函数的参数缺省值是静态绑定，所以不要重新定义虚函数的缺省参数的值。 c++中的多态性的体现 多态性这个概念，分两方面谈： a)从代码实现上 b)从表现形式上 有一个观点是肯定的：多态，必须是存在虚函数，没有虚函数，绝不可能存在多态，有虚函数并且调用虚函数。 （1）从代码实现上来看，当我们调用一个虚函数时，走的是不是通过查询虚函数表来找到虚函数入口地址，然后去执行虚函数，如果走的是这个途径，那就是多态，如果不走这个途径，它就不是多态。看代码分析： 12345678910111213141516171819class A&#123;public: virtual void myvirfunc() &#123;&#125;&#125;;int main()&#123; A *pa = new A(); pa-&gt;myvirfunc(); //是多态 A a; a.myvirfunc(); //这个就不是多态 A *pa1 = &amp;a; pa1-&gt;myvirfunc(); //这个也是多态 return 1;&#125; （2）从表现形式上来看(通过代码来体现) a)有继承关系，有父类有子类，父类中必须有虚函数(这意味着子类中一定有虚函数)，子类重写父类的虚函数。 b)父类指针或者引用指向子类对象。 c)当以父类指针或者引用调用子类中重写了的虚函数时，我们就能看出来多态的表现了，因为调用的是子类的虚函数。 代码分析： 12345678910111213141516171819202122232425class Base&#123;public: virtual void myvirfunc() &#123; cout &lt;&lt; &quot;Base::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;;class Derive :public Base&#123;public: virtual void myvirfunc() &#123; cout &lt;&lt; &quot;Derive::myvirfunc(),value = &quot; &lt;&lt; value &lt;&lt; endl; &#125;&#125;; int main()&#123; Derive derive; Base *pbase = &amp;derive; pbase-&gt;myvirfunc(); //多态实现 return 1;&#125; 四、多继承下的第二基类问题探讨 先给出一个继承关系，稍后做具体分析。 123456789101112131415161718192021222324252627282930313233343536373839class Base&#123;public: virtual void f() &#123; cout &lt;&lt; &quot;Base::f()&quot; &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; &quot;Base::g()&quot; &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; &quot;Base::h()&quot; &lt;&lt; endl; &#125; virtual ~Base() &#123; int abc; abc = 1; &#125;&#125;;class Base2&#123;public: virtual void hBase2() &#123; cout &lt;&lt; &quot;Base2::hBase2()&quot; &lt;&lt; endl; &#125; virtual ~Base2() &#123; int abc; abc = 1; &#125;&#125;;class Derive :public Base,public Base2 &#123;public: virtual void i() &#123; cout &lt;&lt; &quot;Derive::i()&quot; &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; &quot;Derive::g()&quot; &lt;&lt; endl; &#125; void myselffunc() &#123;&#125; //只属于Derive的函数 virtual ~Derive() &#123; int abc; abc = 1; &#125; &#125;; 多重继承的复杂性往往体现在后边这个基类上，先来看使用后面这个基类的情况： 12345Base2 *pb2 = new Derive();//编译器视角Derive *temp = new Derive();Base2 *pb2 = (Base2 *)((char *)temp + sizeof(Base));delete pb2; 现在，我们考虑如何成功删除用第二基类指针new出来的继承类对象。注意，我们要删除的实际是整个Derive()对象，要能够保证Derive()对象的析构函数被正常调用，那么编译器会调用Base2的析构函数，还是调用Derive的析构函数呢？执行delte pb2时，系统的动作会是什么？ 事实上，这里分为以下几种情况： （1）如果Base2里没有析构函数,编译器会直接删除以pb2开头的这段内存，一定报异常，因为这段内存压根就不是new起始的内存。 （2）如果Base2里有一个析构函数，但整个析构函数是个普通析构函数（非虚析构函数），那么当delte pb2，这个析构函数就会被系统调用,但是delete的仍旧是pb2开头这段内存，所以一定报异常。因为这段内存压根就不是new起始的内存。（析构函数如果不是虚函数，编译器会实施静态绑定，静态绑定意味着你delete Base2指针时，删除的内存开始地址就是pb2的当前位置，所以肯定是错误的）。 （3）如果Base2里是一个虚析构函数，则delete的时候，编译器会自动按～Dervice() –&gt; ～Base2() –&gt; ～Base()的顺序调用，此时就是把整个Derive()对象的内存都释放了。 （4）Derive里就就算没有虚析构函数，因为Base2里有虚析构函数，编译器也会为此给Derive生成虚析构函数，为了调用～Base2()和～Base()虚析构函数。 由上述结论知，凡是涉及到继承的，所有类都加上虚析构函数，以防异常。 另外，Derive类的第二个虚函数表中发现了thunk字样，一般它用在多重继承中（从第二个虚函数表开始可能就 会有），用于this指针调整。它其实是一段汇编代码，这段代码干两个事情： (1)调整this指针（this指针调整的目的就是让对象指针正确的指向对象首地址，从而能正确的调用对象的成员函数或者说正确确定数据成员的存储位置） (2)调用Derive析构函数 五、虚基类带虚函数的成员分布以及继承开销123456789101112131415161718192021class Base&#123;public: virtual void f() &#123;&#125; virtual ~Base() &#123;&#125; int m_basei;&#125;;class Derive :public virtual Base&#123;public: virtual ~Derive()&#123;&#125; int m_derivei;&#125;;int main()&#123; cout &lt;&lt; sizeof(Derive) &lt;&lt; endl; // 16 Derive dobj; dobj.m_basei = 2; // 13-16字节 dobj.m_derivei = 5; // 5-8字节&#125; 由此可以看出，此种情况下的数据分布应该是：虚基类表指针（1-4字节）、子类数据成员（5-8字节）、虚函数表指针（9-12字节）、基类数据成员（13-16字节）。 一般来说， （1）随着继承深度的增加，开销或者说执行时间也会增加。 （2）多重继承一般也会导致开销增加。 （3）虚函数也会导致开销增加。 六、指向成员函数的指针以及vcall探讨指向普通成员函数的指针 成员函数地址是在编译时就确定好的。但是，要想调用成员函数，是需要通过对象来调用的。所有常规（非静态）成员函数，要想调用，都需要一个对象来调用它。并且，通过成员函数指针对常规的成员函数调用的成本，和通过普通的函数指针来调用静态成员函数，成本上差不多。 1234567891011121314151617181920212223242526272829303132333435363738class A&#123;public: void myfunc1(int tempvalue1) &#123; cout &lt;&lt; &quot;tempvalue1 = &quot; &lt;&lt; tempvalue1 &lt;&lt; endl; &#125; void myfunc2(int tempvalue2) &#123; cout &lt;&lt; &quot;tempvalue2 = &quot; &lt;&lt; tempvalue2 &lt;&lt; endl; &#125; static void mysfunc(int tempvalue) &#123; cout &lt;&lt; &quot;A::mysfunc()静态成员函数--tempvalue = &quot; &lt;&lt; tempvalue &lt;&lt; endl; &#125;&#125;;int main()&#123; A mya; void (A::*pmypoint)(int tempvalue) = &amp;A::myfunc1; //定义一个成员函数指针并给初值 pmypoint = &amp;A::myfunc2; //给成员函数指针赋值 (mya.*pmypoint)(15); //通过成员函数指针来调用成员函数，必须要通过对象的介入才能调用 A *pmya = new A(); (pmya-&gt;*pmypoint)(20); //用对象指针介入来使用成员函数指针来调用成员函数 //编译器视角 //pmypoint(&amp;mya, 15); //pmypoint(pmya, 20); void(*pmyspoint)(int tempvalue) = &amp;A::mysfunc; //一个普通的函数指针，而不是成员函数指针 pmyspoint(80); return 1;&#125; 指向虚成员函数的指针及vcall理解 vcall(vcall trunk) = virtual call：虚调用。它代表一段要执行的代码的地址，这段代码引导编译器去执行正确的虚函数，或者我们直接把vcall看成虚函数表，如果这么看待的话，那么vcall{0}代表的就是虚函数表里的第一个函数，vcall{4}就代表虚函数表里的第二个虚函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243class A&#123;public: void myfunc1(int tempvalue1) &#123; cout &lt;&lt; &quot;tempvalue1 = &quot; &lt;&lt; tempvalue1 &lt;&lt; endl; &#125; void myfunc2(int tempvalue2) &#123; cout &lt;&lt; &quot;tempvalue2 = &quot; &lt;&lt; tempvalue2 &lt;&lt; endl; &#125; static void mysfunc(int tempvalue) &#123; cout &lt;&lt; &quot;A::mysfunc()静态成员函数--tempvalue = &quot; &lt;&lt; tempvalue &lt;&lt; endl; &#125; virtual void myvirfuncPrev(int tempvalue) &#123; cout &lt;&lt; &quot;A::myvirfuncPrev()虚成员函数--tempvalue = &quot; &lt;&lt; tempvalue &lt;&lt; endl; &#125; virtual void myvirfunc(int tempvalue) &#123; cout &lt;&lt; &quot;A::myvirfunc()虚成员函数--tempvalue = &quot; &lt;&lt; tempvalue &lt;&lt; endl; &#125;&#125;; void func()&#123; void (A::*pmyvirfunc)(int tempvalue) = &amp;A::myvirfunc; //成员函数指针 -- vcall(vcall trunk)地址（虚函数） A *pvaobj = new A; pvaobj-&gt;myvirfunc(190); (pvaobj-&gt;*pmyvirfunc)(190); printf(&quot;%p\n&quot;, &amp;A::myvirfunc); pmyvirfunc = &amp;A::myfunc2; //真正的成员函数地址 (pvaobj-&gt;*pmyvirfunc)(33); delete pvaobj; &#125; 完善理解：&amp;A::myvirfunc,打印出来的是一个地址，这个地址中有一段代码，这个代码中记录的是该虚函数在虚函数表中的一个偏移值，有了这个偏移值，再有了具体的对象指针，我们就能够知道调用的是哪个虚函数表里边的哪个虚函数了。 成员函数指针里，保存的可能是一个vcall(vcall trunk)地址（如果指针指向的是虚函数）,要么也可能是一个真正的成员函数地址（指针指向的不是虚函数）。如果是一个vcall地址，那vcall能够引导编译器找出正确的虚函数表中的虚函数地址进行调用。 七、inline函数介绍及其扩展细节inline函数介绍 使用inline之后，编译器内部会有一个比较复杂的测试算法来评估这个inline函数的复杂度,可能会统计这个inline函数中，赋值次数，内部函数调用，虚函数调用等次数（权重）。 （1）开发者写inline只是对编译器的一个建议，但如果编译器评估这个inline函数复杂度过高，这个inline建议就被编译器忽略。 （2）如果inline被编译器采纳，那么inline函数的扩展，就要在调用这个inline函数的那个点上进行，此时可能带来额外的问题比如：参数求值，可能导致临时对象的生成和管理。 inline扩展细节 见代码的注释部分： 12345678910111213141516inline int myfunc(int testv)&#123; return testv * (5 + 4) * testv;&#125;void func()&#123; int i = myfunc(12 + 15); //编译器会先求值，然后用实参再替换形参 int a = 80; int i = myfunc(a + 15); //编译器会先计算a和15的和值，然后再替换掉形参&#125;int main()&#123; _nmsp1::func(); return 1;&#125;]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>C++对象模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL源码剖析（4）]]></title>
    <url>%2F2019%2F08%2F10%2FSTL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89%2F</url>
    <content type="text"><![CDATA[写在前面的话 前一篇博文介绍了序列式容器，接下来介绍关联式容器。 概览 所谓关联式容器，即每个元素都有一个键值（key）和一个实值（value）。当元素被插入到关联式容器中时，容器的内部结构便按照其键值大小，以某种特定规则将这个元素放置于适当位置。关联式容器没有头尾（只有最大元素和最小元素），所以不会有push_back(), push_front(), pop_back(), pop_front(), begin(), end()这些操作行为。 STL中的关联式容器分为set和map两大类，以及这两大类的衍生体multiset和multimap。这些容器的底层实现机制都是红黑树。红黑树也是一个独立的容器，但是并不开放给外界使用。此外，SGI STL还提供了一个不在标准规格之列的关联式容器：hashtable,以及以hashtable为底层机制的hash_set,hash_map,hash_multiset,hash_multimap。 set （1）set里面元素的键值就是实值，实值就是键值，所有元素都会根据元素的键值自动被排序，并且set不允许两个元素有相同的键值。 （2）我们不能通过set的迭代器改变set的元素值，因为set的元素值就是其键值，关系到set元素的排列规则，如果任意改变set的元素值，会破坏set组织。因此，set::iterator 被定义为const_iterator，杜绝写入操作。 （3）set拥有与list相同的某些性质：当用户对它进行元素新增或删除操作时，操作之前的所有迭代器（除了被删除元素的迭代器）在操作之后都依然有效。 （4）set是以红黑树为底层机制，因为红黑树是一种平衡二叉搜索树，自动排序效果不错。而且对于set所开放的各种接口操作，红黑树也都提供了，所以几乎所有的set操作行为，都只是调用红黑树的操作行为而已。 map （1）map的所有元素都是pair，同时拥有实值（value）和键值（key）。pair的第一元素被视为键值，第二元素被视为实值。它的所有元素都会根据元素的键值自动被排序，并且map不允许两个元素拥有相同的键值。 （2）我们不能通过map的迭代器改变map里元素的键值，因为键值关系到map元素的排列规则，任意改变map元素键值将会严重破坏map组织，但是可以改变元素的实值，因为map元素的实值并不影响map元素的排列规则。 （3）map拥有与list相同的某些性质：当用户对它进行元素新增或删除操作时，操作之前的所有迭代器（除了被删除元素的迭代器）在操作之后都依然有效。 （4）map也是以红黑树为底层机制，因为红黑树是一种平衡二叉搜索树，自动排序效果不错。而且对于map所开放的各种接口操作，红黑树也都提供了，所以几乎所有的map操作行为，都只是调用红黑树的操作行为而已。 multiset和multimap （1）multiset的特性以及用法和set完全相同，唯一的差别在于它允许键值重复，因此它的插入操作采用的是底层机制红黑树的insert_equal()而非insert_unique()。 （2）multimap的特性以及用法和map完全相同，唯一的差别在于它允许键值重复，因此它的插入操作采用的是底层机制红黑树的insert_equal()而非insert_unique()。 hash_set （1）hash_set以hashtable为底层机制，由于hash_set所提供的操作接口，hashtable都提供了，所以几乎所有的hash_set操作行为都只是转调用hashtable的操作行为而已。 （2）红黑树有自动排序功能，而hashtable没有，反映到表层就是，set的元素有自动排序功能而hash_set没有。 （3）hash_set跟set一样，元素的键值就是实值，实值就是键值。 hash_map （1）hash_map也是以hashtable为底层机制，由于hash_map所提供的操作接口，hashtable都提供了，所以几乎所有的hash_map操作行为都只是转调用hashtable的操作行为而已。 （2）红黑树有自动排序功能，而hashtable没有，反映到表层就是，map的元素有自动排序功能而hash_map没有。 （3）hash_map跟map一样，每一个元素同时拥有一个实值和一个键值。 hash_multiset和hash_multimap （1）hash_multiset的特性与multiset完全相同，唯一差别就在于它的底层机制是hashtable。因此，hash_multiset的元素不会自动排序。 （2）hash_multiset和hash_set实现上的唯一差别在于，前者的元素插入操作采用底层机制hashtable的insert_equal(),后者则是采用insert_unique()。 （3）hash_multimap的特性与multimap完全相同，唯一差别就在于它的底层机制是hashtable。因此，hash_multimap的元素不会自动排序。 （4）hash_multimap和hash_map实现上的唯一差别在于，前者的元素插入操作采用底层机制hashtable的insert_equal(),后者则是采用insert_unique()。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型（3） -- 数据语义学]]></title>
    <url>%2F2019%2F08%2F09%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%EF%BC%883%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、数据成员绑定时机12345678910111213typedef string mytype;//定义一个类class A&#123;public: void myfunc(mytype tmpvalue) //mytype = string &#123; m_value = tmpvalue; //出错，是把一个string类型给一个整型 &#125; typedef int mytype;private: mytype m_value; //int &#125;; （1）编译器对成员函数的解析，是整个类定义完毕后才开始的。因为只有整个类定义完毕后，编译器才能看到类中的成员变量，才能根据实际的需要把出现该成员变量的场合做适当的解释（成员函数中解析成类中的变量类型，全局函数中解析成全局的变量类型）。 （2）对于成员函数参数，是在编译器第一次遇到整个类型mytype的时候被决定的。所以，mytype第一次遇到的时候，编译器只看到了typedef string mytype，没有看到类中的typedef int mytype。 （3）为了在类中尽早的看到类型mytype，所以这种类型定义语句typedef，一定要挪到类的最开头定义。（即上述代码中应该把typedef int mytype移到class A的开头处）当后边的成员函数第一次遇到这个类型mytype的时候，它就本着最近碰到的类型的原则来应用最近碰到的类型。 二、进程内存空间布局 不同的数据在内存中会有不同的保存时机，保存位置。当运行一个可执行文件时，操作系统就会把这个可执行文件加载到内存，此时进程有一个虚拟的地址空间（内存空间），分为：堆栈段、数据段、代码段等。从下面代码中可以看出些许规律。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int *ptest = new int(120);int g1;int g2;int g3 = 12;int g4 = 32;int g5;int g6 = 0;static int g7;static int g8=0;static int g9 = 10;void mygfunc()&#123; return;&#125;//定义一个类class MYACLS&#123;public: int m_i; static int m_si; //声明不是定义 int m_j; static int m_sj; int m_k; static int m_sk; //static void myclsfunc() &#123;&#125;&#125;;int MYACLS::m_sj = 0; //这才是定义；int main()&#123; int i = 7;; printf(&quot;i地址=%p\n&quot;, &amp;i); //i地址=00AFFB94 printf(&quot;ptest地址=%p\n&quot;, &amp;ptest); //ptest地址=00F9B300 printf(&quot;g1地址=%p\n&quot;, &amp;g1); //g1地址=00F9B2EC printf(&quot;g2地址=%p\n&quot;, &amp;g2); //g2地址=00F9B2F0 printf(&quot;g3地址=%p\n&quot;, &amp;g3); //g3地址=00F9B000 printf(&quot;g4地址=%p\n&quot;, &amp;g4); //g4地址=00F9B004 printf(&quot;g5地址=%p\n&quot;, &amp;g5); //g5地址=00F9B2F4 printf(&quot;g6地址=%p\n&quot;, &amp;g6); //g6地址=00F9B2F8 printf(&quot;g7地址=%p\n&quot;, &amp;g7); //g7地址=00F9B304 printf(&quot;g8地址=%p\n&quot;, &amp;g8); //g8地址=00F9B308 printf(&quot;g9地址=%p\n&quot;, &amp;g9); //g9地址=00F9B008 printf(&quot;MYACLS::m_sj地址=%p\n&quot;, &amp;(MYACLS::m_sj)); //MYACLS::m_sj地址=00F9B2FC printf(&quot;mygfunc()地址=%p\n&quot;, mygfunc); //mygfunc()地址=00F91433 printf(&quot;main()地址=%p\n&quot;, main); //main()地址=00F9132A cout &lt;&lt; (void*)mygfunc &lt;&lt; endl; //00F91433 return 1;&#125; 从上述代码的打印结果来看，不同类型的数据在内存中的存储位置是不同的，同一类型的数据是连续存储的。 三、类中成员变量的布局 （1）普通成员变量的存储顺序是按照在类中的定义顺序从上到下来的。比较晚出现的成员变量在内存中有更高的地址。类定义中pubic,private,protected的数量，不影响类对象的sizeof。 （2）某些因素会导致成员变量之间排列不连续，就是边界调整（字节对齐），调整的目的是提高效率，编译器自动调整。调整方式：往成员之间填补一些字节，使用类对象的sizoef字节数凑成一个4的整数倍，8的整数倍。 （3）为了统一字节对齐问题，引入一个概念叫一字节对齐(不对齐)：#pragma pack(1)。把这个语句放到程序最开始处即可。 （4）有虚函数时，编译器往类定义中增加vptr虚函数表指针（内部的数据成员）。 （5）成员变量偏移值，就是这个成员变量的地址，离对象首地址偏移多少。 四、类中成员变量的存取 （1）静态成员变量，可以当做一个全局量，但是它只在类的空间内可见。引用时用类名::静态成员变量名。静态成员变量只有一个实体，保存在可执行文件的数据段。 （2）非静态成员变量（普通的成员变量）存放在类的对象中。存取通过类对象（类对象指针）来操作。例如：对于普通成员的访问，编译器是把类对象的首地址加上成员变量的偏移值。 五、单一继承下的数据成员布局 （1）一个子类对象，所包含的内容，是他自己的成员，加上他父类的成员的总和。从偏移值看，父类成员先出现，然后才是孩子类成员。 （2）引入继承关系后，可能会带来内存空间的额外增加（字节对齐）。所以不能用memcpy内存拷贝把父类对象的内容直接往子类对象里拷贝。 六、带有虚函数的类中数据成员布局单个类带虚函数的数据成员布局 类中引入虚函数时，会有额外的成本付出： 1)编译的时候，编译器会产生虚函数表。 2)对象中会产生虚函数表指针vptr，用以指向虚函数表。 3)增加或者扩展构造函数，增加给虚函数表指针vptr赋值的代码，让vptr指向虚函数表。 4)如果多重继承，比如你继承了2个父类，每个父类都有虚函数的话，每个父类都会有vptr，那继承时，子类就会把这两根vptr都继承过来，如果子类还有自己额外的虚函数的话，子类与第一个基类共用一个vptr。 5)析构函数中也被扩展增加了虚函数表指针vptr相关的赋值代码，这个赋值代码似乎和构造函数中代码相同。 单一继承父类带虚函数的数据成员布局 代码如下： 1234567891011121314151617181920212223242526272829303132333435class Base&#123;public: int m_bi; virtual void mybvirfunc() &#123;&#125;&#125;;class MYACLS :public Base&#123;public: int m_i; int m_j; MYACLS() &#123; int abc = 1; //方便加断点 &#125; ~MYACLS() &#123; int def = 0;//方便加断点 &#125;&#125;;int main()&#123; cout &lt;&lt; sizeof(MYACLS) &lt;&lt; endl; //16 printf(&quot;MYACLS::m_bi = %d\n&quot;, &amp;MYACLS::m_bi); //MYACLS::m_bi = 4 printf(&quot;MYACLS::m_i = %d\n&quot;, &amp;MYACLS::m_i); //MYACLS::m_i = 8 printf(&quot;MYACLS::m_j = %d\n&quot;, &amp;MYACLS::m_j); //MYACLS::m_j = 12 MYACLS myobj; myobj.m_i = 3; myobj.m_j = 6; myobj.m_bi = 9; return 1;&#125; 从打印结果可以看出，当父类中有虚函数的时候，指向父类虚函数表的虚函数表指针会占用内存开头的四个字节，紧接着是父类的成员变量，最后才是子类的成员变量。 单一继承父类不带虚函数的数据成员布局12345678910111213141516171819202122232425262728293031323334class Base&#123;public: int m_bi;&#125;;class MYACLS :public Base&#123;public: int m_i; int m_j; MYACLS() &#123; int abc = 1; //方便加断点 &#125; ~MYACLS() &#123; int def = 0;//方便加断点 &#125;&#125;;int main()&#123; cout &lt;&lt; sizeof(MYACLS) &lt;&lt; endl; //12 printf(&quot;MYACLS::m_bi = %d\n&quot;, &amp;MYACLS::m_bi); //MYACLS::m_bi = 0 printf(&quot;MYACLS::m_i = %d\n&quot;, &amp;MYACLS::m_i); //MYACLS::m_i = 4 printf(&quot;MYACLS::m_j = %d\n&quot;, &amp;MYACLS::m_j); //MYACLS::m_j = 8 MYACLS myobj; myobj.m_i = 3; myobj.m_j = 6; myobj.m_bi = 9; return 1;&#125; 从打印结果可以看出，如果父类中没有虚函数，则父类的成员变量就放到了内存开头处，之后是子类的成员变量。 但是如果子类中有虚函数而父类中没有，内存布局又会发生变化，即数据在内存空间中的分布分别是：父类成员、子类的虚函数表指针、子类成员。代码及打印结果如下： 1234567891011121314151617181920212223242526272829303132333435class Base&#123;public: int m_bi;&#125;;class MYACLS :public Base&#123;public: int m_i; int m_j; virtual void myvirfunc() &#123;&#125; MYACLS() &#123; int abc = 1; //方便加断点 &#125; ~MYACLS() &#123; int def = 0;//方便加断点 &#125;&#125;;int main()&#123; cout &lt;&lt; sizeof(MYACLS) &lt;&lt; endl; //16 printf(&quot;MYACLS::m_bi = %d\n&quot;, &amp;MYACLS::m_bi); //MYACLS::m_bi = 0 printf(&quot;MYACLS::m_i = %d\n&quot;, &amp;MYACLS::m_i); //MYACLS::m_i = 8 printf(&quot;MYACLS::m_j = %d\n&quot;, &amp;MYACLS::m_j); //MYACLS::m_j = 12 MYACLS myobj; myobj.m_i = 3; myobj.m_j = 6; myobj.m_bi = 9; return 1;&#125; 如果子类和父类中都有虚函数，则子类和父类共用一个虚函数表指针，即它俩的地址一样，都在内存的开头处，代码如下： 123456789101112131415161718192021222324252627282930313233343536class Base&#123;public: int m_bi; virtual void mybvirfunc() &#123;&#125;&#125;;class MYACLS :public Base&#123;public: int m_i; int m_j; virtual void myvirfunc() &#123;&#125; MYACLS() &#123; int abc = 1; //方便加断点 &#125; ~MYACLS() &#123; int def = 0;//方便加断点 &#125;&#125;;int main()&#123; cout &lt;&lt; sizeof(MYACLS) &lt;&lt; endl; //16 printf(&quot;MYACLS::m_bi = %d\n&quot;, &amp;MYACLS::m_bi); //MYACLS::m_bi = 4 printf(&quot;MYACLS::m_i = %d\n&quot;, &amp;MYACLS::m_i); //MYACLS::m_i = 8 printf(&quot;MYACLS::m_j = %d\n&quot;, &amp;MYACLS::m_j); //MYACLS::m_j = 12 MYACLS myobj; myobj.m_i = 3; myobj.m_j = 6; myobj.m_bi = 9; return 1;&#125; 总结：不管是父类还是子类，只要含有虚函数，则虚函数指针就位于对应的所有数据成员的前面（父类指针对应父类成员，子类指针对应子类成员），如果父类和子类都含有虚函数，则它俩的虚函数表指针共用一块内存，位于内存空间的开头处。 多重继承且父类都带虚函数的数据成员布局1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class Base1&#123;public: int m_bi; virtual void mybvirfunc() &#123;&#125; Base1() &#123; printf(&quot;Base1::Base1()的this指针是：%p!\n&quot;, this); &#125;&#125;;class Base2&#123;public: int m_b2i; virtual void mybvirfunc2() &#123;&#125; Base2() &#123; printf(&quot;Base2::Base2()的this指针是：%p!\n&quot;, this); &#125;&#125;;class MYACLS :public Base1,public Base2&#123;public: int m_i; int m_j; virtual void myvirfunc() &#123;&#125; //虚函数 MYACLS() &#123; int abc = 1; //方便加断点 printf(&quot;MYACLS::MYACLS()的this指针是：%p!\n&quot;, this); &#125; ~MYACLS() &#123; int def = 0;//方便加断点 &#125;&#125;;int main()&#123; cout &lt;&lt; sizeof(MYACLS) &lt;&lt; endl; //24 printf(&quot;MYACLS::m_bi = %d\n&quot;, &amp;MYACLS::m_bi); //MYACLS::m_bi = 4 printf(&quot;MYACLS::m_b2i = %d\n&quot;, &amp;MYACLS::m_b2i); //MYACLS::m_b2i = 4 printf(&quot;MYACLS::m_i = %d\n&quot;, &amp;MYACLS::m_i); //MYACLS::m_i = 16 printf(&quot;MYACLS::m_j = %d\n&quot;, &amp;MYACLS::m_j); //MYACLS::m_j = 20 MYACLS myobj; //Base1::Base1()的this指针是：004FFC24! //Base2::Base2()的this指针是：004FFC2C! //MYACLS::MYACLS()的this指针是：004FFC24! myobj.m_i = 3; myobj.m_j = 6; myobj.m_bi = 9; myobj.m_b2i = 12; MYACLS *pmyobj = new MYACLS(); //Base1::Base1()的this指针是：008F11D8! //Base2::Base2()的this指针是：008F11E0! //MYACLS::MYACLS()的this指针是：008F11D8! pmyobj-&gt;m_i = 3; pmyobj-&gt;m_j = 6; pmyobj-&gt;m_bi = 9; pmyobj-&gt;m_b2i = 12; return 1;&#125; （1）通过this指针打印，我们看到访问Base1成员不用跳 ，访问Base2成员要this指针要偏移（跳过）8字节。 （2）我们看到偏移值，m_bi和m_b2i偏移都是4。 （3）this指针，加上偏移值就的能够访问对应的成员变量，比如m_b2i = this指针+偏移值。 结论：我们要访问一个类对象中的成员，成员的定位是通过：this指针（编译器会自动调整）以及该成员的偏移值，这两个因素来定义。这种this指针偏移的调整都需要编译器介入来处理完成。 虚基类相关1234567891011121314151617181920212223242526272829class Grand //爷爷类&#123;public:&#125;;class A1 : virtual public Grand&#123;public:&#125;;class A2 : virtual public Grand&#123;public:&#125;;class C1 :public A1, public A2&#123;public: int m_c1;&#125;;int main()&#123; cout &lt;&lt; sizeof(Grand) &lt;&lt; endl; // 1 cout &lt;&lt; sizeof(A1) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(A2) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(C1) &lt;&lt; endl; // 12 return 1;&#125; （1）虚基类就是让Grand类只被继承一次，防止二义性问题。 （2）有虚基类，就有虚基类表vbtable(virtual base table)、虚基类表指针vbptr(virtual base table pointer)。 （3）空类sizeof(Grand)=1好理解。虚继承之后，A1,A2里就会被编译器插入一个虚基类表指针，这个指针，有点成员变量的感觉。A1,A2里因为有了虚基类表指针，因此占用了4个字节。 1234567891011121314151617181920212223242526272829303132333435363738class Grand //爷爷类&#123;public: int m_grand;&#125;;class A1 : virtual public Grand&#123;public: int m_a1;&#125;;class A2 : virtual public Grand&#123;public: int m_a2;&#125;;class C1 :public A1, public A2&#123;public: int m_c1;&#125;;int main()&#123; cout &lt;&lt; sizeof(Grand) &lt;&lt; endl; // 1 cout &lt;&lt; sizeof(A1) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(A2) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(C1) &lt;&lt; endl; // 12 //内存分布情况 C1 c; c.m_grand = 2; // 21-24字节 c.m_a1 = 3; // 5-8字节 c.m_a2 = 4; // 13-16字节 c.m_c1 = 5; // 17-20字节 return 1;&#125; 根据内存分析可以看出：1-4字节和9-12字节应该存放的就是两个虚基类表指针，其中1-4字节是vbptr1（继承自A1），9-12字节是vbptr2（继承自A2）。其余的数据分布如上述程序中所示，需要注意的是：爷爷类里的成员分布在内存的最后。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Grand //爷爷类&#123;public: int m_grand;&#125;;class Grand2 //爷爷类&#123;public: int m_grand2;&#125;;class A1 : virtual public Grand,virtual public Grand2&#123;public: int m_a1;&#125;;class A2 : virtual public Grand&#123;public: int m_a2;&#125;;class C1 :public A1, public A2&#123;public: int m_c1;&#125;;int main()&#123; cout &lt;&lt; sizeof(Grand) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(A1) &lt;&lt; endl; // 16（3个int数据+1个虚基类表指针） cout &lt;&lt; sizeof(A2) &lt;&lt; endl; // 12（2个int数据+1个虚基类表指针） cout &lt;&lt; sizeof(C1) &lt;&lt; endl; // 28 //内存分布情况 C1 c; c.m_a1 = 1; // 5-8字节 c.m_a2 = 2; // 13-16字节 c.m_c1 = 3; // 17-20字节 c.m_grand = 4; // 21-24字节 c.m_grand2 = 5; // 25-28字节 return 1;&#125; 由此，可以判断出，一个类同时虚继承多个父类，只会产生一个虚基类指针（A1）。1-4字节放的是A1的虚基类指针，9-12字节放的是A2的虚基类指针。其他的数据分布如程序所示。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>C++对象模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型（2） -- 虚函数]]></title>
    <url>%2F2019%2F08%2F06%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%EF%BC%882)%2F</url>
    <content type="text"><![CDATA[一、虚函数表指针位置分析 一个类若有虚函数，这个类就会产生一个虚函数表。当类创建对象的时候，对象内就会维护一个虚函数表指针，该指针(vptr)会指向这个虚函数表的开始地址。接下来借助代码分析一下虚函数表指针的位置。 12345678910111213141516171819202122232425class A&#123;public: int i; //4字节 virtual void testfunc() &#123;&#125; //虚函数，vptr4字节。&#125;;int main()&#123; A aobj; int ilen = sizeof(aobj); cout &lt;&lt; ilen &lt;&lt; endl; //8字节 char *p1 = reinterpret_cast&lt;char *&gt;(&amp;aobj); //类型转换，硬转 &amp;aobj这是对象aobj的首地址。 char *p2 = reinterpret_cast&lt;char *&gt;(&amp;(aobj.i)); if (p1 == p2) //说明aobj.i和aobj的位置相同，说明i在对象aobj内存布局的上边。虚函数表指针vptr在下边 &#123; cout &lt;&lt; &quot;虚函数表指针位于对象内存的末尾&quot; &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; &quot;虚函数表指针位于对象内存的开头&quot; &lt;&lt; endl; &#125; return 1; &#125; 通过测试，我们发现虚函数表指针在对象内存的开头处。 二、继承关系作用下虚函数的手工调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475//父类class Base&#123;public: virtual void f() &#123; cout &lt;&lt; &quot;Base::f()&quot; &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; &quot;Base::g()&quot; &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; &quot;Base::h()&quot; &lt;&lt; endl; &#125;&#125;;class Derive :public Base &#123; virtual void g() &#123; cout &lt;&lt; &quot;Derive::g()&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; // cout &lt;&lt; sizeof(Base) &lt;&lt; endl; cout &lt;&lt; sizeof(Derive) &lt;&lt; endl; Derive *d = new Derive(); //派生类指针。 long *pvptr = (long *)d; //指向对象的指针d转成了long *类型。 long *vptr = (long *)(*pvptr); //(*pvptr)表示pvptr指向的对象，也就是Derive本身。Derive对象是4字节的，代表的是虚函数表指针地址。 for (int i = 0; i &lt;= 4; i++) //循环5次，打印出虚函数的地址。 &#123; printf(&quot;vptr[%d] = 0x:%p\n&quot;, i, vptr[i]); &#125; //上述循环运行结果： //vptr[0] = 0x:00DF11A4 //vptr[1] = 0x:00DF1320 //vptr[2] = 0x:00DF1334 //vptr[3] = 0x:00000000 //vptr[4] = 0x:69726544 typedef void(*Func)(void); //定义一个函数指针类型 Func f = (Func)vptr[0]; //f就是函数指针变量，vptr[0]是指向第一个虚函数的。 Func g = (Func)vptr[1]; Func h = (Func)vptr[2]; /*Func i = (Func)vptr[3]; Func j = (Func)vptr[4];*/ f(); //Base::f() g(); //Derive::g() h(); //Base::h() //i(); Base *dpar = new Base(); //父类指针 long *pvptrpar = (long *)dpar; long *vptrpar = (long *)(*pvptrpar); for (int i = 0; i &lt;= 4; i++) //循环5次； &#123; printf(&quot;vptr Base[%d] = 0x:%p\n&quot;, i, vptrpar[i]); &#125; //上述循环运行结果： //vptr Base[0] = 0x:00DF11A4 //vptr Base[1] = 0x:00DF117C //vptr Base[2] = 0x:00DF1334 //vptr Base[3] = 0x:00000000 //vptr Base[4] = 0x:65736142 Func fpar = (Func)vptrpar[0]; Func gpar = (Func)vptrpar[1]; Func hpar = (Func)vptrpar[2]; cout &lt;&lt; &quot;--------------------&quot; &lt;&lt; endl; fpar(); //Base::f() gpar(); //Base::g() hpar(); //Base::h() return 1; &#125; 从上面的运行结果来看（注释中已标出），对于子类对象来说，子类中要是有和父类同名的虚函数，则子类中的虚函数就会把父类中的同名虚函数覆盖，同时虚函数表中对应的虚函数地址必然会发生变化（变成子类中虚函数的地址）。但是如果是父类对象，则还是会调用父类中的虚函数（即不会被覆盖）。 接着看下面的代码： 1234567891011121314151617181920212223242526typedef void(*Func)(void); //定义一个函数指针类型Derive derive;long *pvptrderive = (long *)(&amp;derive); long *vptrderive = (long *)(*pvptrderive); //0x00b09b6c &#123;project100.exe!void(* Derive::`vftable&apos;[4])()&#125; &#123;11538847&#125;Func f1 = (Func)vptrderive[0]; //0x00b0119f &#123;project100.exe!Base::f(void)&#125;Func f2 = (Func)vptrderive[1]; //0x00b0150f &#123;project100.exe!Derive::g(void)&#125;Func f3 = (Func)vptrderive[2]; //0x00b01325 &#123;project100.exe!Base::h(void)&#125;Func f4 = (Func)vptrderive[3]; //0x69726544Func f5 = (Func)vptrderive[4]; //0x3a3a6576Derive derive2 = derive; //调用拷贝构造函数long *pvptrderive2 = (long *)(&amp;derive2);long *vptrderive2 = (long *)(*pvptrderive2);Base base = derive; //直接用子类对象给父类对象值，子类中的属于父类那部分内容会被编译器自动区分（切割）出来并拷贝给了父类对象。 //所以Base base = derive;实际干了两个事情： //第一个事情：生成一个base对象 //第二个事情：用derive来初始化base对象的值。long *pvptrbase = (long *)(&amp;base);long *vptrbase = (long *)(*pvptrbase); //0x00b09b34 &#123;project100.exe!void(* Base::`vftable&apos;[4])()&#125; &#123;11538847&#125;Func fb1 = (Func)vptrbase[0]; //0x00b0119f &#123;project100.exe!Base::f(void)&#125;Func fb2 = (Func)vptrbase[1]; //0x00b01177 &#123;project100.exe!Base::g(void)&#125;Func fb3 = (Func)vptrbase[2]; //0x00b01325 &#123;project100.exe!Base::h(void)&#125;Func fb4 = (Func)vptrbase[3]; //0x00000000Func fb5 = (Func)vptrbase[4]; //0x65736142 可以看出，当用子类对象初始化父类对象的时候，编译器给咱们做了一个选择，显然derive的虚函数表指针值并没有覆盖base对象的虚函数表指针值。 总结： （1）一个类只有包含虚函数才会存在虚函数表，同属于一个类的对象共享虚函数表，但是有各自的vptr（虚函数表指针），当然所指向的地址（虚函数表首地址）相同。 （2）父类中有虚函数就等于子类中有虚函数。话句话来说，父类中有虚函数表，则子类中肯定有虚函数表。因为你是继承父类的。并且只要在父类中是虚函数，那么子类中即便不写virtual，也依旧是虚函数。但如果子类只继承自一个父类，则不管是父类还是子类，它们内部都只会有一个虚函数表。 （3）如果子类中完全没有新的虚函数，则我们可以认为子类的虚函数表和父类的虚函数表内容相同。但，仅仅是内容相同，这两个虚函数表在内存中处于不同位置，换句话来说，这是内容相同的两张表。 （4）虚函数表中每一项，保存着一个虚函数的首地址，但如果子类的虚函数表某项和父类的虚函数表某项代表同一个函数（这表示子类没有覆盖父类的虚函数），则该表项所执行的该函数的地址应该相同。 （5）超出虚函数表部分的内容不可知。 三、多重继承虚函数表分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109//基类1class Base1&#123;public: virtual void f() &#123; cout &lt;&lt; &quot;base1::f()&quot; &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; &quot;base1::g()&quot; &lt;&lt; endl; &#125;&#125;;//基类2class Base2&#123;public: virtual void h() &#123; cout &lt;&lt; &quot;base2::h()&quot; &lt;&lt; endl; &#125; virtual void i() &#123; cout &lt;&lt; &quot;base2::i()&quot; &lt;&lt; endl; &#125;&#125;;//子类class Derived :public Base1, public Base2&#123;public: virtual void f() //覆盖父类1的虚函数 &#123; cout &lt;&lt; &quot;derived::f()&quot; &lt;&lt; endl; &#125; virtual void i() //覆盖父类2的虚函数 &#123; cout &lt;&lt; &quot;derived::i()&quot; &lt;&lt; endl; &#125; //如下三个我们自己的虚函数 virtual void mh() &#123; cout &lt;&lt; &quot;derived::mh()&quot; &lt;&lt; endl; &#125; virtual void mi() &#123; cout &lt;&lt; &quot;derived::mi()&quot; &lt;&lt; endl; &#125; virtual void mj() &#123; cout &lt;&lt; &quot;derived::mj()&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; cout &lt;&lt; sizeof(Base1) &lt;&lt; endl; cout &lt;&lt; sizeof(Base2) &lt;&lt; endl; cout &lt;&lt; sizeof(Derived) &lt;&lt; endl; Derived ins; Base1 &amp;b1 = ins; //多态 Base2 &amp;b2 = ins; Derived &amp;d = ins; typedef void(*Func)(void); long *pderived1 = (long *)(&amp;ins); long *vptr1 = (long *)(*pderived1); //取第一个虚函数表指针。 long *pderived2 = pderived1 + 1; //跳过4字。 long *vptr2 = (long *)(*pderived2); //取第二个虚函数表指针。 Func f1 = (Func)vptr1[0]; //0x00ab15d7 &#123;project100.exe!Derived::f(void)&#125; Func f2 = (Func)vptr1[1]; //0x00ab15f0 &#123;project100.exe!Base1::g(void)&#125; Func f3 = (Func)vptr1[2]; //0x00ab15cd &#123;project100.exe!Derived::mh(void)&#125; Func f4 = (Func)vptr1[3]; //0x00ab15ff &#123;project100.exe!Derived::mi(void)&#125; Func f5 = (Func)vptr1[4]; //0x00ab15eb &#123;project100.exe!Derived::mj(void)&#125; Func f6 = (Func)vptr1[5]; //非正常 Func f7 = (Func)vptr1[6]; Func f8 = (Func)vptr1[7]; Func f11 = (Func)vptr2[0]; //0x00ab15af &#123;project100.exe!Base2::h(void)&#125; Func f22 = (Func)vptr2[1]; //0x00ab15b9 &#123;project100.exe!Derived::i(void)&#125; Func f33 = (Func)vptr2[2]; //非正常 Func f44 = (Func)vptr2[3]; b1.f(); b2.i(); d.f(); d.i(); d.mh(); d.g(); cout &lt;&lt; &quot;-----------------&quot; &lt;&lt; endl; f1(); f2(); f3(); f4(); f5(); cout &lt;&lt; &quot;-------------&quot; &lt;&lt; endl; f11(); f22(); return 1; &#125; （1）一个对象，如果它的类有多个基类则有多个虚函数表指针（注意是多个虚函数表指针，而不是多个虚函数表）。 （2）在多继承中，对应各个基类的vptr按继承顺序依次放置在类的内存空间中，且子类与第一个基类共用一个vptr(第二个基类有自己的vptr); （3）如上程序中，子类对象ins有两个虚函数表指针，vptr1,vptr2。类Derived有两个虚函数表，因为它继承自两个基类。 （4）子类和第一个基类公用一个vptr（因为vptr指向一个虚函数表，所以也可以说子类和第一个基类共用一个虚函数表vtbl),因为我们注意到了类Derived的虚函数表1里边的5个函数，而g()正好是base1里边的函数。 （5）子类中的虚函数覆盖了父类中的同名虚函数。比如derived::f(),derived::i(); 四、vptr、vtbl创建时机 （1）vptr（虚函数表指针）跟着对象走，所以对象什么时候创建出来，vptr就什么时候创建出来。即运行的时候。实际上，对于这种有虚函数的类，在编译的时候，编译器会往相关的构造函数中增加为vptr赋值的代码，这是在编译期间编译器为构造函数增加的。当程序运行的时候，遇到创建对象的代码，执行对象的构造函数，那么这个构造函数里有给对象的vptr(成员变量)赋值的语句，自然这个对象的vptr就被赋值了。 （2）虚函数表是编译器在编译期间（不是运行期间）就为每个类确定好了对应的虚函数表vtbl的内容。然后也是在编译期间在相应的类构造函数中添加给vptr赋值的代码，这样程序运行的时候，当运行到创建类对象的代码时，会调用类的构造函数，执行到类的构造函数中的给vptr赋值的代码，这样这个类对象的vptr(虚函数表指针)就有值了。 五、普通类包含虚函数时引发的虚函数调用问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class X&#123;public: int x; int y; int z; //X() :x(0), y(0), z(0) X() &#123; //编译器角度 伪码； //vptr = vtbl; //下边的memset会把vptr（虚函数表指针）清0 memset(this, 0, sizeof(X)); cout &lt;&lt; &quot;构造函数被执行&quot; &lt;&lt; endl; &#125; //X(const X &amp;tm) :x(tm.x), y(tm.y), z(tm.z) X(const X &amp;tm) &#123; memcpy(this, &amp;tm, sizeof(X)); cout &lt;&lt; &quot;拷贝构造函数被执行&quot; &lt;&lt; endl; &#125; virtual ~X() &#123; cout &lt;&lt; &quot;析构函数被执行&quot; &lt;&lt; endl; &#125; virtual void virfunc() &#123; cout &lt;&lt; &quot;虚函数virfunc()被执行&quot; &lt;&lt; endl; &#125; void ptfunc() &#123; cout &lt;&lt; &quot;普通函数ptfunc()被执行&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; //X x0; //调用构造函数 ///*x0.x = 100; //x0.y = 200; //x0.z = 300;*/ //x0.virfunc(); //虚函数表指针为null居然可以成功调用虚函数； //X x1(x0); //调用拷贝构造函数 //cout &lt;&lt; &quot;x1.x=&quot; &lt;&lt; x1.x &lt;&lt; &quot; x1.y=&quot; &lt;&lt; x1.y &lt;&lt; &quot; x1.z=&quot; &lt;&lt; x1.z &lt;&lt; endl; //X *px0 = new X(); //px0-&gt;ptfunc(); //正常调用 //px0-&gt;virfunc(); //无法正常调用 //delete px0; //无法正常调用 //new出来的对象，虚函数变得无法正常执行了； int i = 9; printf(&quot;i的地址 = %p\n&quot;, &amp;i); X x0; printf(&quot;ptfunc()的地址=%p\n&quot;, &amp;X::ptfunc); //打印正常的成员函数地址。 //long *pvptrpar = (long *)(&amp;x0); //long *vptrpar = (long *)(*pvptrpar); //printf(&quot;virfunc的地址 = %p\n&quot;, vptrpar[1]);//虚函数virfunc地址 x0.ptfunc(); x0.virfunc(); //不叫多态，属于静态联编，我们推断：这个函数ptfunc()和virfunc()函数，是在编译的就确定好的； X *pX0 = new X(); pX0-&gt;ptfunc(); pX0-&gt;virfunc(); //通过虚函数表指针，找虚函数表，然后从虚函数表中找到virfunc虚函数的地址并调用。这就是多态 //更明白：虚函数，多态，这种概念专门给指针或者引用用的； X &amp;xy = *pX0; xy.virfunc(); X &amp;xy2 = x0; xy2.virfunc(); return 1;&#125; （1）如果一个普通类中包含了虚函数，那么在构造函数中使用如上所示的memset或者拷贝构造函数中使用如上所示的memcpy方法，那么就会出现程序崩溃的情形。 （2）某些情况下，编译器会往类内部增加一些我们看不见但真实存在的成员变量（隐藏成员变量），比如你类中增加了虚函数，系统默认往类对象中增加虚函数表指针，这个虚函数表指针就是隐藏的成员变量。有了这种变量的类，就不是普通的类了。同时，这种隐藏的成员变量的增加(使用)或者赋值的时机，往往都是在执行构造函数或者拷贝构造函数的函数体之前进行。那么你如果使用memset,memcpy，很可能把编译器给隐藏变量的值你就给清空了，要么覆盖了。 （3）静态联编是指：我们编译的时候就能确定调用哪个函数。把调用语句和被调用函数绑定到一起。动态联编是在程序运行时，根据时机情况，动态的把调用语句和被调用函数绑定到一起，动态联编一般旨有在多态和虚函数情况下才存在。 （4）对多态，虚函数，父类，子类。虚函数主要解决的问题父类指针指向子类对象这种情况。如果一个类中只有虚函数，没有继承，那么虚函数和普通函数没有区别，就算虚函数表指针被置空，仍然可通过对象正常调用，因为这是静态联编，不是多态。但是如果用new出来的对象调用，就会失败，因为虚函数表指针为空，找不到虚函数表。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>C++对象模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型（1） -- 对象]]></title>
    <url>%2F2019%2F08%2F04%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、类对象所占用的空间 （1）一个空类所占用空间是一个字节，如果有成员变量，就是成员变量占用的内存。为什么空类还要占一个字节的内存？这是因为创建了一个对象就要占用一个字节的地址，就像买房子一样，空房子也是占面积的。 （2）类的成员函数不占用类对象的内存空间，而成员变量占用对象的内存空间。 （3）成员变量是包含在每个对象中的，是占用对象字节的，有多少个对象就有多少个成员变量。而对于成员函数，每个类只诞生一个（跟着类走），而不管你用这个类产生了多少个该类的对象。 二、对象结构的发展和演化 （1）非静态的成员变量(普通成员变量)跟着类对象走（存在对象内部），也就是每个类对象都有自己的成员变量。 （2）静态成员变量跟对象没有什么关系，所以肯定不会保存在对象内部，是保存在对象外面（表示所占用的内存空间和类对象无关）的，所以不计算在类对象sizeof()内。 （3）成员函数：不管静态的还是非静态，全部都保存在类对象之外。所以不管几个成员函数，不管是否是静态的成员函数，对象的sizeof的大小都是不增加的。 （4）虚函数：不管有几个虚函数，sizeof()都是多了4个字节。类里只要有一个虚函数（或者说至少有一个虚函数），这个类就会产生一个指向虚函数的指针。有两个虚函数，那么这个类就会产生两个指向虚函数的指针。而类本身指向虚函数的指针（一个或者一堆）要有地方存放，存放在一个表格里，这个表格我们就称为“虚函数表(virtual table【vtbl】)”。这个虚函数表一般是保存在可执行文件中的，在程序执行的时候载入到内存中来。 （5）虚函数表是基于类的，跟着类走的。对于类对象，这四个字节的增加，其实是因为虚函数的存在；因为有了虚函数的存在，导致系统往类对象中添加了一个指针，这个指针正好指向这个虚函数表，很多资料上把这个指针叫vptr；这个vptr的值由系统在适当的时机赋值（比如构造函数中通过增加额外的代码来给值）。 （6）如果有多个数据成员，那么为了提高访问速度，某些编译器可能会将数据成员之间的内存占用比例进行调整(内存字节对齐)。 （7）不管什么类型指针char *p,int *q;,该指针占用的内存大小是固定的。 三、this指针调整：多重继承 （1）派生类对象是包含基类子对象的。 （2）如果派生类只从一个基类继承的话，那么这个派生类对象的地址和基类子对象的地址相同。 （3）如果派生类对象同时继承多个基类，那么就要注意：第一个基类子对象的开始地址和派生类对象的开始地址相同。后续这些基类子对象的开始地址和派生类对象的开始地址相差多少呢？那就得把前边那些基类子对象所占用的内存空间累加。 （4）调用哪个子类的成员函数，这个this指针就会被编译器自动调整到对象内存布局中对应该子类对象的起始地址那去。 四、构造函数语义 传统认识认为：如果我们自己没定义任何构造函数，那么编译器就会为我们隐式自动定义一个默认的构造函数，我们称这种构造函数为：“合成的默认构造函数”。 事实是：“合成的默认构造函数”，只有在必要的时候，编译器才会为我们合成出来，而不是必然或者必须为我们合成出来。那么编译器会在哪些必要的时候帮助我们把默认的构造函数合成出来呢？ （1）该类没有任何构造函数，但包含一个类类型的成员,而该对象所属于的类有一个缺省的构造函数。这个时候，编译器就会为该类生成一个 “合成默认的构造函数”，合成的目的是为了调用类类型成员所属类里的默认构造函数。 （2）父类带缺省构造函数，子类没有任何构造函数，那因为父类这个缺省的构造函数要被调用，所以编译器会为这个子类合成出一个默认构造函数。合成的目的是为了调用这个父类的构造函数。换句话说，编译器合成了默认的构造函数，并在其中安插代码，调用其父类的默认构造函数。 （3）如果一个类含有虚函数，但没有任何构造函数时，因为虚函数的存在，编译器会给我们生成一个基于该类的虚函数表vftable。此外编译器给我们合成了一个构造函数，调用了父类的构造函数，并且在其中安插代码，把类的虚函数表地址赋给类对象的虚函数表指针（赋值语句/代码）。我们可以把虚函数表指针看成是我们表面上看不见的一个类的成员函数。 （4）当我们有自己的默认构造函数时，编译器会根据需要扩充我们自己写的构造函数代码，比如调用父类构造函数，给对象的虚函数表指针赋值。 （5）如果一个类带有虚基类，编译器也会为它合成一个默认构造函数。虚基类：通过两个直接基类（虚基类）继承同一个间接基类。所以一般是三层 ，有爷爷Grand，有两个爹A,A2，有孙子C。有虚基类结构，编译器为子类和父类都产生了“合成的默认构造函数”。 五、拷贝构造函数语义 传统上，大家认为：如果我们没有定义一个自己的拷贝构造函数，编译器会帮助我们合成 一个拷贝构造函数。 事实上，这个合成的拷贝构造函数，也是在必要的时候才会被编译器合成出来。那编译器在什么情况下会帮助我们合成出拷贝构造函数来呢？这个编译器合成出来的拷贝构造函数又要干什么事情呢？ （1）如果一个类A没有拷贝构造函数，但是含有一个类类型CTB的成员变量m_ctb。该类型CTB含有拷贝构造函数，那么当代码中有涉及到类A的拷贝构造时，编译器就会为类A合成一个拷贝构造函数。编译器合成的拷贝构造函数往往都是干一些特殊的事情。如果只是一些类成员变量值的拷贝这些事，编译器是不用专门合成出拷贝构造函数来干的，编译器内部就干了，即成员变量初始化手法，比如int这种简单类型，直接就按值拷贝过去,编译器不需要合成拷贝构造函数的情况下就帮助我们把这个事情办了。再如类A中有类类型ASon成员变量asubobj，也会递归似的去拷贝类ASon的每个成员变量。 （2）如果一个类CTBSon没有拷贝构造函数，但是它有一个父类CTB，父类有拷贝构造函数，当代码中有涉及到类CTBSon的拷贝构造时，编译器会为CTBSon合成一个拷贝构造函数，调用父类的拷贝构造函数。 （3）如果一个类CTBSon没有拷贝构造函数，但是该类声明了或者继承了虚函数，当代码中有涉及到类CTBSon的拷贝构造时，编译器会为CTBSon合成一个拷贝构造函数 ,往这个拷贝构造函数里插入语句。这个语句的含义是设定类对象的虚函数表指针值。 （4）如果一个类没有拷贝构造函数，但是该类含有虚基类，当代码中有涉及到类的拷贝构造时，编译器会为该类合成一个拷贝构造函数。 六、程序转化语义 程序转化语义主要是理解编译器如何将人类写的代码解析成编译器理解的代码。为此，从两个角度来分析。下面的代码帮助更好的理解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class X&#123;public: int m_i; X(const X &amp;tmpx) &#123; m_i = tmpx.m_i; cout &lt;&lt; &quot;拷贝构造函数被调用&quot; &lt;&lt; endl; &#125; X() &#123; m_i = 0; cout &lt;&lt; &quot;构造函数被调用&quot; &lt;&lt; endl; &#125; ~X() &#123; cout &lt;&lt; &quot;析构函数被调用&quot; &lt;&lt; endl; &#125; void functest() &#123; cout &lt;&lt; &quot;functest()被调用&quot; &lt;&lt; endl; &#125;&#125;;//参数初始化对比//人类角度void func(X tmpx)&#123; return;&#125;//老编译器看func(老编译器角度)void func(X &amp;tmpx)&#123; return;&#125;//返回值初始化对比//人类视角X func()&#123; X x0; //.... return x0; //系统产生临时对象并把x0的内容拷贝构造给了临时对象。&#125;//编译器角度的funcvoid func(X &amp;extra)&#123; X x0; //从编译器角度，这行不调用X的构造函数 //... //... extra.X::X(x0); return;&#125; 我们写的代码，编译器会对代码进行拆分，拆分成编译器更容易理解和实现的代码。看一看编译器是如何解析这些代码的。 （1）定义时初始化对象 12345678910//程序员视角X x0;x0.m_i = 15;X x1 = x0; X x2(x0);X x3 = (x0);//切换到编译器角度，编译器会拆分成两个步骤(编译器视角)X x100; //步骤一：定义一个对象，为对象分配内存。从编译器视角来看，这句是不调用X类的构造函数。x100.X::X(x0); //步骤二：直接调用对象的拷贝构造函数去了； （2）参数的初始化 12345678//程序员视角/现代编译器func(x0);//老编译器视角X tmpobj; //编译器产生一个临时对象tmpobj.X::X(x0); //调用拷贝构造函数func(tmpobj); //用临时对象调用functmpobj.X::~X(); //func()被调用完成后，本析构被调用。 （3）返回值初始化 123456789101112131415161718192021222324252627//程序员角度X my = func();//编译器对上述代码的理解(编译器角度)X my; //不会调用X的构造函数func(my);//利用返回值调用成员函数//人类视角func().functest();//切换到编译器视角X my; //不会调用X的构造函数(func(my), my).functest(); //逗号表达式：先计算表达式1，再计算表达式2，整个逗号表达式的结果是表达式2的值；//利用函数指针调用成员函数//程序员视角X(*pf)(); //定义个函数指针pf = func;pf().functest();//编译器视角X my; //不调用构造函数void (*pf)(X &amp;);pf = func;pf(my);my.functest(); 七、拷贝构造续与深浅拷贝 （1）当编译器面临用一个类对象作为另外一个类对象初值的情况，各个编译器表现不同。但是所有编译器都为了提高效率而努力。我们也没有办法确定我们自己使用的编译器是否一定会调用拷贝构造函数。 （2）拷贝构造函数不是必须有的，如果只有一些简单的成员变量类型，int,double，你会发现你根本不需要拷贝构造函数，编译器内部本身就支持成员变量的bitwise(按位)copy，即按位拷贝。 （3）当需要处理很复杂的成员变量类型的时候。因为我们增加了自己的拷贝构造函数，导致编译器本身的bitwise拷贝能力失效，它会调用我们自己的拷贝构造函数，因此如果你增加了自己的拷贝构造函数后，就要对各个成员变量的值的初始化负责了。 （4）我们自己创建内存，把目标对象的内存内容拷贝过来，叫深拷贝，例如下面的程序。相反，上述编译器做的拷贝叫浅拷贝。（注意：涉及到指针的时候，必须用深拷贝，不能浅拷贝，否则指针所指的内存会被析构两次，导致错误） 12345678910111213class X&#123;public: int m_i; int *p_mi; X(const X&amp; tmpx) &#123; p_mi = new int(100); //自己申请内存 memcpy(p_mi, tmpx.p_mi, sizeof(int)); //拷贝 m_i = tmpx.m_i; cout &lt;&lt; &quot;拷贝构造函数被调用&quot; &lt;&lt; endl; &#125;&#125;; 八、初始化列表 （1）必须使用初始化列表的情况 （a）这个成员是个引用 （b）是个const类型成员 （c）如果这个类是继承一个基类，并且基类中有构造函数，这个构造函数里边还有参数。 （d）如果成员变量类型是某个类类型，而这个类的构造函数带参数时。 （2）使用初始化列表的优势。除了必须用初始化列表的场合，我们用初始化列表还有什么其他目的？ 有，就是提高程序运行效率。对于类类型成员变量放到初始化列表中能够比较明显的看到效率的提升，但是如果是个简单类型的成员变量比如int m_test,其实放在初始化列表或者放在函数体里效率差别不大。（提醒：成员变量初始化尽量放在初始化列表里，显得高端，大气上档次） （3）初始化列表中的代码可以看作是被编译器安插到构造函数体中的，只是这些代码有些特殊。这些代码是在任何用户自己的构造函数体代码之前被执行的。所以要区分开构造函数中的用户代码和编译器插入的初始化所属的代码。 （4）初始化列表中变量的初始化顺序是变量的定义顺序，而不是在初始化列表中的顺序。不建议在初始化列表中进行两个都在初始化列表中出现的成员之间的初始化（例如：m1和m2都在初始化列表中，不建议用m1来初始化m2，或用m2初始化m1）。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>C++对象模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL源码剖析（3）]]></title>
    <url>%2F2019%2F07%2F30%2FSTL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89%2F</url>
    <content type="text"><![CDATA[写在前面的话 前一篇博文介绍了迭代器，接下来介绍一下STL的大部头–容器。这一篇首先介绍序列式容器。 容器概览与分类 STL的容器是将运用最广的一些数据结构实现出来。众所周知，常用的数据结构不外乎 array, list, tree, stack, queue, hash table, set, map 等。根据数据在容器中的排列特性，这些数据结构分为序列式和关联式两种，因此容器也分为序列式容器和关联式容器。序列式容器有：array, vector, heap, priority-queue, list, slist, deque, stack, queue。关联式容器有：rb-tree, set, map, multiset, multimap, hashtable, hash-set, hash-map, hash-multiset, hash_multimap。 其中，heap是以vector为底层来实现的，priority-queue又是以heap为底层实现。而stack和queue都是以deque为原型通过配接器配接而来。关联式容器中的 set map multiset multimap 都是以 rb-tree 为底层实现, hash-set hash-map hash-multiset hash_multimap又都是以 hashtable 为底层实现。 需要注意的是，序列式容器都可序，但未必有序。接下来分别介绍各容器。 vectorvector概述 vector 的数据安排以及操作方式与 array 非常相似。两者唯一的差别在于空间的运用的灵活性。array 是静态空间，一旦配置了就不能改变，要换一个大（小）一点的空间，首先得配置一块新空间，然后从旧址一一搬往新址，再把原来的空间释放。vector 是动态空间，随着元素的加入，它的内部机制会自行扩充空间以容纳新元素。因此使用 vector，我们再也不必因为害怕空间不足而一开始就要求一个大块头 array 了。 vector的迭代器 vector 维护的是一个连续的线性空间，所以不论其元素型别为何，普通指针都可以作为 vector 的迭代器而满足所有必要条件。因此 vector 的迭代器是普通指针。vector 支持随机存取，而普通指针也正有这样的能力，所以 vector 提供的是 random access iterators。 vector的数据结构 vector的数据结构比较简单，是线性连续空间。它内部维护有三个迭代器（指针）：start表示目前使用空间的头，finish表示目前使用空间的尾，end_of_storage表示目前可用空间的尾。 当我们以push_back()将新元素插入于vector尾端时，该函数首先检查是否还有备用空间，如果有就直接在备用空间上构造元素，并调整迭代器 finish，使 vector 变大。如果没有备用空间了，就扩充空间，即动态增加大小，这并不是在原空间之后接续新空间（因为无法保证原空间之后有可供配置的空间），而是以原大小的两倍另外配置一块较大空间，然后将原内容拷贝过来，然后才开始在原内容之后构造新元素，并释放原空间。因此，对 vector 的任何操作，一旦引起空间重新配置，指向原 vector 的所有迭代器就都失效了。 vector的erase(first, last)操作 首先将last至finsh之间的元素拷贝到first开始处，然后释放拷贝内容中最后一个元素的下一个内存单元至finsh的内存，再将finsh调整为：finsh=finsh-(last-first)。 listlist概述 list是一个链表，是由一个一个节点组成的，每一个节点结构内部有两个指针，分别指向前一个节点和后一个节点，还有一个数据域来存放节点数据。list的好处是每次插入或删除一个元素，就配置或释放一个元素空间。因此，list对空间的利用率很高，一点也不浪费。而且，对于任何位置的元素插入或元素移除，list永远是常数时间。 list的迭代器 list不再能够像vector一样以普通指针作为迭代器，因为其节点不保证在存储空间中连续存在。list迭代器必须有能力指向list的节点，并且有能力进行正确的递增、递减、取值、成员存取等操作。也就是说，递增时指向下一个节点，递减时指向上一个节点，取值时取的是节点的数据值，成员取用时取用的是节点的成员。 由于STL的list是一个双向链表。迭代器必须具备前移、后移的能力，所以list提供的是bidirectional iterators。list在插入和接合操作的时候都不会造成原有的list迭代器失效，在删除操作的时候只有指向被删元素的那个迭代器失效，其他迭代器不受任何影响。 list的数据结构 list不仅是一个双向链表，而且还是一个环状双向链表，所以它只需要一个指针，便可完整表现整个链表。如果让该指针（注意：此指针并非前面所说的节点内部的指针，这里的指针是指向每个节点的指针）指向刻意置于尾端的一个空白节点，便能符合STL对于“前闭后开”区间的要求，成为list迭代器。list作为双向链表，在头部和尾部都可以插入数据。 dequedeque概述 deque是一种双向开口的连续线性空间。所谓双向开口，意思就是可以在头尾两端分别做元素的插入和删除操作。deque和vector的不同主要有三点：（1）vector是单向开口的空间，虽然也能在头部插入元素，但是效率极差，而deque可以在常数时间内对头部进行插入或移除操作。（2）deque没有容量的概念，因为它是动态地以分段连续空间组合而成，随时可以增加一段新的空间并链接起来。而vector是因旧空间不足而重新配置一块更大空间，然后复制元素，再释放旧空间。（3）deque的迭代器不是普通指针，因为它的实际空间并不是连续的，而vector的迭代器和普通指针一样。 deque表面上看起来是连续空间，其实它内部是将一段一段连续空间通过中控器的操作接合起来，一旦有必要在deque的前端或尾端增加新空间，便配置一段定量连续空间，串接在整个deque的头端或尾端。deque的最大任务，便是在这些分段的定量连续空间上，维护其整体连续的假象，使人们使用起来感觉像是在操作一段连续空间。它还提供了随机存取接口，避免了“重新配置、复制、释放”的轮回，代价则是复杂的迭代器结构。 deque采用一块所谓的map作为主控，这里的map其实是一小块连续空间，其中每个元素都是指针，指向另一段（较大的）连续线性空间，称为缓冲区。缓冲区才是deque的存储空间主体。通过看源码，可以发现map其实是一个指针，所指之物又是一个指针，指向另一块空间。 deque的迭代器 deque的迭代器首先必须能够指出缓冲区在哪里，其次它必须能够判断自己是否已经处于所在缓冲区的边缘，如果是，一旦前进或后退时就必须跳跃至下一个或上一个缓冲区。因此，deque的迭代器应该包括四个指针：cur指向该迭代器所指缓冲区中的当前元素，first指向该迭代器所指缓冲区的头部，last指向该迭代器所指缓冲区的尾部，node指向管控中心，用来找到迭代器所指的缓冲区。 deque的数据结构 deque除了维护一个先前说过的指向map的指针外，也维护start,finish两个迭代器，分别指向第一缓冲区的第一个元素和最后缓冲区的最后一个元素的下一位置。此外，它当然也必须记住目前的map大小。因为一旦map所提供的节点不足，就必须重新配置更大的一块map。 stack和queuestack stack是一种先进后出的数据结构，它只有一个出口。stack允许新增元素、移除元素、取得顶端元素。但除了最顶端外，没有任何其他方法可以存取stack的其他元素。换言之，stack不允许有遍历行为。STL中以deque作为缺省情况下的stack底部结构。 stack所有元素的进出都必须符合先进后出的条件，只有stack顶端的元素，才有机会被外界取用。stack不提供走访功能，也不提供迭代器。另外，除了deque外，list也可以作为stack的底部容器。 queue queue是一种先进先出的数据结构。他有两个出口，允许新增元素、移除元素、从最底端加入元素、取得最顶端的元素。但是除了最底端加入、最顶端取出外，没有其他任何办法可以存取queue的其他元素。即queue不允许有遍历行为，queue也没有迭代器。STL默认将deque作为queue的底部容器，当然list也可以作为queue的底部容器。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL源码剖析（2）]]></title>
    <url>%2F2019%2F07%2F28%2FSTL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[写在前面的话 上一篇博文写了STL的分配器，这一篇着重介绍一下迭代器。 迭代器介绍 我们都知道，STL中将容器和算法分离开来，彼此独立设计，以达到泛化的效果，而在使用的时候又需要将这两种东西撮合到一起，实现这个撮合功能的就是迭代器。也就是说迭代器是介于容器与算法之间的一种东西，它可以把实现某个算法所需要的容器里面的信息传递给算法，从而达到一种“桥梁”的效果。 迭代器可以看作是一种“智能指针”。它是一种行为类似指针的对象，而指针的各种行为中最常见的也是最重要的便是内容提取和成员访问，因此，迭代器最重要的编程工作就是对 operator✳ 和 operator-&gt;进行重载。关于这一点，其实跟真证的智能指针（share_ptr等）没有区别。既然迭代器实现的功能和指针一样，那为什么不直接用指针来代替迭代器呢？何必还要多此一举。这是因为，指针只能在连续空间上前进和后退，而不能随意的跳转，例如在双向链表的每一个节点中，都有两个指针，分别指向前一个元素和后一个元素，除此之外每个节点中还有另外的空间来存储数据，当指针+1的时候，它只能在该节点的连续空间上移动，而当设计好相应功能的迭代器+1的时候，可以直接跳到下一个节点，也就是说，迭代器可以实现跨区域跳转，这就是它与指针之间最大的不同。 迭代器的相应型别 我们发现，在算法中运用迭代器时，会用到迭代器的相应型别，什么是相应型别？迭代器所指之物的型别就是其中的一种。常用迭代器的相应型别有五种，分别是：value type; difference type; reference type; pointer type; iterator_category.接下来分别介绍这五种相应型别。 value type 所谓 value type，就是指迭代器所指对象的型别，任何一个打算与 STL 算法有完美搭配的类，都应该定义自己的 value type 内嵌型别。 difference type difference type 用来表示两个迭代器之间的距离，因此它也可以用来表示一个容器的最大容量，因为对于连续空间的容器而言，头尾之间的距离就是其最大容量，如果一个泛型算法提供计数功能，例如 STL 的 count(), 其传回值就必须使用迭代器的 difference type。 reference type 在 C++ 中，函数要传回左值，都是以传引用的方式进行，所以当 p 是个可修改值的迭代器时，如果其 value type 是 T,那么 ✳p 的型别不应该是 T，应该是 T&amp;.同理，如果 p 是一个不可修改值的迭代器，其 value type 是 T，那么 ✳p 的型别不应该是 const T,而应该是 const T&amp;。这里讨论的 ✳p 的型别，即所谓的 reference type。 pointer type 指针和引用有着非常密切的关系。如果传回一个左值，令它代表 p 所指之物是可能的，那么传回一个左值，令它代表 p 所指之物的地址也一定可以。也就是说，我们能够传回一个指针，指向迭代器所指之物。 iterator_category 这个型别表明了迭代器的类别。根据移动特性和施行操作，迭代器被分为五类：input iterator（只读，即这种迭代器所指的对象不允许外界改变）；output iterator（只写，即该迭代器所指的对象只能被外界改变，不能读取）；forward iterator（单向读写）；bidirectional iterator（双向读写）；random access iterator（随机读写）。 以上五种迭代器的类别，前三种支持 operator++，第四种再加上 operator–，第五种则涵盖所有指针算术能力，包括 p+n, p-n, p[n], p1-p2, p1&lt;p2。在设计算法时，应该尽量对迭代器的类型做一个明确的规定，这样才能在不同情况下提供最大的效率。假设有个算法可接受 forward iterator ,你给它传一个 random access iteator 进去，它当然也会接受，因为一个 random access iteator 必然是一个 forward iteator,但是从效率上来讲，这并不是最佳的方案。 Traits编程技法 traits用来提取对象的型别，对应的模板参数不管是泛化版本还是特化版本，通通都能准确的萃取出来。如果传进来的参数 I 定义有自己的 value type，那么通过 traits,萃取出来的 value type 就是 I::value type。如果是特化版本，例如 T✳，则萃取出来的 value type 就是 T。特别注意，const T✳，萃取出来后也是 T 而非 const T,这是因为我们的本意就是声明一个临时变量，使之与迭代器的 value type 相同，而如果声明一个无法赋值的变量，没有什么作用，因此，对于 const 类型的变量，萃取出来的 value type就会变成 non-const类型。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL源码剖析（1）]]></title>
    <url>%2F2019%2F07%2F26%2FSTL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[写在前面的话 近段时间看了侯捷老师的《STL源码剖析》，看第一遍的时候一头雾水，反复多看几遍，似乎明白了一些。因此将学到的知识做一个记录，也算是记录自己的学习过程。本系列博客主要记录一些宏观理解性的东西，具体的代码实现还是要仔细品味原书。 概览 STL即C++标准模板库，主要由六大部件组成，分别是：分配器、容器、迭代器、算法、仿函数、配接器。这六大部件之间的交互关系表现为：容器通过分配器取得数据存储空间，算法通过迭代器存取容器的内容，仿函数可以协助算法完成不同的策略变化，配接器可以修饰或套接仿函数、迭代器、容器等。 在讲述这些主要部件之前，先来了解一下面向对象编程和泛型编程，面向对象编程（Object-Oriented programming，简称OOP）企图将数据和处理数据的方法放到一起，例如，在C++的类中，一般会有成员变量和处理成员变量的成员函数，在需要使用的时候创建一个对象，然后以对象来调用它们。而泛型编程（Generic Programming,简称GP）是将数据和处理方法分离开来，这里的处理方法通常是全局函数，例如STL中的算法和容器，两者互不影响，需要的时候通过迭代器来传递信息。 好了，接下来就从这六大部件出发，了解STL的内部关系。这篇博文主要记录分配器的重点。 分配器（allocators） allocator主要是用来管理存储空间，它当中的 allocate() 调用 operator new() 来分配空间，其中 operator new() 中又调用了C语言中的 malloc() 函数，而 deallocate() 则调用了operator delete(),其中，operator delete() 又调用了 free() 来释放内存。以上谈的这种分配器是标准规范下的实现方法。而SGI STL有一种默认的分配器 alloc ，它的每一个容器都已经指定其缺省的空间分配器为 alloc，例如下面的 vector 声明： template &lt;class T, class Alloc = alloc&gt; class vector{…}; 这其中就是缺省使用的 alloc 为分配器。由于调用 malloc() 只会寻找整片比较大的空间，对于一些小型区块，可能造成内存浪费的问题,因此，SGI设计了双级分配器，第一级分配器直接使用 malloc() 和 free()，第二级分配器则视情况采用不同的策略：当配置区块超过128字节时，视之为 “足够大”，便调用第一级分配器 ，当分配区块小于128字节时，视之为 “过小”，为了降低额外负担（合理利用资源），就使用第二级分配器。 而第二级分配器的具体实现是以内存池管理的形式，每次配置一块大内存，然后维护对应的自由链表（可增加，也可删减），下次如果再有相同大小的内存需求，就直接从自由链表中取出，如果使用方释放了小块内存，则由分配器回收到对应的链表中。为了方便管理，SGI的第二级分配器会主动将任何小额区块的内存需求上调至8的倍数（例如使用者需要30字节，就自动调整为32字节），并维护16个自由链表，各自管理的大小分别为：8，16，24，32，40，56，64，72，80，88，96，104，112，128字节的小额区块（例如：第一个链表节点就管理空间内所有大小为8字节的小区快，第二个节点管理所有大小为16字节的小区快，以此类推）。 因此，整个的内存分配释放过程即可归纳为如下流程：分配器拥有标准接口函数 allocate()，此函数首先判断区块的大小，大于128字节就调用第一级分配器，小于128字节就检查对应的自由链表。如果自由链表内有可用的区块，就直接拿来用，如果没有可用的区块，就将区块大小上调至8的倍数，然后重新填充空间。 在释放的时候，同样由分配器的标准接口函数 deallocate() 首先判断区块大小，大于128字节就调用第一级分配器，小于128字节就找出对应的自由链表，将区块回收。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博客]]></title>
    <url>%2F2019%2F07%2F13%2F%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[写博客的想法是怎么产生的前两天在B站上偶然看见一个免费搭建个人博客的教程，于是产生了兴趣。尝试去搜索了一下，竟然发现有好多搭建博客的方法，实在是感觉自己好low，不过，总归现在发现还不算太晚（强行安慰。。）于是按照搜索的几种方法都进行了尝试，最终选择了用 hexo 配合 github 搭建了第一个属于自己的个人博客（正是此博客）。虽然现在看起来有点low，但是基本功能还算齐全，其他华丽的功能有待开发。 写博客的目的博客站点搭建好了，当然也要开始养成写博客的习惯了。之前在网上搜索一些问题的时候总是能看到各种大佬级别的博客，都写得特别好，虽然我也有过写博客的想法，但是一直没有付诸行动，这次搭建了自己的站点，再不写点就说不过去了，总不能就光秃秃的一个页面，什么内容也没有吧。所以借着这次机会，总算能治一治我的拖延症了。至于本博客的目的，就当是记录自己的生活，学习过程。如果能帮到别人，那自然是更好。 博客内容对于博客内容，我初步打算分为以下几个类别：生活、技术、读书笔记等。生活类的文章主要谈一些我所经历过的值得记录的事情以及感想；技术方面主要就是在学习过程中的一些积累（这方面可能会写的比较多一点）。读书笔记则会在我每读完一本书的时候做一些总结，方便以后查阅（主要是指技术书籍）。当然后续还有其他有趣的版块分类，我也会加进去。 期待的样子 我所期待的博客当然是不仅能够连贯地记录自己的生活，而且能够利用自己的知识帮助更多的人。然而，道理我们都懂，一口吃不成胖子，而且万事开头难，所以要一步一步来，努力把它打造成自己喜欢的样子。]]></content>
      <categories>
        <category>生活杂谈</category>
      </categories>
      <tags>
        <tag>生活杂谈</tag>
      </tags>
  </entry>
</search>
